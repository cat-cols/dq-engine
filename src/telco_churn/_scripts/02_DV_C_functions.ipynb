{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa89937f",
   "metadata": {},
   "source": [
    "# 02 ‚Äî Data Validation & Cleaning\n",
    "\n",
    "**Goal:** Validate schema, types, missingness, and logical consistency; then produce a clean dataset for downstream preprocessing.\n",
    "\n",
    "**Inputs:** `resources/data/raw/telco_customer_churn.csv`  \n",
    "**Outputs:** \n",
    "- `resources/data/processed/telco_clean.csv`\n",
    "- `Level_3/reports/validation_summary.csv` (issues & fixes applied)\n",
    "- `Level_3/reports/missingness_summary.csv`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc5badc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found raw dataset: /Users/b/DATA/PROJECTS/Telco/resources/data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "‚úÖ Environment loaded from 00_Setup.ipynb\n",
      "üì• Raw loaded: 7,043 rows √ó 21 cols\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üèóÔ∏è Setup: env, paths, and load raw dataset\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Reuse 00_Setup if available; else minimal inline setup\n",
    "try:\n",
    "    %run ./00_Setup.ipynb\n",
    "    print(\"‚úÖ Environment loaded from 00_Setup.ipynb\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Fallback setup (00_Setup failed: {e})\")\n",
    "    current_path = Path.cwd().resolve()\n",
    "    for parent in [current_path] + list(current_path.parents):\n",
    "        if parent.name == \"Telco\":\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(\"‚ùå 'Telco' repo root not found.\")\n",
    "    DATA_ROOT = PROJECT_ROOT / \"resources\" / \"data\"\n",
    "    DATA_RAW_DIR = DATA_ROOT / \"raw\"\n",
    "    DATA_PROCESSED_DIR = DATA_ROOT / \"processed\"\n",
    "    RAW_PATH = DATA_RAW_DIR / \"telco_customer_churn.csv\"\n",
    "    CLEAN_PATH = DATA_PROCESSED_DIR / \"telco_clean.csv\"\n",
    "\n",
    "# 2) Level_3 outputs\n",
    "LEVEL_DIR = PROJECT_ROOT / \"Level_3\"\n",
    "REPORTS = LEVEL_DIR / \"reports\"\n",
    "REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3) Load raw (no mutations here)\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "print(f\"üì• Raw loaded: {df.shape[0]:,} rows √ó {df.shape[1]:,} cols\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27767e80",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Structural Validation (Schema & Dtypes)\n",
    "- Validate required columns\n",
    "- Flag extras\n",
    "- Normalize dtypes (coerce where appropriate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4da056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema check complete.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üîé Schema & Dtypes\n",
    "# ==========================================================\n",
    "validation_log = []\n",
    "\n",
    "# Expected baseline columns (adjust per dataset if needed)\n",
    "expected_columns = [\n",
    "    \"customerID\", \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\",\n",
    "    \"tenure\", \"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
    "    \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\",\n",
    "    \"PaymentMethod\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"\n",
    "]\n",
    "\n",
    "missing = [c for c in expected_columns if c not in df.columns]\n",
    "extra   = [c for c in df.columns if c not in expected_columns]\n",
    "\n",
    "if missing:\n",
    "    validation_log.append({\"issue\": \"missing_columns\", \"detail\": \",\".join(missing), \"action\": \"review upstream or adjust expectations\"})\n",
    "if extra:\n",
    "    validation_log.append({\"issue\": \"extra_columns\", \"detail\": \",\".join(extra), \"action\": \"retain for now (non-blocking)\"})\n",
    "\n",
    "\n",
    "# Coerce common problematic dtypes safely (examples)\n",
    "# Leave cleaning/imputation decisions for later steps\n",
    "coerce_numeric_cols = [\"SeniorCitizen\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "for c in coerce_numeric_cols:\n",
    "    if c in df.columns:\n",
    "        before_na = df[c].isna().sum()\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        after_na = df[c].isna().sum()\n",
    "        if after_na > before_na:\n",
    "            validation_log.append({\"issue\": \"dtype_coercion_to_numeric\",\n",
    "                                   \"detail\": f\"{c}: {before_na}‚Üí{after_na} NaN after coercion\",\n",
    "                                   \"action\": \"handle missing in step 2\"})\n",
    "\n",
    "print(\"‚úÖ Schema check complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f7695",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2) Missingness & Empty Strings\n",
    "- Quantify missing/blank/space-only\n",
    "- Decide imputation vs. leave as NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e04935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================================\n",
    "# üß≠ Missingness & blanks\n",
    "# ==========================================================\n",
    "# Empty-string & space-only counts\n",
    "empty_counts = {}\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == \"object\":\n",
    "        empty_counts[c] = {\n",
    "            \"empty_string\": (df[c] == \"\").sum(),\n",
    "            \"single_space\": (df[c] == \" \").sum(),\n",
    "            \"strip_to_empty\": df[c].astype(str).str.strip().eq(\"\").sum()\n",
    "        }\n",
    "empty_df = pd.DataFrame(empty_counts).T.sort_index()\n",
    "empty_df.to_csv(REPORTS / \"missingness_summary.csv\")\n",
    "\n",
    "validation_log.append({\"issue\": \"blank_values\", \"detail\": \"see missingness_summary.csv\", \"action\": \"normalize below\"})\n",
    "\n",
    "\n",
    "# Normalize object columns: strip whitespace; set \"\" ‚Üí NaN\n",
    "obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for c in obj_cols:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "    df[c].replace({\"\": np.nan}, inplace=True)\n",
    "\n",
    "# Example policy (adjust to your needs):\n",
    "# - Leave NaN for modeling pipeline to handle OR\n",
    "# - Minimal imputation for known logic (commented examples below)\n",
    "\n",
    "# Telco-specific example (optional): tenure==0 often implies TotalCharges‚âà0\n",
    "# if \"tenure\" in df.columns and \"TotalCharges\" in df.columns:\n",
    "#     mask = df[\"tenure\"].fillna(-1).eq(0) & df[\"TotalCharges\"].isna()\n",
    "#     df.loc[mask, \"TotalCharges\"] = 0\n",
    "#     if mask.sum():\n",
    "#         validation_log.append({\"issue\": \"impute_TotalCharges\",\n",
    "#                                \"detail\": f\"Set TotalCharges=0 for {mask.sum()} rows where tenure=0\",\n",
    "#                                \"action\": \"documented explicit rule\"})\n",
    "\n",
    "print(\"‚úÖ Missingness normalization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd448ddf",
   "metadata": {},
   "source": [
    "## 3) Domain & Logical Consistency\n",
    "- Range checks (non-negative, reasonable upper bounds)\n",
    "- Category membership checks\n",
    "- Cross-field logic (e.g., internet service vs. downstream features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd514a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# ‚öñÔ∏è Domain & Logical Rules\n",
    "# ==========================================================\n",
    "def add_log(issue, detail, action):\n",
    "    validation_log.append({\"issue\": issue, \"detail\": detail, \"action\": action})\n",
    "\n",
    "# --- Range checks (examples) ---\n",
    "if \"tenure\" in df.columns:\n",
    "    bad = df.query(\"tenure < 0\").shape[0]\n",
    "    if bad:\n",
    "        add_log(\"invalid_tenure\", f\"{bad} rows tenure<0\", \"clip to 0\")\n",
    "        df[\"tenure\"] = df[\"tenure\"].clip(lower=0)\n",
    "\n",
    "for col in [\"MonthlyCharges\", \"TotalCharges\"]:\n",
    "    if col in df.columns:\n",
    "        neg = df[df[col] < 0].shape[0]\n",
    "        if neg:\n",
    "            add_log(\"negative_values\", f\"{col}: {neg} rows\", \"set negatives to NaN\")\n",
    "            df.loc[df[col] < 0, col] = np.nan\n",
    "\n",
    "# --- Category membership (examples) ---\n",
    "def enforce_membership(col, allowed):\n",
    "    if col in df.columns:\n",
    "        vals = set(df[col].dropna().unique())\n",
    "        invalid = vals - set(allowed)\n",
    "        if invalid:\n",
    "            add_log(\"invalid_category\", f\"{col}: {invalid}\", \"normalize case/whitespace; then set invalid‚ÜíNaN\")\n",
    "            # normalize case/title (idempotent)\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "            # strategy: set truly invalid to NaN\n",
    "            df.loc[~df[col].isin(allowed), col] = np.nan\n",
    "\n",
    "enforce_membership(\"Contract\", {\"Month-to-month\", \"One year\", \"Two year\"})\n",
    "enforce_membership(\"InternetService\", {\"DSL\", \"Fiber optic\", \"No\"})\n",
    "enforce_membership(\"PaperlessBilling\", {\"Yes\", \"No\"})\n",
    "enforce_membership(\"Churn\", {\"Yes\", \"No\"})\n",
    "\n",
    "# --- Cross-field logic (examples) ---\n",
    "# If no internet service, dependent features should reflect that\n",
    "internet_no_mask = df.get(\"InternetService\", pd.Series(index=df.index)).eq(\"No\") if \"InternetService\" in df else pd.Series(False, index=df.index)\n",
    "internet_dependent = [\"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\"]\n",
    "for c in internet_dependent:\n",
    "    if c in df.columns:\n",
    "        mism = (~df[c].isin({\"No internet service\", \"Yes\", \"No\"})).sum()\n",
    "        if mism:\n",
    "            add_log(\"unexpected_values\", f\"{c}: {mism} rows\", \"coerce unexpected ‚Üí NaN\")\n",
    "            df.loc[~df[c].isin({\"No internet service\", \"Yes\", \"No\"}), c] = np.nan\n",
    "        # enforce logical mapping\n",
    "        fix_mask = internet_no_mask & df[c].ne(\"No internet service\")\n",
    "        if fix_mask.any():\n",
    "            df.loc[fix_mask, c] = \"No internet service\"\n",
    "            add_log(\"logical_fix\", f\"{c}: set 'No internet service' for {int(fix_mask.sum())} rows\", \"rule-based correction\")\n",
    "\n",
    "print(\"‚úÖ Domain & logical rules applied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de7a40",
   "metadata": {},
   "source": [
    "## 4) Duplicates & Outliers (flag; minimal mutation)\n",
    "- Remove exact-duplicate rows\n",
    "- Flag extreme numeric outliers (don‚Äôt drop by default in cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c561030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================================\n",
    "# üßæ Duplicates & Outlier Flags\n",
    "# ==========================================================\n",
    "# Exact duplicates\n",
    "dups = df.duplicated().sum()\n",
    "if dups:\n",
    "    validation_log.append({\"issue\": \"duplicate_rows\", \"detail\": f\"{dups} duplicates\", \"action\": \"drop duplicates\"})\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "# Simple outlier flag (IQR) ‚Äî do not remove here, just log counts\n",
    "def iqr_outlier_count(series):\n",
    "    q1, q3 = series.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    return int(((series < lower) | (series > upper)).sum())\n",
    "\n",
    "for col in [\"MonthlyCharges\", \"TotalCharges\", \"tenure\"]:\n",
    "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "        count = iqr_outlier_count(df[col].dropna())\n",
    "        if count:\n",
    "            validation_log.append({\"issue\": \"outliers_flagged\", \"detail\": f\"{col}: {count} flagged (IQR)\", \"action\": \"review in 03_Preprocessing\"})\n",
    "print(\"‚úÖ Duplicates handled; outliers flagged.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7b86b",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Final sanity check & save artifacts\n",
    "- Save validation logs\n",
    "- Save cleaned dataset (CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# üíæ Save reports & clean dataset\n",
    "# ==========================================================\n",
    "val_df = pd.DataFrame(validation_log) if validation_log else pd.DataFrame(columns=[\"issue\",\"detail\",\"action\"])\n",
    "val_path = REPORTS / \"validation_summary.csv\"\n",
    "val_df.to_csv(val_path, index=False)\n",
    "\n",
    "clean_path = DATA_PROCESSED_DIR / \"telco_clean.csv\"\n",
    "df.to_csv(clean_path, index=False)\n",
    "\n",
    "print(f\"üìù Validation summary: {val_path}\")\n",
    "print(f\"‚úÖ Clean dataset saved: {clean_path}\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a328e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (Optional) Upgrade path\n",
    "- Swap ad-hoc checks for **Pandera** or **Great Expectations** in a future pass.\n",
    "- Add unit tests to assert schema and critical invariants.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can also generate a **matching header cell for `03_Preprocessing.ipynb`** that expects `telco_clean.csv` and sets up encoders/scalers/splits cleanly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
