{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e98c5e",
   "metadata": {},
   "source": [
    "Nice, letâ€™s â€œlock inâ€ Section 2 as a **pure config consumer** with a clean 2.0A header + a single helper that guarantees everything is ready.\n",
    "\n",
    "Hereâ€™s a drop-in **2.0A block** you can paste at the **top of Section 2** (right before 2.0.1). It does:\n",
    "\n",
    "* Docstring-style overview for 2.0A.\n",
    "* A helper `assert_config_ready_for_section2()` that:\n",
    "\n",
    "  * Checks `CONFIG`, `C`, `PROJECT_ROOT`, `df`, `REPORTS_DIR`, etc.\n",
    "  * Validates key config roots: `TARGET`, `ID_COLUMNS`, `RANGES`, `DATA_QUALITY`.\n",
    "* Prints a short â€œOK, Section 2 may proceedâ€ summary.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© 2.0A Environment & Config Readiness (drop-in code)\n",
    "\n",
    "```python\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2.0A âš™ï¸ Environment & Path Initialization (Section 2 preflight)\n",
    "# \n",
    "# Purpose:\n",
    "#   - Assert that Section 1 has fully run (config, paths, data load).\n",
    "#   - Confirm key config roots for Section 2 are present.\n",
    "#   - Ensure report/artifact directories exist and are writable.\n",
    "#\n",
    "# This cell does NOT load config. It only CONSUMES:\n",
    "#   - PROJECT_ROOT, CONFIG, C(), df\n",
    "#   - REPORTS_DIR, ARTIFACTS_DIR, FIGURES_DIR, etc.\n",
    "#\n",
    "# If everything is OK, later sections (2.0.1â€“2.9) can assume:\n",
    "#   - df is a valid working DataFrame\n",
    "#   - CONFIG has the required keys for Section 2\n",
    "#   - paths & directories are ready for reports and artifacts\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def assert_config_ready_for_section2() -> None:\n",
    "    \"\"\"\n",
    "    Preflight checks for Section 2.\n",
    "\n",
    "    Raises informative exceptions if:\n",
    "      - Section 1 was not run (missing CONFIG, C, df, PROJECT_ROOT, paths)\n",
    "      - Required CONFIG roots for Section 2 are missing\n",
    "    \"\"\"\n",
    "    # --- 1. Global objects from Section 1 ---------------------------------------\n",
    "    required_globals = [\n",
    "        \"PROJECT_ROOT\",\n",
    "        \"CONFIG\",\n",
    "        \"C\",\n",
    "        \"RAW_DATA\",\n",
    "        \"REPORTS_DIR\",\n",
    "        \"ARTIFACTS_DIR\",\n",
    "        \"FIGURES_DIR\",\n",
    "        \"MODELS_DIR\",\n",
    "        \"OUTPUTS_DIR\",\n",
    "        \"df\",\n",
    "    ]\n",
    "\n",
    "    missing = [g for g in required_globals if g not in globals()]\n",
    "    if missing:\n",
    "        raise RuntimeError(\n",
    "            \"âŒ Section 2 preflight failed â€” missing globals from Section 1: \"\n",
    "            + \", \".join(missing)\n",
    "        )\n",
    "\n",
    "    if not callable(C):\n",
    "        raise TypeError(\"âŒ C is not callable. Did Section 1.3 run correctly?\")\n",
    "\n",
    "    # --- 2. Basic path sanity ---------------------------------------------------\n",
    "    core_dirs = {\n",
    "        \"REPORTS_DIR\": REPORTS_DIR,\n",
    "        \"ARTIFACTS_DIR\": ARTIFACTS_DIR,\n",
    "        \"FIGURES_DIR\": FIGURES_DIR,\n",
    "        \"MODELS_DIR\": MODELS_DIR,\n",
    "        \"OUTPUTS_DIR\": OUTPUTS_DIR,\n",
    "    }\n",
    "\n",
    "    for name, d in core_dirs.items():\n",
    "        if not isinstance(d, Path):\n",
    "            raise TypeError(f\"âŒ {name} is not a pathlib.Path: {d!r}\")\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- 3. Required CONFIG roots for Section 2 --------------------------------\n",
    "    required_roots = [\"TARGET\", \"ID_COLUMNS\", \"RANGES\", \"DATA_QUALITY\"]\n",
    "\n",
    "    missing_roots = [r for r in required_roots if r not in CONFIG]\n",
    "    if missing_roots:\n",
    "        raise KeyError(\n",
    "            \"âŒ Section 2 requires config roots missing from CONFIG: \"\n",
    "            + \", \".join(missing_roots)\n",
    "        )\n",
    "\n",
    "    # Optional: soft-check flags block\n",
    "    if \"FLAGS\" not in CONFIG:\n",
    "        print(\"âš ï¸ CONFIG.FLAGS missing (optional). Using defaults in code where needed.\")\n",
    "\n",
    "    # --- 4. DataFrame sanity ----------------------------------------------------\n",
    "    if \"df\" not in globals():\n",
    "        raise NameError(\"âŒ Working DataFrame 'df' not found. Run Section 1.5 first.\")\n",
    "\n",
    "    n_rows, n_cols = df.shape\n",
    "    if n_rows == 0 or n_cols == 0:\n",
    "        raise ValueError(f\"âŒ 'df' is empty, shape={df.shape}. Section 2 cannot proceed.\")\n",
    "\n",
    "    print(\"âœ… Section 2 preflight OK.\")\n",
    "    print(f\"   â€¢ df shape: {n_rows:,} rows Ã— {n_cols:,} columns\")\n",
    "    print(f\"   â€¢ PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "    print(f\"   â€¢ REPORTS_DIR:  {REPORTS_DIR}\")\n",
    "    print(f\"   â€¢ Required CONFIG roots present: {', '.join(required_roots)}\")\n",
    "\n",
    "\n",
    "# --- Run the preflight once at the top of Section 2 ----------------------------\n",
    "print(\"ğŸ“‹ 2.0A âš™ï¸ Environment & Config Readiness Check\")\n",
    "assert_config_ready_for_section2()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### How this fits your 2.0 chain\n",
    "\n",
    "With this in place, your Section 2 now flows like:\n",
    "\n",
    "1. **2.0A** â€“ Preflight\n",
    "\n",
    "   * `assert_config_ready_for_section2()`\n",
    "   * Confirms Type 3 (YAML) â†’ Type 2 (CONFIG) bridge is ready.\n",
    "\n",
    "2. **2.0.1 Reporting Bootstrap/Setup**\n",
    "\n",
    "   * Create `/resources/reports/section2/`\n",
    "   * Build unified `section2_report_path`, manifest, etc.\n",
    "\n",
    "3. **2.0.2 Config & Constants Registration**\n",
    "\n",
    "   * Use the `CONFIG`/`C()`/`target_name`/`id_cols` you already have.\n",
    "   * Build `section2_config_checks.csv` and append summary to the unified Section 2 report.\n",
    "\n",
    "4. **2.0.3 Logging & Metadata Setup**\n",
    "\n",
    "   * Create `section2.log` / `section2_run_metadata.json` in `ARTIFACTS_DIR`.\n",
    "\n",
    "Youâ€™ve now made it explicit in code that:\n",
    "\n",
    "* **Section 1 = Type 3 â†’ Type 2 layer (load & resolve)**\n",
    "* **Section 2 = consumer of config + reporter of environment health**\n",
    "\n",
    "If youâ€™d like, next step I can:\n",
    "\n",
    "* Add a small **2.0.3 Logging & Metadata Setup** block that writes a `section2_run_metadata.json` with:\n",
    "\n",
    "  * timestamp\n",
    "  * git hash (if available)\n",
    "  * script/notebook name\n",
    "  * dataset version_id from your `dataset_version_registry.csv`\n",
    "    so each Section 2 run is auditable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e308f0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "># Section 2: T3_L4 functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81311198",
   "metadata": {},
   "source": [
    "># Section 2.0.3 T3_L4 functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0.3 ğŸ§¾ Logging & Metadata Setup (Function: Use with 2.0A)\n",
    "# Purpose:\n",
    "#   Create an auditable metadata record for each Section 2 run.\n",
    "#   Captures: timestamp, git hash (if available), script/notebook name,\n",
    "#   dataset version_id (from dataset_version_registry.csv).\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“‹ 2.0.3 ğŸ§¾ Logging & Metadata Setup\")\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# --- 1ï¸âƒ£ Timestamp ---------------------------------------------------------------\n",
    "run_ts = datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
    "\n",
    "# --- 2ï¸âƒ£ Git hash (if available) --------------------------------------------------\n",
    "try:\n",
    "    git_hash = (\n",
    "        subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=PROJECT_ROOT)\n",
    "        .decode(\"utf-8\")\n",
    "        .strip()\n",
    "    )\n",
    "except Exception:\n",
    "    git_hash = None\n",
    "    print(\"âš ï¸  Git hash unavailable (not a repo or no git installed).\")\n",
    "\n",
    "# --- 3ï¸âƒ£ Notebook or script name -------------------------------------------------\n",
    "try:\n",
    "    script_name = Path(__file__).name  # works if .py\n",
    "except NameError:\n",
    "    # Fallback for Jupyter notebooks\n",
    "    import ipynbname\n",
    "    try:\n",
    "        script_name = ipynbname.name() + \".ipynb\"\n",
    "    except Exception:\n",
    "        script_name = \"unknown_notebook_or_script\"\n",
    "\n",
    "# --- 4ï¸âƒ£ Dataset version lookup --------------------------------------------------\n",
    "version_registry_path = ARTIFACTS_DIR / \"dataset_version_registry.csv\"\n",
    "version_id = None\n",
    "\n",
    "if version_registry_path.exists():\n",
    "    try:\n",
    "        reg_df = pd.read_csv(version_registry_path)\n",
    "        if not reg_df.empty:\n",
    "            version_id = str(reg_df[\"version_id\"].iloc[-1])\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not read dataset version registry: {e}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Dataset version registry not found: {version_registry_path}\")\n",
    "\n",
    "# --- 5ï¸âƒ£ Compose metadata record -------------------------------------------------\n",
    "section2_run_metadata = {\n",
    "    \"timestamp_utc\": run_ts,\n",
    "    \"git_hash\": git_hash,\n",
    "    \"script_or_notebook\": script_name,\n",
    "    \"dataset_version_id\": version_id,\n",
    "    \"project_root\": str(PROJECT_ROOT),\n",
    "    \"reports_dir\": str(REPORTS_DIR),\n",
    "    \"user\": os.getenv(\"USER\") or os.getenv(\"USERNAME\"),\n",
    "}\n",
    "\n",
    "# --- 6ï¸âƒ£ Save metadata snapshot --------------------------------------------------\n",
    "metadata_path = ARTIFACTS_DIR / \"section2_run_metadata.json\"\n",
    "\n",
    "with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(section2_run_metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Section 2 run metadata written â†’ {metadata_path}\")\n",
    "print(json.dumps(section2_run_metadata, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
