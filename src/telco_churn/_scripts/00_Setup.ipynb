{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d37e6b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"\n",
    "    cursor:pointer;background:#f7f7fb;border:10px solid #70d498ff;\n",
    "padding:10px 12px;border-radius:10px;font-weight:700;\">\n",
    "Tiny Helper Scripts (setup-only, optional)\n",
    "</summary>\n",
    "\n",
    "\n",
    "**scripts/verify_data.py** (shape + target + dtype spot-check)\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "import pandas as pd, yaml\n",
    "\n",
    "csv = Path(\"data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "schema = yaml.safe_load(Path(\"configs/schema.yaml\").read_text())\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "expected = schema[\"expected_dtypes\"]\n",
    "\n",
    "missing = [c for c in expected if c not in df.columns]\n",
    "extra = [c for c in df.columns if c not in expected]\n",
    "\n",
    "print(\"Missing columns:\", missing)\n",
    "print(\"Extra columns:\", extra)\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Target present:\", \"Churn\" in df.columns)\n",
    "```\n",
    "\n",
    "Run:\n",
    "\n",
    "```bash\n",
    "python -m scripts.check_paths\n",
    "python -m scripts.verify_data\n",
    "```\n",
    "\n",
    "## 14) Optional tiny scripts (handy helpers)\n",
    "\n",
    "`scripts/check_paths.py`\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "paths = [\"data/raw\",\"data/processed\",\"outputs/figures\",\"outputs/reports\",\"models\"]\n",
    "for p in paths:\n",
    "    print(Path(p).resolve(), \"âœ“\" if Path(p).exists() else \"âœ—\")\n",
    "```\n",
    "\n",
    "`scripts/quick_profile.py`\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "csv = Path(\"data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df = pd.read_csv(csv)\n",
    "print(df.shape)\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "```\n",
    "\n",
    "Run:\n",
    "\n",
    "```bash\n",
    "python -m scripts.check_paths\n",
    "python -m scripts.quick_profile\n",
    "```\n",
    "\n",
    "# Complete Guide: Setting Up Clean, Reusable Python Code for Data Science Projects\n",
    "## From Messy Notebooks to Production-Ready Code\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Quick Start Checklist\n",
    "\n",
    "Before diving into details, here's what you'll set up:\n",
    "- [ ] Project structure with clear separation of concerns\n",
    "- [ ] Virtual environment for dependency isolation\n",
    "- [ ] Version control with Git\n",
    "- [ ] Configuration management system\n",
    "- [ ] Logging framework\n",
    "- [ ] Testing infrastructure\n",
    "- [ ] Documentation standards\n",
    "- [ ] Code formatting and linting tools\n",
    "- [ ] Reproducibility measures\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‚ 1. Project Structure\n",
    "\n",
    "### Recommended Directory Layout\n",
    "\n",
    "```\n",
    "your-data-science-project/\n",
    "â”‚\n",
    "â”œâ”€â”€ data/                       # Data storage (gitignored)\n",
    "â”‚   â”œâ”€â”€ raw/                   # Original, immutable data\n",
    "â”‚   â”œâ”€â”€ interim/               # Intermediate transformations\n",
    "â”‚   â”œâ”€â”€ processed/             # Final, analysis-ready data\n",
    "â”‚   â””â”€â”€ external/              # External data sources\n",
    "â”‚\n",
    "â”œâ”€â”€ src/                       # Source code for the project\n",
    "â”‚   â”œâ”€â”€ __init__.py           \n",
    "â”‚   â”œâ”€â”€ data/                 # Data loading and processing\n",
    "â”‚   â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”‚   â”œâ”€â”€ load_data.py\n",
    "â”‚   â”‚   â”œâ”€â”€ clean_data.py\n",
    "â”‚   â”‚   â””â”€â”€ validate_data.py\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ features/             # Feature engineering\n",
    "â”‚   â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”‚   â”œâ”€â”€ build_features.py\n",
    "â”‚   â”‚   â””â”€â”€ feature_selection.py\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ models/               # Model training and prediction\n",
    "â”‚   â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”‚   â”œâ”€â”€ train_model.py\n",
    "â”‚   â”‚   â”œâ”€â”€ predict_model.py\n",
    "â”‚   â”‚   â””â”€â”€ evaluate_model.py\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ visualization/        # Visualization functions\n",
    "â”‚   â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”‚   â””â”€â”€ visualize.py\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ utils/                # Utility functions\n",
    "â”‚       â”œâ”€â”€ __init__.py\n",
    "â”‚       â”œâ”€â”€ config.py\n",
    "â”‚       â”œâ”€â”€ logger.py\n",
    "â”‚       â””â”€â”€ helpers.py\n",
    "â”‚\n",
    "â”œâ”€â”€ notebooks/                 # Jupyter notebooks\n",
    "â”‚   â”œâ”€â”€ 01_data_exploration.ipynb\n",
    "â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb\n",
    "â”‚   â””â”€â”€ 03_model_experiments.ipynb\n",
    "â”‚\n",
    "â”œâ”€â”€ tests/                     # Test files\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ test_data.py\n",
    "â”‚   â”œâ”€â”€ test_features.py\n",
    "â”‚   â””â”€â”€ test_models.py\n",
    "â”‚\n",
    "â”œâ”€â”€ configs/                   # Configuration files\n",
    "â”‚   â”œâ”€â”€ config.yaml           # Main configuration\n",
    "â”‚   â”œâ”€â”€ logging_config.yaml  # Logging configuration\n",
    "â”‚   â””â”€â”€ model_params.yaml     # Model parameters\n",
    "â”‚\n",
    "â”œâ”€â”€ outputs/                   # Generated outputs (gitignored)\n",
    "â”‚   â”œâ”€â”€ figures/              # Generated graphics\n",
    "â”‚   â”œâ”€â”€ models/               # Trained model files\n",
    "â”‚   â””â”€â”€ reports/              # Generated reports\n",
    "â”‚\n",
    "â”œâ”€â”€ docs/                      # Documentation\n",
    "â”‚   â”œâ”€â”€ data_dictionary.md   # Data documentation\n",
    "â”‚   â”œâ”€â”€ model_card.md        # Model documentation\n",
    "â”‚   â””â”€â”€ api_reference.md     # Code documentation\n",
    "â”‚\n",
    "â”œâ”€â”€ scripts/                   # Standalone scripts\n",
    "â”‚   â”œâ”€â”€ download_data.py\n",
    "â”‚   â”œâ”€â”€ train_pipeline.py\n",
    "â”‚   â””â”€â”€ generate_report.py\n",
    "â”‚\n",
    "â”œâ”€â”€ .env.example              # Example environment variables\n",
    "â”œâ”€â”€ .gitignore                # Git ignore file\n",
    "â”œâ”€â”€ requirements.txt          # Project dependencies\n",
    "â”œâ”€â”€ requirements-dev.txt      # Development dependencies\n",
    "â”œâ”€â”€ setup.py                  # Package setup file\n",
    "â”œâ”€â”€ README.md                 # Project documentation\n",
    "â”œâ”€â”€ Makefile                  # Automation commands\n",
    "â””â”€â”€ pyproject.toml           # Modern Python project config\n",
    "```\n",
    "\n",
    "### Creating the Structure\n",
    "\n",
    "```bash\n",
    "# Create project structure with a script\n",
    "#!/bin/bash\n",
    "# save as: create_project_structure.sh\n",
    "\n",
    "PROJECT_NAME=\"your-data-science-project\"\n",
    "\n",
    "# Create main directories\n",
    "mkdir -p $PROJECT_NAME/{data/{raw,interim,processed,external},\\\n",
    "src/{data,features,models,visualization,utils},\\\n",
    "notebooks,tests,configs,outputs/{figures,models,reports},\\\n",
    "docs,scripts}\n",
    "\n",
    "# Create __init__.py files\n",
    "find $PROJECT_NAME/src -type d -exec touch {}/__init__.py \\;\n",
    "touch $PROJECT_NAME/tests/__init__.py\n",
    "\n",
    "# Create essential files\n",
    "touch $PROJECT_NAME/{README.md,.gitignore,requirements.txt,\\\n",
    "requirements-dev.txt,setup.py,Makefile,.env.example}\n",
    "\n",
    "echo \"Project structure created for $PROJECT_NAME\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ 2. Environment Setup\n",
    "\n",
    "### Step 1: Create Virtual Environment\n",
    "\n",
    "```bash\n",
    "# Using venv (built-in)\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
    "\n",
    "# Or using conda\n",
    "conda create -n myproject python=3.9\n",
    "conda activate myproject\n",
    "\n",
    "# Or using poetry (modern approach)\n",
    "pip install poetry\n",
    "poetry new myproject\n",
    "poetry install\n",
    "```\n",
    "\n",
    "### Step 2: Requirements Management\n",
    "\n",
    "**requirements.txt** - Core dependencies\n",
    "```txt\n",
    "# Data manipulation\n",
    "pandas==2.0.3\n",
    "numpy==1.24.3\n",
    "\n",
    "# Machine learning\n",
    "scikit-learn==1.3.0\n",
    "xgboost==1.7.6\n",
    "\n",
    "# Visualization\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2\n",
    "plotly==5.15.0\n",
    "\n",
    "# Configuration\n",
    "pyyaml==6.0\n",
    "python-dotenv==1.0.0\n",
    "\n",
    "# Data validation\n",
    "great-expectations==0.17.12\n",
    "pandera==0.16.1\n",
    "\n",
    "# Utilities\n",
    "tqdm==4.65.0\n",
    "joblib==1.3.1\n",
    "```\n",
    "\n",
    "**requirements-dev.txt** - Development dependencies\n",
    "```txt\n",
    "# Testing\n",
    "pytest==7.4.0\n",
    "pytest-cov==4.1.0\n",
    "pytest-mock==3.11.1\n",
    "\n",
    "# Code quality\n",
    "black==23.7.0\n",
    "flake8==6.0.0\n",
    "pylint==2.17.4\n",
    "mypy==1.4.1\n",
    "isort==5.12.0\n",
    "\n",
    "# Pre-commit hooks\n",
    "pre-commit==3.3.3\n",
    "\n",
    "# Documentation\n",
    "sphinx==7.1.1\n",
    "sphinx-rtd-theme==1.3.0\n",
    "\n",
    "# Notebooks\n",
    "jupyter==1.0.0\n",
    "nbqa==1.7.0\n",
    "nbstripout==0.6.1\n",
    "```\n",
    "\n",
    "### Step 3: Setup Configuration\n",
    "\n",
    "**setup.py** - Make your project installable\n",
    "```python\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "with open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n",
    "    long_description = fh.read()\n",
    "\n",
    "with open(\"requirements.txt\", \"r\", encoding=\"utf-8\") as fh:\n",
    "    requirements = [line.strip() for line in fh if line.strip() and not line.startswith(\"#\")]\n",
    "\n",
    "setup(\n",
    "    name=\"your-data-science-project\",\n",
    "    version=\"0.1.0\",\n",
    "    author=\"Your Name\",\n",
    "    author_email=\"your.email@example.com\",\n",
    "    description=\"A clean data science project\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    url=\"https://github.com/yourusername/your-project\",\n",
    "    packages=find_packages(where=\"src\"),\n",
    "    package_dir={\"\": \"src\"},\n",
    "    classifiers=[\n",
    "        \"Development Status :: 3 - Alpha\",\n",
    "        \"Intended Audience :: Developers\",\n",
    "        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"Programming Language :: Python :: 3.8\",\n",
    "        \"Programming Language :: Python :: 3.9\",\n",
    "        \"Programming Language :: Python :: 3.10\",\n",
    "    ],\n",
    "    python_requires=\">=3.8\",\n",
    "    install_requires=requirements,\n",
    "    extras_require={\n",
    "        \"dev\": [\"pytest>=7.0\", \"black>=23.0\", \"flake8>=6.0\"],\n",
    "    },\n",
    "    entry_points={\n",
    "        \"console_scripts\": [\n",
    "            \"train-model=scripts.train_pipeline:main\",\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Install in development mode\n",
    "# pip install -e .\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ 3. Code Organization Principles\n",
    "\n",
    "### 3.1 Data Module Structure\n",
    "\n",
    "**src/data/load_data.py**\n",
    "```python\n",
    "\"\"\"Data loading module with validation and caching.\"\"\"\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from functools import lru_cache\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Handle data loading with validation and caching.\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = \"configs/config.yaml\"):\n",
    "        \"\"\"Initialize with configuration.\"\"\"\n",
    "        self.config = self._load_config(config_path)\n",
    "        self.data_dir = Path(self.config['data']['base_dir'])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_config(config_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Load configuration from YAML file.\"\"\"\n",
    "        with open(config_path, 'r') as f:\n",
    "            return yaml.safe_load(f)\n",
    "    \n",
    "    @lru_cache(maxsize=1)\n",
    "    def load_raw_data(self, \n",
    "                     filename: str,\n",
    "                     validate: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load raw data with caching and validation.\n",
    "        \n",
    "        Args:\n",
    "            filename: Name of the file to load\n",
    "            validate: Whether to validate data after loading\n",
    "            \n",
    "        Returns:\n",
    "            Loaded DataFrame\n",
    "            \n",
    "        Raises:\n",
    "            FileNotFoundError: If file doesn't exist\n",
    "            ValueError: If validation fails\n",
    "        \"\"\"\n",
    "        filepath = self.data_dir / 'raw' / filename\n",
    "        \n",
    "        if not filepath.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "        \n",
    "        logger.info(f\"Loading data from {filepath}\")\n",
    "        \n",
    "        # Detect file type and load accordingly\n",
    "        if filepath.suffix == '.csv':\n",
    "            df = pd.read_csv(filepath, **self.config['data'].get('csv_params', {}))\n",
    "        elif filepath.suffix == '.parquet':\n",
    "            df = pd.read_parquet(filepath)\n",
    "        elif filepath.suffix in ['.xlsx', '.xls']:\n",
    "            df = pd.read_excel(filepath)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {filepath.suffix}\")\n",
    "        \n",
    "        logger.info(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "        \n",
    "        if validate:\n",
    "            self._validate_data(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _validate_data(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Validate loaded data against schema.\"\"\"\n",
    "        required_columns = self.config['data'].get('required_columns', [])\n",
    "        \n",
    "        missing = set(required_columns) - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n",
    "        \n",
    "        # Additional validation\n",
    "        if df.empty:\n",
    "            raise ValueError(\"DataFrame is empty\")\n",
    "        \n",
    "        if df.duplicated().any():\n",
    "            logger.warning(f\"Found {df.duplicated().sum()} duplicate rows\")\n",
    "        \n",
    "        logger.info(\"Data validation passed\")\n",
    "    \n",
    "    def save_processed_data(self, \n",
    "                           df: pd.DataFrame, \n",
    "                           filename: str,\n",
    "                           compress: bool = True) -> None:\n",
    "        \"\"\"Save processed data efficiently.\"\"\"\n",
    "        filepath = self.data_dir / 'processed' / filename\n",
    "        \n",
    "        if compress and not filename.endswith('.parquet'):\n",
    "            filepath = filepath.with_suffix('.parquet')\n",
    "            df.to_parquet(filepath, compression='snappy')\n",
    "        else:\n",
    "            df.to_csv(filepath, index=False)\n",
    "        \n",
    "        logger.info(f\"Saved processed data to {filepath}\")\n",
    "```\n",
    "\n",
    "### 3.2 Feature Engineering Module\n",
    "\n",
    "**src/features/build_features.py**\n",
    "```python\n",
    "\"\"\"Feature engineering with pipeline approach.\"\"\"\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FeatureEngineer:\n",
    "    \"\"\"Centralized feature engineering.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict):\n",
    "        \"\"\"Initialize with configuration.\"\"\"\n",
    "        self.config = config\n",
    "        self.feature_pipeline = None\n",
    "        self.feature_names = []\n",
    "    \n",
    "    def create_features(self, \n",
    "                       df: pd.DataFrame,\n",
    "                       target_col: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create all features for the dataset.\n",
    "        \n",
    "        Args:\n",
    "            df: Input DataFrame\n",
    "            target_col: Target column to exclude from features\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with engineered features\n",
    "        \"\"\"\n",
    "        df_features = df.copy()\n",
    "        \n",
    "        # Temporal features\n",
    "        if self.config.get('create_temporal_features', True):\n",
    "            df_features = self._create_temporal_features(df_features)\n",
    "        \n",
    "        # Aggregation features\n",
    "        if self.config.get('create_aggregation_features', True):\n",
    "            df_features = self._create_aggregation_features(df_features)\n",
    "        \n",
    "        # Interaction features\n",
    "        if self.config.get('create_interaction_features', True):\n",
    "            df_features = self._create_interaction_features(df_features)\n",
    "        \n",
    "        # Log transform skewed features\n",
    "        if self.config.get('log_transform_skewed', True):\n",
    "            df_features = self._log_transform_skewed_features(df_features)\n",
    "        \n",
    "        # Record feature names\n",
    "        self.feature_names = [col for col in df_features.columns \n",
    "                             if col != target_col]\n",
    "        \n",
    "        logger.info(f\"Created {len(self.feature_names)} features\")\n",
    "        \n",
    "        return df_features\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create time-based features.\"\"\"\n",
    "        date_columns = df.select_dtypes(include=['datetime64']).columns\n",
    "        \n",
    "        for col in date_columns:\n",
    "            df[f'{col}_year'] = df[col].dt.year\n",
    "            df[f'{col}_month'] = df[col].dt.month\n",
    "            df[f'{col}_day'] = df[col].dt.day\n",
    "            df[f'{col}_dayofweek'] = df[col].dt.dayofweek\n",
    "            df[f'{col}_quarter'] = df[col].dt.quarter\n",
    "            df[f'{col}_is_weekend'] = df[col].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _create_aggregation_features(self, \n",
    "                                    df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create aggregation-based features.\"\"\"\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        if len(numerical_cols) > 1:\n",
    "            # Statistical aggregations\n",
    "            df['numerical_mean'] = df[numerical_cols].mean(axis=1)\n",
    "            df['numerical_std'] = df[numerical_cols].std(axis=1)\n",
    "            df['numerical_max'] = df[numerical_cols].max(axis=1)\n",
    "            df['numerical_min'] = df[numerical_cols].min(axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_interaction_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create interaction features between columns.\"\"\"\n",
    "        # Example: Create ratios for numerical columns\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for i, col1 in enumerate(numerical_cols):\n",
    "            for col2 in numerical_cols[i+1:]:\n",
    "                # Avoid division by zero\n",
    "                if (df[col2] != 0).any():\n",
    "                    df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-8)\n",
    "                    df[f'{col1}_mult_{col2}'] = df[col1] * df[col2]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def _log_transform_skewed_features(df: pd.DataFrame, \n",
    "                                      threshold: float = 0.75) -> pd.DataFrame:\n",
    "        \"\"\"Apply log transformation to skewed features.\"\"\"\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numerical_cols:\n",
    "            skewness = df[col].skew()\n",
    "            if abs(skewness) > threshold:\n",
    "                if (df[col] > 0).all():  # Only if all values are positive\n",
    "                    df[f'{col}_log'] = np.log1p(df[col])\n",
    "                    logger.debug(f\"Log transformed {col} (skewness: {skewness:.2f})\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom sklearn transformer for pipeline integration.\"\"\"\n",
    "    \n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.function(X)\n",
    "```\n",
    "\n",
    "### 3.3 Model Module\n",
    "\n",
    "**src/models/train_model.py**\n",
    "```python\n",
    "\"\"\"Model training with experiment tracking.\"\"\"\n",
    "\n",
    "import logging\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Handle model training with tracking and versioning.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_config: Dict[str, Any],\n",
    "                 experiment_name: str = \"default_experiment\"):\n",
    "        \"\"\"Initialize trainer with configuration.\"\"\"\n",
    "        self.config = model_config\n",
    "        self.experiment_name = experiment_name\n",
    "        self.model = None\n",
    "        self.metrics = {}\n",
    "        \n",
    "        # Setup MLflow\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    def train(self,\n",
    "             X_train: pd.DataFrame,\n",
    "             y_train: pd.Series,\n",
    "             X_val: Optional[pd.DataFrame] = None,\n",
    "             y_val: Optional[pd.Series] = None) -> Any:\n",
    "        \"\"\"\n",
    "        Train model with experiment tracking.\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training features\n",
    "            y_train: Training target\n",
    "            X_val: Validation features (optional)\n",
    "            y_val: Validation target (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Trained model\n",
    "        \"\"\"\n",
    "        with mlflow.start_run():\n",
    "            # Log parameters\n",
    "            mlflow.log_params(self.config['model_params'])\n",
    "            \n",
    "            # Initialize model\n",
    "            model_class = self._get_model_class()\n",
    "            self.model = model_class(**self.config['model_params'])\n",
    "            \n",
    "            # Train model\n",
    "            logger.info(f\"Training {self.config['model_type']} model\")\n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate model\n",
    "            if X_val is not None and y_val is not None:\n",
    "                self.metrics = self._evaluate_model(X_val, y_val)\n",
    "                \n",
    "                # Log metrics\n",
    "                for metric_name, metric_value in self.metrics.items():\n",
    "                    mlflow.log_metric(metric_name, metric_value)\n",
    "            \n",
    "            # Cross-validation\n",
    "            if self.config.get('cross_validate', True):\n",
    "                cv_scores = self._cross_validate(X_train, y_train)\n",
    "                mlflow.log_metric('cv_mean_score', cv_scores.mean())\n",
    "                mlflow.log_metric('cv_std_score', cv_scores.std())\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(\n",
    "                self.model,\n",
    "                \"model\",\n",
    "                registered_model_name=f\"{self.experiment_name}_model\"\n",
    "            )\n",
    "            \n",
    "            # Save model locally\n",
    "            self._save_model()\n",
    "            \n",
    "            logger.info(f\"Training completed. Metrics: {self.metrics}\")\n",
    "            \n",
    "        return self.model\n",
    "    \n",
    "    def _get_model_class(self):\n",
    "        \"\"\"Get model class from configuration.\"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from xgboost import XGBClassifier\n",
    "        \n",
    "        model_classes = {\n",
    "            'random_forest': RandomForestClassifier,\n",
    "            'gradient_boosting': GradientBoostingClassifier,\n",
    "            'logistic_regression': LogisticRegression,\n",
    "            'xgboost': XGBClassifier\n",
    "        }\n",
    "        \n",
    "        model_type = self.config['model_type']\n",
    "        if model_type not in model_classes:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        return model_classes[model_type]\n",
    "    \n",
    "    def _evaluate_model(self, \n",
    "                       X_val: pd.DataFrame, \n",
    "                       y_val: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"Evaluate model performance.\"\"\"\n",
    "        from sklearn.metrics import (\n",
    "            accuracy_score, precision_score, recall_score,\n",
    "            f1_score, roc_auc_score\n",
    "        )\n",
    "        \n",
    "        y_pred = self.model.predict(X_val)\n",
    "        y_proba = self.model.predict_proba(X_val)[:, 1] if hasattr(self.model, 'predict_proba') else None\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_val, y_pred),\n",
    "            'precision': precision_score(y_val, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_val, y_pred, average='weighted'),\n",
    "            'f1': f1_score(y_val, y_pred, average='weighted')\n",
    "        }\n",
    "        \n",
    "        if y_proba is not None and len(np.unique(y_val)) == 2:\n",
    "            metrics['roc_auc'] = roc_auc_score(y_val, y_proba)\n",
    "        \n",
    "        # Log confusion matrix\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        logger.info(f\"Confusion Matrix:\\n{cm}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _cross_validate(self, \n",
    "                       X: pd.DataFrame, \n",
    "                       y: pd.Series,\n",
    "                       cv: int = 5) -> np.ndarray:\n",
    "        \"\"\"Perform cross-validation.\"\"\"\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(\n",
    "            self.model, X, y, \n",
    "            cv=skf, \n",
    "            scoring=self.config.get('scoring', 'accuracy')\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Cross-validation scores: {scores}\")\n",
    "        logger.info(f\"Mean CV score: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def _save_model(self) -> None:\n",
    "        \"\"\"Save model and metadata.\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        model_path = f\"outputs/models/model_{timestamp}.pkl\"\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(self.model, model_path)\n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'timestamp': timestamp,\n",
    "            'model_type': self.config['model_type'],\n",
    "            'parameters': self.config['model_params'],\n",
    "            'metrics': self.metrics,\n",
    "            'feature_names': self.config.get('feature_names', [])\n",
    "        }\n",
    "        \n",
    "        metadata_path = f\"outputs/models/metadata_{timestamp}.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"Metadata saved to {metadata_path}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” 4. Configuration Management\n",
    "\n",
    "### 4.1 Main Configuration File\n",
    "\n",
    "**configs/config.yaml**\n",
    "```yaml\n",
    "# Project configuration\n",
    "project:\n",
    "  name: \"telco-churn-analysis\"\n",
    "  version: \"1.0.0\"\n",
    "  description: \"Customer churn prediction\"\n",
    "  author: \"Your Name\"\n",
    "\n",
    "# Data configuration\n",
    "data:\n",
    "  base_dir: \"data\"\n",
    "  raw_file: \"telco_customer_churn.csv\"\n",
    "  processed_file: \"telco_processed.parquet\"\n",
    "  \n",
    "  # Column definitions\n",
    "  target_column: \"Churn\"\n",
    "  id_column: \"customerID\"\n",
    "  \n",
    "  # Required columns for validation\n",
    "  required_columns:\n",
    "    - customerID\n",
    "    - gender\n",
    "    - tenure\n",
    "    - MonthlyCharges\n",
    "    - TotalCharges\n",
    "    - Churn\n",
    "  \n",
    "  # CSV reading parameters\n",
    "  csv_params:\n",
    "    encoding: \"utf-8\"\n",
    "    sep: \",\"\n",
    "    na_values: [\"\", \" \", \"NA\", \"N/A\", \"null\"]\n",
    "\n",
    "# Feature engineering configuration\n",
    "features:\n",
    "  create_temporal_features: true\n",
    "  create_aggregation_features: true\n",
    "  create_interaction_features: true\n",
    "  log_transform_skewed: true\n",
    "  \n",
    "  # Categorical encoding\n",
    "  encoding_method: \"one_hot\"  # options: one_hot, label, target\n",
    "  \n",
    "  # Feature selection\n",
    "  selection_method: \"mutual_info\"  # options: mutual_info, chi2, anova\n",
    "  n_features_to_select: 20\n",
    "\n",
    "# Model configuration\n",
    "model:\n",
    "  model_type: \"xgboost\"  # options: random_forest, xgboost, logistic_regression\n",
    "  \n",
    "  # Model parameters\n",
    "  model_params:\n",
    "    n_estimators: 100\n",
    "    max_depth: 5\n",
    "    learning_rate: 0.1\n",
    "    random_state: 42\n",
    "  \n",
    "  # Training configuration\n",
    "  test_size: 0.2\n",
    "  validation_size: 0.2\n",
    "  cross_validate: true\n",
    "  cv_folds: 5\n",
    "  scoring: \"roc_auc\"\n",
    "  \n",
    "  # Hyperparameter tuning\n",
    "  hyperparameter_tuning:\n",
    "    enabled: true\n",
    "    method: \"grid_search\"  # options: grid_search, random_search, bayesian\n",
    "    n_iter: 50  # for random search\n",
    "    param_grid:\n",
    "      n_estimators: [50, 100, 200]\n",
    "      max_depth: [3, 5, 7]\n",
    "      learning_rate: [0.01, 0.1, 0.3]\n",
    "\n",
    "# Paths\n",
    "paths:\n",
    "  logs: \"logs\"\n",
    "  outputs: \"outputs\"\n",
    "  models: \"outputs/models\"\n",
    "  figures: \"outputs/figures\"\n",
    "  reports: \"outputs/reports\"\n",
    "\n",
    "# Logging configuration\n",
    "logging:\n",
    "  level: \"INFO\"\n",
    "  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "  file: \"logs/project.log\"\n",
    "```\n",
    "\n",
    "### 4.2 Environment Variables\n",
    "\n",
    "**.env.example**\n",
    "```bash\n",
    "# Database connections\n",
    "DB_HOST=localhost\n",
    "DB_PORT=5432\n",
    "DB_NAME=myproject\n",
    "DB_USER=username\n",
    "DB_PASSWORD=password\n",
    "\n",
    "# API Keys\n",
    "API_KEY=your-api-key-here\n",
    "SECRET_KEY=your-secret-key-here\n",
    "\n",
    "# Cloud storage\n",
    "AWS_ACCESS_KEY_ID=your-access-key\n",
    "AWS_SECRET_ACCESS_KEY=your-secret-key\n",
    "S3_BUCKET=your-bucket-name\n",
    "\n",
    "# MLflow tracking\n",
    "MLFLOW_TRACKING_URI=http://localhost:5000\n",
    "MLFLOW_EXPERIMENT_NAME=telco_churn\n",
    "\n",
    "# Environment\n",
    "ENVIRONMENT=development  # development, staging, production\n",
    "DEBUG=True\n",
    "```\n",
    "\n",
    "### 4.3 Configuration Loader\n",
    "\n",
    "**src/utils/config.py**\n",
    "```python\n",
    "\"\"\"Configuration management utilities.\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration management.\"\"\"\n",
    "    \n",
    "    _instance = None\n",
    "    \n",
    "    def __new__(cls):\n",
    "        \"\"\"Singleton pattern for configuration.\"\"\"\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super().__new__(cls)\n",
    "            cls._instance._initialized = False\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize configuration.\"\"\"\n",
    "        if self._initialized:\n",
    "            return\n",
    "        \n",
    "        self._initialized = True\n",
    "        self.project_root = Path(__file__).parent.parent.parent\n",
    "        \n",
    "        # Load environment variables\n",
    "        self._load_env()\n",
    "        \n",
    "        # Load YAML configuration\n",
    "        self.config = self._load_yaml_config()\n",
    "        \n",
    "        # Override with environment variables\n",
    "        self._override_with_env()\n",
    "        \n",
    "    def _load_env(self) -> None:\n",
    "        \"\"\"Load environment variables from .env file.\"\"\"\n",
    "        env_file = self.project_root / '.env'\n",
    "        if env_file.exists():\n",
    "            load_dotenv(env_file)\n",
    "            logger.info(f\"Loaded environment variables from {env_file}\")\n",
    "    \n",
    "    def _load_yaml_config(self, \n",
    "                         config_file: str = 'configs/config.yaml') -> Dict[str, Any]:\n",
    "        \"\"\"Load YAML configuration file.\"\"\"\n",
    "        config_path = self.project_root / config_file\n",
    "        \n",
    "        if not config_path.exists():\n",
    "            logger.warning(f\"Config file not found: {config_path}\")\n",
    "            return {}\n",
    "        \n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        \n",
    "        logger.info(f\"Loaded configuration from {config_path}\")\n",
    "        return config\n",
    "    \n",
    "    def _override_with_env(self) -> None:\n",
    "        \"\"\"Override configuration with environment variables.\"\"\"\n",
    "        # Example: Override database configuration\n",
    "        if os.getenv('DB_HOST'):\n",
    "            self.config.setdefault('database', {})['host'] = os.getenv('DB_HOST')\n",
    "        \n",
    "        if os.getenv('ENVIRONMENT'):\n",
    "            self.config['environment'] = os.getenv('ENVIRONMENT')\n",
    "    \n",
    "    def get(self, key: str, default: Any = None) -> Any:\n",
    "        \"\"\"Get configuration value by key (supports nested keys).\"\"\"\n",
    "        keys = key.split('.')\n",
    "        value = self.config\n",
    "        \n",
    "        for k in keys:\n",
    "            if isinstance(value, dict):\n",
    "                value = value.get(k)\n",
    "            else:\n",
    "                return default\n",
    "            \n",
    "            if value is None:\n",
    "                return default\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    @property\n",
    "    def data_dir(self) -> Path:\n",
    "        \"\"\"Get data directory path.\"\"\"\n",
    "        return self.project_root / self.get('data.base_dir', 'data')\n",
    "    \n",
    "    @property\n",
    "    def output_dir(self) -> Path:\n",
    "        \"\"\"Get output directory path.\"\"\"\n",
    "        return self.project_root / self.get('paths.outputs', 'outputs')\n",
    "    \n",
    "    def get_model_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get model parameters.\"\"\"\n",
    "        return self.get('model.model_params', {})\n",
    "\n",
    "# Create global config instance\n",
    "config = Config()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š 5. Logging Setup\n",
    "\n",
    "**src/utils/logger.py**\n",
    "```python\n",
    "\"\"\"Logging configuration and utilities.\"\"\"\n",
    "\n",
    "import logging\n",
    "import logging.config\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "def setup_logging(\n",
    "    config_path: Optional[str] = None,\n",
    "    default_level: int = logging.INFO,\n",
    "    log_dir: str = \"logs\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Setup logging configuration.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path to logging configuration file\n",
    "        default_level: Default logging level\n",
    "        log_dir: Directory for log files\n",
    "    \"\"\"\n",
    "    # Create log directory\n",
    "    Path(log_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    if config_path and Path(config_path).exists():\n",
    "        # Load from configuration file\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        logging.config.dictConfig(config)\n",
    "    else:\n",
    "        # Default configuration\n",
    "        log_file = Path(log_dir) / f\"app_{datetime.now():%Y%m%d}.log\"\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=default_level,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # Reduce noise from third-party libraries\n",
    "    logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "    logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Logging initialized\")\n",
    "\n",
    "class LoggerMixin:\n",
    "    \"\"\"Mixin to add logging to any class.\"\"\"\n",
    "    \n",
    "    @property\n",
    "    def logger(self):\n",
    "        \"\"\"Get logger for the class.\"\"\"\n",
    "        name = '.'.join([\n",
    "            self.__class__.__module__,\n",
    "            self.__class__.__name__\n",
    "        ])\n",
    "        return logging.getLogger(name)\n",
    "\n",
    "# Logging configuration file\n",
    "# configs/logging_config.yaml\n",
    "\"\"\"\n",
    "version: 1\n",
    "disable_existing_loggers: false\n",
    "\n",
    "formatters:\n",
    "  default:\n",
    "    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "  detailed:\n",
    "    format: '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    "\n",
    "handlers:\n",
    "  console:\n",
    "    class: logging.StreamHandler\n",
    "    level: INFO\n",
    "    formatter: default\n",
    "    stream: ext://sys.stdout\n",
    "  \n",
    "  file:\n",
    "    class: logging.handlers.RotatingFileHandler\n",
    "    level: DEBUG\n",
    "    formatter: detailed\n",
    "    filename: logs/app.log\n",
    "    maxBytes: 10485760  # 10MB\n",
    "    backupCount: 5\n",
    "  \n",
    "  error_file:\n",
    "    class: logging.handlers.RotatingFileHandler\n",
    "    level: ERROR\n",
    "    formatter: detailed\n",
    "    filename: logs/errors.log\n",
    "    maxBytes: 10485760  # 10MB\n",
    "    backupCount: 5\n",
    "\n",
    "loggers:\n",
    "  src:\n",
    "    level: DEBUG\n",
    "    handlers: [console, file]\n",
    "    propagate: no\n",
    "  \n",
    "  src.models:\n",
    "    level: INFO\n",
    "    handlers: [console, file]\n",
    "    propagate: no\n",
    "\n",
    "root:\n",
    "  level: INFO\n",
    "  handlers: [console, file, error_file]\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª 6. Testing Infrastructure\n",
    "\n",
    "### 6.1 Test Structure\n",
    "\n",
    "**tests/test_data.py**\n",
    "```python\n",
    "\"\"\"Tests for data module.\"\"\"\n",
    "\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "from src.data.load_data import DataLoader\n",
    "from src.data.clean_data import DataCleaner\n",
    "\n",
    "class TestDataLoader:\n",
    "    \"\"\"Test data loading functionality.\"\"\"\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def sample_data(self):\n",
    "        \"\"\"Create sample data for testing.\"\"\"\n",
    "        return pd.DataFrame({\n",
    "            'id': range(1, 101),\n",
    "            'value': np.random.randn(100),\n",
    "            'category': np.random.choice(['A', 'B', 'C'], 100)\n",
    "        })\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def temp_csv_file(self, sample_data):\n",
    "        \"\"\"Create temporary CSV file.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:\n",
    "            sample_data.to_csv(f, index=False)\n",
    "            return f.name\n",
    "    \n",
    "    def test_load_csv_file(self, temp_csv_file):\n",
    "        \"\"\"Test loading CSV file.\"\"\"\n",
    "        loader = DataLoader()\n",
    "        df = loader.load_raw_data(Path(temp_csv_file).name)\n",
    "        \n",
    "        assert df is not None\n",
    "        assert len(df) == 100\n",
    "        assert list(df.columns) == ['id', 'value', 'category']\n",
    "    \n",
    "    def test_load_nonexistent_file(self):\n",
    "        \"\"\"Test loading non-existent file raises error.\"\"\"\n",
    "        loader = DataLoader()\n",
    "        \n",
    "        with pytest.raises(FileNotFoundError):\n",
    "            loader.load_raw_data('nonexistent.csv')\n",
    "    \n",
    "    def test_validate_data_with_missing_columns(self, sample_data):\n",
    "        \"\"\"Test validation with missing required columns.\"\"\"\n",
    "        loader = DataLoader()\n",
    "        loader.config = {'data': {'required_columns': ['id', 'missing_column']}}\n",
    "        \n",
    "        with pytest.raises(ValueError, match=\"Missing required columns\"):\n",
    "            loader._validate_data(sample_data)\n",
    "    \n",
    "    @pytest.mark.parametrize(\"file_extension,reader_method\", [\n",
    "        ('.csv', 'read_csv'),\n",
    "        ('.parquet', 'read_parquet'),\n",
    "        ('.xlsx', 'read_excel')\n",
    "    ])\n",
    "    def test_file_type_detection(self, file_extension, reader_method, monkeypatch):\n",
    "        \"\"\"Test correct reader is used for different file types.\"\"\"\n",
    "        loader = DataLoader()\n",
    "        \n",
    "        # Mock the reader methods\n",
    "        mock_called = {'called': False}\n",
    "        \n",
    "        def mock_reader(*args, **kwargs):\n",
    "            mock_called['called'] = True\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        monkeypatch.setattr(pd, reader_method, mock_reader)\n",
    "        \n",
    "        # This would need actual implementation in the loader\n",
    "        # Just showing the test structure\n",
    "\n",
    "class TestDataCleaner:\n",
    "    \"\"\"Test data cleaning functionality.\"\"\"\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def dirty_data(self):\n",
    "        \"\"\"Create data with quality issues.\"\"\"\n",
    "        return pd.DataFrame({\n",
    "            'id': [1, 2, 2, 3, 4],  # Duplicate\n",
    "            'value': [10, 20, 20, None, 40],  # Missing value\n",
    "            'text': ['  hello  ', 'WORLD', 'Test', None, '  ']  # Needs cleaning\n",
    "        })\n",
    "    \n",
    "    def test_remove_duplicates(self, dirty_data):\n",
    "        \"\"\"Test duplicate removal.\"\"\"\n",
    "        cleaner = DataCleaner()\n",
    "        cleaned = cleaner.remove_duplicates(dirty_data)\n",
    "        \n",
    "        assert len(cleaned) == 4\n",
    "        assert not cleaned.duplicated().any()\n",
    "    \n",
    "    def test_handle_missing_values(self, dirty_data):\n",
    "        \"\"\"Test missing value handling.\"\"\"\n",
    "        cleaner = DataCleaner()\n",
    "        \n",
    "        # Test different strategies\n",
    "        filled = cleaner.handle_missing(dirty_data, strategy='mean')\n",
    "        assert filled['value'].isna().sum() == 0\n",
    "        \n",
    "        dropped = cleaner.handle_missing(dirty_data, strategy='drop')\n",
    "        assert len(dropped) == 3\n",
    "    \n",
    "    def test_clean_text_columns(self, dirty_data):\n",
    "        \"\"\"Test text cleaning.\"\"\"\n",
    "        cleaner = DataCleaner()\n",
    "        cleaned = cleaner.clean_text(dirty_data, columns=['text'])\n",
    "        \n",
    "        assert cleaned['text'].iloc[0] == 'hello'\n",
    "        assert cleaned['text'].iloc[1] == 'world'\n",
    "        assert cleaned['text'].iloc[4] == ''\n",
    "```\n",
    "\n",
    "### 6.2 Test Configuration\n",
    "\n",
    "**pytest.ini**\n",
    "```ini\n",
    "[pytest]\n",
    "testpaths = tests\n",
    "python_files = test_*.py\n",
    "python_classes = Test*\n",
    "python_functions = test_*\n",
    "addopts = \n",
    "    -v\n",
    "    --cov=src\n",
    "    --cov-report=html\n",
    "    --cov-report=term-missing\n",
    "    --tb=short\n",
    "    --strict-markers\n",
    "markers =\n",
    "    slow: marks tests as slow (deselect with '-m \"not slow\"')\n",
    "    integration: marks tests as integration tests\n",
    "    unit: marks tests as unit tests\n",
    "```\n",
    "\n",
    "**conftest.py**\n",
    "```python\n",
    "\"\"\"Shared test fixtures and configuration.\"\"\"\n",
    "\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))\n",
    "\n",
    "@pytest.fixture(scope='session')\n",
    "def test_data_dir():\n",
    "    \"\"\"Get test data directory.\"\"\"\n",
    "    return Path(__file__).parent / 'test_data'\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_telco_data():\n",
    "    \"\"\"Create sample telco churn data.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'customerID': [f'ID_{i:04d}' for i in range(n_samples)],\n",
    "        'tenure': np.random.randint(0, 72, n_samples),\n",
    "        'MonthlyCharges': np.random.uniform(20, 120, n_samples),\n",
    "        'TotalCharges': np.random.uniform(100, 8000, n_samples),\n",
    "        'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples),\n",
    "        'PaymentMethod': np.random.choice([\n",
    "            'Electronic check', 'Mailed check', \n",
    "            'Bank transfer', 'Credit card'\n",
    "        ], n_samples),\n",
    "        'Churn': np.random.choice(['Yes', 'No'], n_samples, p=[0.3, 0.7])\n",
    "    })\n",
    "\n",
    "@pytest.fixture(autouse=True)\n",
    "def reset_singleton():\n",
    "    \"\"\"Reset singleton instances between tests.\"\"\"\n",
    "    from src.utils.config import Config\n",
    "    Config._instance = None\n",
    "    yield\n",
    "    Config._instance = None\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¨ 7. Code Quality Tools\n",
    "\n",
    "### 7.1 Pre-commit Configuration\n",
    "\n",
    "**.pre-commit-config.yaml**\n",
    "```yaml\n",
    "repos:\n",
    "  # Remove trailing whitespace\n",
    "  - repo: https://github.com/pre-commit/pre-commit-hooks\n",
    "    rev: v4.4.0\n",
    "    hooks:\n",
    "      - id: trailing-whitespace\n",
    "      - id: end-of-file-fixer\n",
    "      - id: check-yaml\n",
    "      - id: check-added-large-files\n",
    "        args: ['--maxkb=1000']\n",
    "      - id: check-json\n",
    "      - id: check-merge-conflict\n",
    "      - id: debug-statements\n",
    "\n",
    "  # Black formatting\n",
    "  - repo: https://github.com/psf/black\n",
    "    rev: 23.7.0\n",
    "    hooks:\n",
    "      - id: black\n",
    "        language_version: python3.9\n",
    "\n",
    "  # isort import sorting\n",
    "  - repo: https://github.com/PyCQA/isort\n",
    "    rev: 5.12.0\n",
    "    hooks:\n",
    "      - id: isort\n",
    "        args: [\"--profile\", \"black\"]\n",
    "\n",
    "  # Flake8 linting\n",
    "  - repo: https://github.com/PyCQA/flake8\n",
    "    rev: 6.0.0\n",
    "    hooks:\n",
    "      - id: flake8\n",
    "        args: ['--max-line-length=100', '--ignore=E203,W503']\n",
    "\n",
    "  # Type checking with mypy\n",
    "  - repo: https://github.com/pre-commit/mirrors-mypy\n",
    "    rev: v1.4.1\n",
    "    hooks:\n",
    "      - id: mypy\n",
    "        additional_dependencies: [types-all]\n",
    "        args: [--ignore-missing-imports]\n",
    "\n",
    "  # Jupyter notebook cleaning\n",
    "  - repo: https://github.com/kynan/nbstripout\n",
    "    rev: 0.6.1\n",
    "    hooks:\n",
    "      - id: nbstripout\n",
    "\n",
    "# Install pre-commit hooks\n",
    "# pre-commit install\n",
    "```\n",
    "\n",
    "### 7.2 Makefile for Automation\n",
    "\n",
    "**Makefile**\n",
    "```makefile\n",
    ".PHONY: help setup test clean lint format run\n",
    "\n",
    "help:\n",
    "\t@echo \"Available commands:\"\n",
    "\t@echo \"  make setup    - Set up the development environment\"\n",
    "\t@echo \"  make test     - Run tests\"\n",
    "\t@echo \"  make lint     - Run linting\"\n",
    "\t@echo \"  make format   - Format code\"\n",
    "\t@echo \"  make clean    - Clean up temporary files\"\n",
    "\t@echo \"  make run      - Run the main pipeline\"\n",
    "\n",
    "setup:\n",
    "\tpython -m venv venv\n",
    "\t. venv/bin/activate && pip install --upgrade pip\n",
    "\t. venv/bin/activate && pip install -r requirements.txt\n",
    "\t. venv/bin/activate && pip install -r requirements-dev.txt\n",
    "\t. venv/bin/activate && pip install -e .\n",
    "\t. venv/bin/activate && pre-commit install\n",
    "\t@echo \"Setup complete! Activate with: source venv/bin/activate\"\n",
    "\n",
    "test:\n",
    "\tpytest tests/ -v --cov=src --cov-report=html\n",
    "\n",
    "lint:\n",
    "\tflake8 src/ tests/\n",
    "\tpylint src/\n",
    "\tmypy src/\n",
    "\n",
    "format:\n",
    "\tblack src/ tests/\n",
    "\tisort src/ tests/\n",
    "\n",
    "clean:\n",
    "\tfind . -type f -name \"*.pyc\" -delete\n",
    "\tfind . -type d -name \"__pycache__\" -delete\n",
    "\tfind . -type d -name \"*.egg-info\" -exec rm -rf {} + 2>/dev/null || true\n",
    "\trm -rf .pytest_cache\n",
    "\trm -rf .coverage\n",
    "\trm -rf htmlcov\n",
    "\trm -rf .mypy_cache\n",
    "\n",
    "run:\n",
    "\tpython scripts/train_pipeline.py\n",
    "\n",
    "# Data pipeline commands\n",
    "data-download:\n",
    "\tpython scripts/download_data.py\n",
    "\n",
    "data-process:\n",
    "\tpython scripts/process_data.py\n",
    "\n",
    "# Model commands\n",
    "train:\n",
    "\tpython scripts/train_model.py\n",
    "\n",
    "evaluate:\n",
    "\tpython scripts/evaluate_model.py\n",
    "\n",
    "predict:\n",
    "\tpython scripts/predict.py\n",
    "\n",
    "# Docker commands\n",
    "docker-build:\n",
    "\tdocker build -t $(PROJECT_NAME) .\n",
    "\n",
    "docker-run:\n",
    "\tdocker run -it --rm -v $(PWD):/app $(PROJECT_NAME)\n",
    "\n",
    "# Documentation\n",
    "docs:\n",
    "\tsphinx-build -b html docs/ docs/_build\n",
    "\n",
    "# Quality checks\n",
    "quality-check: lint test\n",
    "\t@echo \"All quality checks passed!\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š 8. Documentation Standards\n",
    "\n",
    "### 8.1 README Template\n",
    "\n",
    "**README.md**\n",
    "```markdown\n",
    "# Project Name\n",
    "\n",
    "Brief description of what the project does and its purpose.\n",
    "\n",
    "## ðŸš€ Quick Start\n",
    "\n",
    "```bash\n",
    "# Clone the repository\n",
    "git clone https://github.com/username/project.git\n",
    "cd project\n",
    "\n",
    "# Set up environment\n",
    "make setup\n",
    "\n",
    "# Run the pipeline\n",
    "make run\n",
    "```\n",
    "\n",
    "## ðŸ“‹ Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Virtual environment tool (venv, conda, or poetry)\n",
    "- Git\n",
    "\n",
    "## ðŸ› ï¸ Installation\n",
    "\n",
    "### Option 1: Using Make\n",
    "```bash\n",
    "make setup\n",
    "```\n",
    "\n",
    "### Option 2: Manual Setup\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
    "pip install -r requirements.txt\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "## ðŸ“‚ Project Structure\n",
    "\n",
    "```\n",
    "project/\n",
    "â”œâ”€â”€ src/          # Source code\n",
    "â”œâ”€â”€ tests/        # Test files\n",
    "â”œâ”€â”€ notebooks/    # Jupyter notebooks\n",
    "â”œâ”€â”€ configs/      # Configuration files\n",
    "â”œâ”€â”€ data/         # Data files (not in version control)\n",
    "â””â”€â”€ outputs/      # Generated outputs\n",
    "```\n",
    "\n",
    "## ðŸ”§ Configuration\n",
    "\n",
    "1. Copy `.env.example` to `.env` and fill in your values\n",
    "2. Modify `configs/config.yaml` as needed\n",
    "\n",
    "## ðŸ“Š Usage\n",
    "\n",
    "### Training a Model\n",
    "```python\n",
    "from src.models import ModelTrainer\n",
    "from src.data import DataLoader\n",
    "\n",
    "# Load data\n",
    "loader = DataLoader()\n",
    "data = loader.load_raw_data('data.csv')\n",
    "\n",
    "# Train model\n",
    "trainer = ModelTrainer(config)\n",
    "model = trainer.train(X_train, y_train)\n",
    "```\n",
    "\n",
    "### Making Predictions\n",
    "```python\n",
    "from src.models import predict\n",
    "\n",
    "predictions = predict(model, new_data)\n",
    "```\n",
    "\n",
    "## ðŸ§ª Testing\n",
    "\n",
    "```bash\n",
    "# Run all tests\n",
    "pytest\n",
    "\n",
    "# Run with coverage\n",
    "pytest --cov=src\n",
    "\n",
    "# Run specific test file\n",
    "pytest tests/test_data.py\n",
    "```\n",
    "\n",
    "## ðŸ“ˆ Results\n",
    "\n",
    "Brief description of model performance and key findings.\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Accuracy | 0.95 |\n",
    "| Precision | 0.93 |\n",
    "| Recall | 0.92 |\n",
    "| F1 Score | 0.92 |\n",
    "\n",
    "## ðŸ¤ Contributing\n",
    "\n",
    "1. Fork the repository\n",
    "2. Create a feature branch (`git checkout -b feature/amazing`)\n",
    "3. Commit your changes (`git commit -m 'Add amazing feature'`)\n",
    "4. Push to the branch (`git push origin feature/amazing`)\n",
    "5. Open a Pull Request\n",
    "\n",
    "## ðŸ“ License\n",
    "\n",
    "This project is licensed under the MIT License - see LICENSE file for details.\n",
    "\n",
    "## ðŸ‘¥ Authors\n",
    "\n",
    "- Your Name - Initial work\n",
    "\n",
    "## ðŸ™ Acknowledgments\n",
    "\n",
    "- Hat tip to anyone whose code was used\n",
    "- Inspiration sources\n",
    "- References\n",
    "```\n",
    "\n",
    "### 8.2 Docstring Standards\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Module docstring describing the module's purpose.\n",
    "\n",
    "This module provides functionality for X, Y, and Z.\n",
    "It is designed to be used as part of the larger system.\n",
    "\n",
    "Example:\n",
    "    Basic usage of this module::\n",
    "    \n",
    "        from mymodule import MyClass\n",
    "        \n",
    "        obj = MyClass()\n",
    "        result = obj.process(data)\n",
    "\n",
    "Attributes:\n",
    "    MODULE_CONSTANT (int): Description of module constant\n",
    "\n",
    "Todo:\n",
    "    * Add support for feature X\n",
    "    * Optimize performance of function Y\n",
    "\"\"\"\n",
    "\n",
    "def function_with_docstring(param1: str, \n",
    "                           param2: int = 10,\n",
    "                           **kwargs) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Brief one-line description of function.\n",
    "    \n",
    "    Longer description explaining what the function does,\n",
    "    any important details about its behavior, and when\n",
    "    to use it.\n",
    "    \n",
    "    Args:\n",
    "        param1: Description of param1\n",
    "        param2: Description of param2 with default value\n",
    "        **kwargs: Additional keyword arguments:\n",
    "            - option1 (bool): Description of option1\n",
    "            - option2 (str): Description of option2\n",
    "    \n",
    "    Returns:\n",
    "        Description of return value, including type and\n",
    "        structure if complex.\n",
    "        \n",
    "        Example return structure:\n",
    "        {\n",
    "            'status': 'success',\n",
    "            'data': [...],\n",
    "            'metadata': {...}\n",
    "        }\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If param1 is empty\n",
    "        TypeError: If param2 is not an integer\n",
    "    \n",
    "    Example:\n",
    "        >>> result = function_with_docstring(\"test\", param2=20)\n",
    "        >>> print(result['status'])\n",
    "        'success'\n",
    "    \n",
    "    Note:\n",
    "        This function has side effects on X.\n",
    "        \n",
    "    See Also:\n",
    "        related_function: Does something similar\n",
    "        OtherClass: Related class\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ 9. Putting It All Together\n",
    "\n",
    "### Complete Working Example\n",
    "\n",
    "**scripts/train_pipeline.py**\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Complete training pipeline script.\n",
    "\n",
    "This script orchestrates the entire machine learning pipeline from\n",
    "data loading through model training and evaluation.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import click\n",
    "import mlflow\n",
    "\n",
    "from src.utils.config import config\n",
    "from src.utils.logger import setup_logging\n",
    "from src.data.load_data import DataLoader\n",
    "from src.data.clean_data import DataCleaner\n",
    "from src.features.build_features import FeatureEngineer\n",
    "from src.models.train_model import ModelTrainer\n",
    "from src.models.evaluate_model import ModelEvaluator\n",
    "\n",
    "# Setup logging\n",
    "setup_logging()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@click.command()\n",
    "@click.option('--config-path', default='configs/config.yaml', \n",
    "              help='Path to configuration file')\n",
    "@click.option('--data-path', default=None,\n",
    "              help='Override data path from config')\n",
    "@click.option('--experiment-name', default='default',\n",
    "              help='MLflow experiment name')\n",
    "@click.option('--debug', is_flag=True,\n",
    "              help='Run in debug mode')\n",
    "def main(config_path, data_path, experiment_name, debug):\n",
    "    \"\"\"Run the complete training pipeline.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"Starting training pipeline\")\n",
    "        logger.info(\"=\"*60)\n",
    "        \n",
    "        # Load configuration\n",
    "        logger.info(\"Loading configuration\")\n",
    "        # config is already loaded as singleton\n",
    "        \n",
    "        if debug:\n",
    "            logging.getLogger().setLevel(logging.DEBUG)\n",
    "        \n",
    "        # Step 1: Load data\n",
    "        logger.info(\"Step 1: Loading data\")\n",
    "        loader = DataLoader(config_path)\n",
    "        \n",
    "        data_file = data_path or config.get('data.raw_file')\n",
    "        df = loader.load_raw_data(data_file)\n",
    "        logger.info(f\"Loaded {len(df)} rows\")\n",
    "        \n",
    "        # Step 2: Clean data\n",
    "        logger.info(\"Step 2: Cleaning data\")\n",
    "        cleaner = DataCleaner()\n",
    "        df = cleaner.clean(df)\n",
    "        logger.info(f\"Cleaned data: {len(df)} rows remaining\")\n",
    "        \n",
    "        # Step 3: Feature engineering\n",
    "        logger.info(\"Step 3: Engineering features\")\n",
    "        engineer = FeatureEngineer(config.get('features', {}))\n",
    "        df = engineer.create_features(df, target_col=config.get('data.target_column'))\n",
    "        logger.info(f\"Created {len(engineer.feature_names)} features\")\n",
    "        \n",
    "        # Step 4: Split data\n",
    "        logger.info(\"Step 4: Splitting data\")\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        target_col = config.get('data.target_column')\n",
    "        X = df[engineer.feature_names]\n",
    "        y = df[target_col]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, \n",
    "            test_size=config.get('model.test_size', 0.2),\n",
    "            random_state=42,\n",
    "            stratify=y\n",
    "        )\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train,\n",
    "            test_size=config.get('model.validation_size', 0.2),\n",
    "            random_state=42,\n",
    "            stratify=y_train\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "        \n",
    "        # Step 5: Train model\n",
    "        logger.info(\"Step 5: Training model\")\n",
    "        trainer = ModelTrainer(\n",
    "            config.get('model', {}),\n",
    "            experiment_name=experiment_name\n",
    "        )\n",
    "        \n",
    "        model = trainer.train(X_train, y_train, X_val, y_val)\n",
    "        logger.info(\"Model training completed\")\n",
    "        \n",
    "        # Step 6: Evaluate model\n",
    "        logger.info(\"Step 6: Evaluating model\")\n",
    "        evaluator = ModelEvaluator()\n",
    "        metrics = evaluator.evaluate(model, X_test, y_test)\n",
    "        \n",
    "        logger.info(\"=\"*60)\n",
    "        logger.info(\"Pipeline completed successfully!\")\n",
    "        logger.info(f\"Final metrics: {metrics}\")\n",
    "        logger.info(\"=\"*60)\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline failed: {str(e)}\", exc_info=True)\n",
    "        return 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    exit(main())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ“ Best Practices Summary\n",
    "\n",
    "### Do's âœ…\n",
    "\n",
    "1. **Always use version control** - Commit early and often\n",
    "2. **Write tests first** - TDD helps design better code\n",
    "3. **Document as you go** - Future you will thank you\n",
    "4. **Use type hints** - Makes code self-documenting\n",
    "5. **Keep functions small** - Single responsibility principle\n",
    "6. **Handle errors gracefully** - Never let errors pass silently\n",
    "7. **Use configuration files** - No hardcoded values\n",
    "8. **Log everything important** - Debugging will be easier\n",
    "9. **Profile before optimizing** - Measure, don't guess\n",
    "10. **Review your own code** - After a break, review with fresh eyes\n",
    "\n",
    "### Don'ts âŒ\n",
    "\n",
    "1. **Don't commit data files** - Use .gitignore\n",
    "2. **Don't use global variables** - Pass parameters explicitly\n",
    "3. **Don't ignore warnings** - They often indicate problems\n",
    "4. **Don't copy-paste code** - Extract common functionality\n",
    "5. **Don't skip testing** - Technical debt accumulates quickly\n",
    "6. **Don't use print for debugging** - Use proper logging\n",
    "7. **Don't hardcode paths** - Use configuration or Path objects\n",
    "8. **Don't ignore code style** - Consistency matters\n",
    "9. **Don't optimize prematurely** - Working code first\n",
    "10. **Don't work without version control** - Even for experiments\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš¦ Getting Started Checklist\n",
    "\n",
    "```bash\n",
    "# 1. Create project structure\n",
    "bash create_project_structure.sh\n",
    "\n",
    "# 2. Initialize git\n",
    "cd your-data-science-project\n",
    "git init\n",
    "git add .\n",
    "git commit -m \"Initial commit\"\n",
    "\n",
    "# 3. Set up virtual environment\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "\n",
    "# 4. Install dependencies\n",
    "pip install -r requirements.txt\n",
    "pip install -r requirements-dev.txt\n",
    "pip install -e .\n",
    "\n",
    "# 5. Set up pre-commit hooks\n",
    "pre-commit install\n",
    "\n",
    "# 6. Run initial tests\n",
    "pytest\n",
    "\n",
    "# 7. Start coding!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "*This guide provides a comprehensive foundation for setting up professional, maintainable data science projects. Adapt and modify based on your specific needs, but maintain the core principles of clean, reusable code.*\n",
    "\n",
    "\n",
    "# Cell 2: Environment Setup (Clean)\n",
    "# Core imports and configuration\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Add project path\n",
    "HERE = Path().resolve()\n",
    "sys.path.insert(0, str(HERE.parent / \"src\"))\n",
    "\n",
    "# Data science stack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Project modules\n",
    "from utils.loader import DataLoader\n",
    "from utils.preprocessor import clean_telco_data\n",
    "from utils.stats import (\n",
    "    test_numerical_vs_churn,\n",
    "    test_categorical_vs_churn,\n",
    "    identify_risk_segments\n",
    ")\n",
    "\n",
    "# Load configuration\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"âœ… Environment setup complete\")\n",
    "# Cell 3: Data Loading & Validation\n",
    "# Load and prepare data using modular functions\n",
    "loader = DataLoader(config)\n",
    "df_raw, load_report = loader.load_data(config['data']['raw_path'])\n",
    "df_clean = clean_telco_data(df_raw)\n",
    "\n",
    "# Data quality summary\n",
    "print(f\"Dataset: {df_clean.shape[0]:,} customers, {df_clean.shape[1]} features\")\n",
    "print(f\"Churn rate: {(df_clean['Churn'] == 'Yes').mean()*100:.1f}%\")\n",
    "print(f\"Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# Save processed data\n",
    "processed_path = Path(config['data']['processed_path'])\n",
    "processed_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_clean.to_csv(processed_path, index=False)\n",
    "print(f\"âœ… Clean data saved to {processed_path}\")\n",
    "# Cell 4: Statistical Testing Framework\n",
    "# Define features to test\n",
    "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "categorical_features = ['Contract', 'PaymentMethod', 'InternetService']\n",
    "\n",
    "# Initialize results storage\n",
    "statistical_results = {\n",
    "    'numerical': {},\n",
    "    'categorical': {}\n",
    "}\n",
    "\n",
    "print(\"ðŸ”¬ Running Statistical Tests\")\n",
    "print(\"=\" * 40)\n",
    "# Cell 5: Numerical Feature Analysis\n",
    "# Test numerical features\n",
    "for feature in numerical_features:\n",
    "    result = test_numerical_vs_churn(df_clean, feature, 'Churn')\n",
    "    statistical_results['numerical'][feature] = result\n",
    "    \n",
    "    print(f\"\\n{feature.upper()}:\")\n",
    "    print(f\"  Test: {result['test_used']}\")\n",
    "    print(f\"  P-value: {result['p_value']:.4e}\")\n",
    "    print(f\"  Effect size: {result['cohens_d']:.3f} ({result['effect_size']})\")\n",
    "    print(f\"  Significant: {'âœ…' if result['significant'] else 'âŒ'}\")\n",
    "# Cell 6: Categorical Feature Analysis\n",
    "# Test categorical features\n",
    "for feature in categorical_features:\n",
    "    result = test_categorical_vs_churn(df_clean, feature, 'Churn')\n",
    "    statistical_results['categorical'][feature] = result\n",
    "    \n",
    "    print(f\"\\n{feature.upper()}:\")\n",
    "    print(f\"  Chi-square: {result['chi2_statistic']:.2f}\")\n",
    "    print(f\"  P-value: {result['p_value']:.4e}\")\n",
    "    print(f\"  CramÃ©r's V: {result['cramers_v']:.3f}\")\n",
    "    print(f\"  Highest risk: {result['highest_risk_category']}\")\n",
    "#Cell 7: Key Findings Visualization\n",
    "# Create focused visualizations for significant findings\n",
    "significant_features = []\n",
    "\n",
    "# Identify significant results\n",
    "for category, results in statistical_results.items():\n",
    "    for feature, result in results.items():\n",
    "        if result['significant']:\n",
    "            significant_features.append((feature, result))\n",
    "\n",
    "print(f\"ðŸ“Š Visualizing {len(significant_features)} significant findings\")\n",
    "\n",
    "# Create subplot grid\n",
    "n_features = len(significant_features)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (feature, result) in enumerate(significant_features[:4]):\n",
    "    # Your visualization code here\n",
    "    pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "Cell 8: Risk Segmentation\n",
    "python# Business-focused risk analysis\n",
    "risk_segments = identify_risk_segments(df_clean)\n",
    "\n",
    "print(\"ðŸŽ¯ HIGH-RISK CUSTOMER SEGMENTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Sort by risk level and revenue impact\n",
    "high_risk_segments = {k: v for k, v in risk_segments.items() \n",
    "                     if v['risk_level'] == 'HIGH'}\n",
    "\n",
    "for segment_name, data in high_risk_segments.items():\n",
    "    print(f\"\\n{segment_name.upper()}:\")\n",
    "    print(f\"  Size: {data['size']:,} customers ({data['percentage_of_base']:.1f}%)\")\n",
    "    print(f\"  Churn Rate: {data['churn_rate']:.1f}%\")\n",
    "    print(f\"  Revenue at Risk: ${data.get('monthly_revenue_at_risk', 0):,.0f}/month\")\n",
    "# Cell 9: Executive Summary & Recommendations\n",
    "# Business intelligence summary\n",
    "print(\"ðŸ“‹ EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate total impact\n",
    "total_revenue_at_risk = sum(\n",
    "    segment.get('monthly_revenue_at_risk', 0) \n",
    "    for segment in risk_segments.values()\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ’° BUSINESS IMPACT:\")\n",
    "print(f\"   Total Monthly Revenue at Risk: ${total_revenue_at_risk:,.0f}\")\n",
    "print(f\"   Annualized Impact: ${total_revenue_at_risk * 12:,.0f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ TOP 3 RECOMMENDATIONS:\")\n",
    "\n",
    "# Generate recommendations from significant findings\n",
    "recommendations = []\n",
    "for feature, result in significant_features:\n",
    "    if feature == 'Contract' and result['significant']:\n",
    "        recommendations.append({\n",
    "            'priority': 1,\n",
    "            'action': 'Contract Incentive Program',\n",
    "            'rationale': f\"Month-to-month customers have {result['churn_rates_by_category']['Month-to-month']*100:.1f}% churn rate\",\n",
    "            'expected_impact': '20% reduction in contract-related churn'\n",
    "        })\n",
    "\n",
    "# Display top recommendations\n",
    "for i, rec in enumerate(recommendations[:3], 1):\n",
    "    print(f\"\\n   {i}. {rec['action']}\")\n",
    "    print(f\"      Rationale: {rec['rationale']}\")\n",
    "    print(f\"      Expected Impact: {rec['expected_impact']}\")\n",
    "# Cell 10: Technical Appendix (Optional)\n",
    "# Detailed statistical results for technical stakeholders\n",
    "print(\"ðŸ“Š DETAILED STATISTICAL RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Export detailed results\n",
    "results_export = {\n",
    "    'summary': {\n",
    "        'total_features_tested': len(numerical_features) + len(categorical_features),\n",
    "        'significant_findings': len(significant_features),\n",
    "        'alpha_level': 0.05\n",
    "    },\n",
    "    'detailed_results': statistical_results\n",
    "}\n",
    "\n",
    "# Save results for reporting\n",
    "import json\n",
    "with open('../results/statistical_analysis_results.json', 'w') as f:\n",
    "    json.dump(results_export, f, indent=2, default=str)\n",
    "\n",
    "print(\"âœ… Results exported for technical documentation\")\n",
    "# ðŸŽ¯ Key Improvements for Level 3\n",
    "# 1. Separation of Concerns\n",
    "### âŒ Mixed exploration and analysis\n",
    "```python\n",
    "tenure_0_customers = df_clean[df_clean['tenure'] == 0]\n",
    "print(tabulate(tenure_0_customers, headers='keys', tablefmt='psql'))\n",
    "```\n",
    "\n",
    "## âœ… Focused analysis only\n",
    "```python\n",
    "result = test_numerical_vs_churn(df_clean, 'tenure', 'Churn')\n",
    "print(f\"Tenure analysis: p={result['p_value']:.4e}, d={result['cohens_d']:.3f}\")\n",
    "```\n",
    "## 2. Professional Output Formatting\n",
    "### âŒ Basic print statements\n",
    "```python\n",
    "print(\"Tenure Analysis Results:\")\n",
    "print(f\"  Test used: {tenure_results['test_used']}\")\n",
    "```\n",
    "### âœ… Structured, scannable output\n",
    "```python\n",
    "print(\"ðŸ”¬ STATISTICAL TEST RESULTS\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Feature: {feature}\")\n",
    "print(f\"Test: {result['test_used']}\")\n",
    "print(f\"Significance: {'âœ… Significant' if result['significant'] else 'âŒ Not significant'}\")\n",
    "```\n",
    "\n",
    "## 3. Result-Oriented Structure\n",
    "### âŒ Process-focused\n",
    "\"First let's load the data, then clean it, then test it...\"\n",
    "\n",
    "### âœ… Results-focused\n",
    "\"Key Finding: Contract type significantly predicts churn (p<0.001)\"\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0e768",
   "metadata": {},
   "source": [
    "Perfect â€” hereâ€™s a lightweight, **Level-3-friendly Python script** you can drop into any notebook (or run as a standalone utility) to **read your YAML checklist** and report overall completion progress.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© `progress_tracker.py` (or notebook cell)\n",
    "\n",
    "```python\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "def checklist_progress(yaml_path, section_name):\n",
    "    \"\"\"\n",
    "    Reads a YAML checklist (like project_plan.yaml) and reports\n",
    "    completion percentage + remaining unchecked tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load YAML\n",
    "    with open(yaml_path, \"r\") as f:\n",
    "        plan = yaml.safe_load(f)\n",
    "\n",
    "    section = plan.get(section_name)\n",
    "    if not section:\n",
    "        print(f\"âŒ Section '{section_name}' not found in {yaml_path}\")\n",
    "        return\n",
    "\n",
    "    # Flatten all subtasks\n",
    "    def flatten(tasks):\n",
    "        items = []\n",
    "        for task in tasks:\n",
    "            if isinstance(task, dict):\n",
    "                # Nested structure (one main task with subtasks)\n",
    "                for key, subtasks in task.items():\n",
    "                    if isinstance(subtasks, list):\n",
    "                        items.append(key)\n",
    "                        items.extend(flatten(subtasks))\n",
    "                    else:\n",
    "                        items.append(key)\n",
    "            elif isinstance(task, str):\n",
    "                items.append(task)\n",
    "        return items\n",
    "\n",
    "    # Count completed vs total\n",
    "    completed = 0\n",
    "    total = 0\n",
    "    for task in section.get(\"tasks\", []):\n",
    "        lines = yaml.dump(task).splitlines()\n",
    "        for line in lines:\n",
    "            if \"[x]\" in line.lower():\n",
    "                completed += 1\n",
    "                total += 1\n",
    "            elif \"[ ]\" in line:\n",
    "                total += 1\n",
    "\n",
    "    percent = round((completed / total) * 100, 1) if total else 0\n",
    "    print(f\"\\nðŸ“Š Progress for '{section_name}': {completed}/{total} tasks complete ({percent}%)\")\n",
    "\n",
    "    # Optional: list remaining unchecked items\n",
    "    print(\"\\nðŸ“ Remaining Tasks:\")\n",
    "    for task in flatten(section[\"tasks\"]):\n",
    "        if \"[ ]\" in task:\n",
    "            print(f\"  - {task.strip('- [ ]')}\")\n",
    "\n",
    "# Example usage:\n",
    "# checklist_progress(\"project_plan.yaml\", \"02_Data_Validation_and_Cleaning\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  How to Use\n",
    "\n",
    "1. Save your YAML (from the previous step) as `project_plan.yaml` in your Level_3 directory.\n",
    "2. Paste this code into a notebook cell or script.\n",
    "3. Run:\n",
    "\n",
    "   ```python\n",
    "   checklist_progress(\"project_plan.yaml\", \"02_Data_Validation_and_Cleaning\")\n",
    "   ```\n",
    "4. Youâ€™ll see output like:\n",
    "\n",
    "   ```\n",
    "   ðŸ“Š Progress for '02_Data_Validation_and_Cleaning': 27/64 tasks complete (42.2%)\n",
    "\n",
    "   ðŸ“ Remaining Tasks:\n",
    "     - 3.4 Decide drop / imputation strategy\n",
    "     - 8.5 Flag anomalies and prepare issue log\n",
    "     - 15.3 Save dataset â†’ data/processed/telco_clean.csv\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§© Optional Bonus (if you want to scale this later)\n",
    "\n",
    "You can:\n",
    "\n",
    "* Loop over **all sections** to print total project progress.\n",
    "* Integrate it into a **Makefile**, **pre-commit hook**, or **CI/CD** to track progress automatically.\n",
    "* Output progress to a small JSON for dashboards.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to extend this script so it reports **progress for all notebooks** (01â€“10) in one table?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
