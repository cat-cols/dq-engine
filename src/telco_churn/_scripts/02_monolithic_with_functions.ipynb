{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66cf99b0",
   "metadata": {},
   "source": [
    "\n",
    "# Telco Churn — Level 2 Monolithic Notebook (Structured EDA)\n",
    "\n",
    "**Scope:** Level 2 only — systematic, business-focused exploration of a cleaned dataset.  \n",
    "No modeling here (that begins at Level 4).\n",
    "\n",
    "**What this notebook does (end-to-end Level 2):**\n",
    "1. Load the IBM Telco Churn dataset\n",
    "2. Validate the data (shape, types, missing, duplicates)\n",
    "3. Apply business-aware fixes (e.g., `TotalCharges`)\n",
    "4. Structured EDA on **all** columns\n",
    "5. Simple feature engineering for useful segments\n",
    "6. Export figures and a cleaned/enhanced CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d55f40",
   "metadata": {},
   "source": [
    "## 0) Setup & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c46bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- User-configurable paths ---\n",
    "from pathlib import Path\n",
    "import os, sys, textwrap, inspect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# >>> Adjust this to your machine if needed\n",
    "PROJECT = Path(\"/Users/b/DATA/PROJECTS/Telco/L2\")\n",
    "DATA    = PROJECT / \"data\" / \"WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "FIGS    = PROJECT / \"figures\"\n",
    "FIGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "print(\"Project:\", PROJECT)\n",
    "print(\"Data:\", DATA)\n",
    "print(\"Figures:\", FIGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Utilities (defined inline for monolithic workflow)\n",
    "def ensure_dir(path):\n",
    "    \"\"\"Create directory if missing.\"\"\"\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def memory_report(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Human-readable memory usage for a DataFrame.\"\"\"\n",
    "    mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    return f\"{mb:.2f} MB\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad80fc",
   "metadata": {},
   "source": [
    "## 2) Loading & Basic Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "BINARY_YN = [\n",
    "    \"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\",\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
    "    \"StreamingTV\", \"StreamingMovies\", \"MultipleLines\"\n",
    "]\n",
    "SERVICE_WITH_NO_INTERNET = [\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
    "    \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"\n",
    "]\n",
    "\n",
    "def strip_object_whitespace(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    obj_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for c in obj_cols:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def simplify_service_levels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Map 'No internet service' -> 'No'; keep raw copy with *_raw.\"\"\"\n",
    "    for c in SERVICE_WITH_NO_INTERNET:\n",
    "        if c in df.columns:\n",
    "            raw = f\"{c}_raw\"\n",
    "            if raw not in df.columns:\n",
    "                df[raw] = df[c].copy()\n",
    "            df[c] = df[c].replace({\"No internet service\": \"No\"})\n",
    "    if \"MultipleLines\" in df.columns:\n",
    "        raw = \"MultipleLines_raw\"\n",
    "        if raw not in df.columns:\n",
    "            df[raw] = df[\"MultipleLines\"].copy()\n",
    "        df[\"MultipleLines\"] = df[\"MultipleLines\"].replace({\"No phone service\": \"No\"})\n",
    "    return df\n",
    "\n",
    "def load_telco_data(filepath: str, optimize_memory: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Load the IBM Telco dataset and apply light normalization/typing.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = strip_object_whitespace(df)\n",
    "    if \"TotalCharges\" in df.columns:\n",
    "        df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "    df = simplify_service_levels(df)\n",
    "\n",
    "    if optimize_memory:\n",
    "        for c in BINARY_YN:\n",
    "            if c in df.columns:\n",
    "                df[c] = df[c].astype(\"category\")\n",
    "        for c in [\"gender\", \"Contract\", \"PaymentMethod\", \"InternetService\", \"Churn\"]:\n",
    "            if c in df.columns:\n",
    "                df[c] = df[c].astype(\"category\")\n",
    "        if \"SeniorCitizen\" in df.columns:\n",
    "            df[\"SeniorCitizen\"] = df[\"SeniorCitizen\"].astype(\"int8\").astype(\"category\")\n",
    "        for c in [\"tenure\", \"MonthlyCharges\"]:\n",
    "            if c in df.columns and not np.issubdtype(df[c].dtype, np.number):\n",
    "                df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    if \"Churn\" in df.columns and \"ChurnFlag\" not in df.columns:\n",
    "        df[\"ChurnFlag\"] = (df[\"Churn\"].astype(str) == \"Yes\").astype(\"int8\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf99266",
   "metadata": {},
   "source": [
    "## 3) Validation & Dtype Probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c7dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    expected_columns=None,\n",
    "    unique_id_col: str | None = \"customerID\",\n",
    "    show_examples_for_missing: int = 3,\n",
    ") -> dict:\n",
    "    \"\"\"Print a human-readable validation report and return a dict summary.\"\"\"\n",
    "    report = {}\n",
    "    report[\"shape\"] = df.shape\n",
    "    report[\"memory\"] = memory_report(df)\n",
    "    report[\"duplicates\"] = int(df.duplicated().sum())\n",
    "    nulls = df.isna().sum()\n",
    "    report[\"missing\"] = nulls[nulls > 0].sort_values(ascending=False)\n",
    "\n",
    "    if expected_columns is not None:\n",
    "        expected = set(expected_columns)\n",
    "        actual = set(df.columns)\n",
    "        report[\"missing_columns\"] = sorted(list(expected - actual))\n",
    "        report[\"unexpected_columns\"] = sorted(list(actual - expected))\n",
    "\n",
    "    if unique_id_col and unique_id_col in df.columns:\n",
    "        report[\"id_uniqueness_ok\"] = bool(df[unique_id_col].is_unique)\n",
    "        if not report[\"id_uniqueness_ok\"]:\n",
    "            report[\"duplicate_ids\"] = (\n",
    "                df[unique_id_col][df[unique_id_col].duplicated()].head(show_examples_for_missing).tolist()\n",
    "            )\n",
    "\n",
    "    print(\"=== Data Validation Report ===\")\n",
    "    print(f\"Shape: {report['shape']}\")\n",
    "    print(f\"Memory: {report['memory']}\")\n",
    "    print(f\"Duplicates: {report['duplicates']}\")\n",
    "    if len(report.get(\"missing\", [])):\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(report[\"missing\"])\n",
    "    if \"missing_columns\" in report and report[\"missing_columns\"]:\n",
    "        print(\"\\nMissing columns:\", report[\"missing_columns\"])\n",
    "    if \"unexpected_columns\" in report and report[\"unexpected_columns\"]:\n",
    "        print(\"Unexpected columns:\", report[\"unexpected_columns\"])\n",
    "    if \"id_uniqueness_ok\" in report:\n",
    "        print(\"customerID unique?:\", report[\"id_uniqueness_ok\"])\n",
    "        if not report[\"id_uniqueness_ok\"]:\n",
    "            print(\"Example duplicate IDs:\", report.get(\"duplicate_ids\", []))\n",
    "\n",
    "    return report\n",
    "\n",
    "def investigate_object_columns(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Inspect object columns for numeric convertibility and unique patterns.\"\"\"\n",
    "    objs = df.select_dtypes(include=\"object\").columns\n",
    "    print(\"=== Object Column Investigations ===\")\n",
    "    for c in objs:\n",
    "        try:\n",
    "            pd.to_numeric(df[c])\n",
    "            print(f\"✓ {c}: convertible to numeric\")\n",
    "        except Exception:\n",
    "            nunique = df[c].nunique(dropna=True)\n",
    "            preview = \", \".join(map(str, df[c].dropna().unique()[:10]))\n",
    "            print(f\"✗ {c}: stays as object; unique={nunique}; sample: {preview}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5e8ac",
   "metadata": {},
   "source": [
    "## 4) Business Logic Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452954e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_business_logic(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fill `TotalCharges` for NaN rows using tenure * MonthlyCharges; keep audit diffs.\"\"\"\n",
    "    df = df.copy()\n",
    "    needed = {\"tenure\", \"MonthlyCharges\", \"TotalCharges\"}\n",
    "    if needed.issubset(df.columns):\n",
    "        expected = df[\"tenure\"].astype(float) * df[\"MonthlyCharges\"].astype(float)\n",
    "        df[\"charge_difference\"] = df[\"TotalCharges\"] - expected\n",
    "        na_mask = df[\"TotalCharges\"].isna()\n",
    "        df.loc[na_mask, \"TotalCharges\"] = expected[na_mask]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c35d5d",
   "metadata": {},
   "source": [
    "## 5) Feature Engineering (Level 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ef52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_customer_segments(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create segments: CustomerValue (TotalCharges tertiles), LifecycleStage (tenure bins), ServiceCount.\"\"\"\n",
    "    df = df.copy()\n",
    "    if \"TotalCharges\" in df.columns:\n",
    "        df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "        valid = df[\"TotalCharges\"].dropna()\n",
    "        if valid.size:\n",
    "            try:\n",
    "                df[\"CustomerValue\"] = pd.qcut(df[\"TotalCharges\"], q=3, labels=[\"Low\",\"Medium\",\"High\"])\n",
    "            except ValueError:\n",
    "                df[\"CustomerValue\"] = pd.cut(df[\"TotalCharges\"], bins=3, labels=[\"Low\",\"Medium\",\"High\"])\n",
    "    if \"tenure\" in df.columns:\n",
    "        df[\"LifecycleStage\"] = pd.cut(\n",
    "            df[\"tenure\"].astype(float),\n",
    "            bins=[-0.1, 12, 24, 48, 72, np.inf],\n",
    "            labels=[\"New\",\"Growing\",\"Mature\",\"Loyal\",\"Veteran\"],\n",
    "            include_lowest=True, right=True\n",
    "        )\n",
    "    service_cols = [\n",
    "        \"PhoneService\",\"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\n",
    "        \"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\"MultipleLines\"\n",
    "    ]\n",
    "    present = [c for c in service_cols if c in df.columns]\n",
    "    df[\"ServiceCount\"] = 0\n",
    "    for c in present:\n",
    "        df[\"ServiceCount\"] = df[\"ServiceCount\"] + (df[c].astype(str) == \"Yes\").astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b675f0b",
   "metadata": {},
   "source": [
    "## 6) EDA Plot Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_categorical(df: pd.DataFrame, column: str, target: str = \"Churn\", figsize=(12,4), top_n: int | None = 12):\n",
    "    \"\"\"Distribution, stacked churn proportion, quick stats box.\"\"\"\n",
    "    s = df[column].astype(\"category\")\n",
    "    if top_n and s.nunique() > top_n:\n",
    "        top_levels = s.value_counts().nlargest(top_n).index\n",
    "        s = s.where(s.isin(top_levels), other=\"__OTHER__\")\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    s.value_counts().sort_values(ascending=False).plot(kind=\"bar\", ax=axes[0])\n",
    "    axes[0].set_title(f\"{column} Distribution\"); axes[0].set_ylabel(\"Count\")\n",
    "    if target in df.columns:\n",
    "        ct = pd.crosstab(s, df[target], normalize=\"index\")\n",
    "        ct.plot(kind=\"bar\", stacked=True, ax=axes[1])\n",
    "        axes[1].set_title(f\"{column} vs {target} (Proportion)\"); axes[1].set_ylabel(\"Proportion\")\n",
    "        axes[1].legend(title=target, bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    else:\n",
    "        axes[1].axis(\"off\"); axes[1].text(0.1, 0.5, f\"Target '{target}' not found.\", fontsize=11)\n",
    "    axes[2].axis(\"off\")\n",
    "    stats_text = f\"\"\"Unique: {s.nunique()}\n",
    "Mode: {s.mode().iat[0] if not s.mode().empty else '—'}\n",
    "Missing: {int(s.isna().sum())}\"\"\"\n",
    "    axes[2].text(0.05, 0.6, stats_text, fontsize=12, family=\"monospace\")\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_numerical(df: pd.DataFrame, column: str, target: str = \"Churn\", bins: int = 30):\n",
    "    \"\"\"Histogram, boxplot by target, KDE by target (safe), stats table.\"\"\"\n",
    "    x = pd.to_numeric(df[column], errors=\"coerce\")\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    x.dropna().hist(bins=bins, ax=axes[0,0], edgecolor=\"black\"); axes[0,0].set_title(f\"{column} Distribution\")\n",
    "    if target in df.columns:\n",
    "        groups_vals = df[target].dropna().unique()\n",
    "        groups = [x[df[target] == v].dropna().values for v in groups_vals]\n",
    "        if any(len(g) > 0 for g in groups):\n",
    "            axes[0,1].boxplot(groups, labels=[str(v) for v in groups_vals]); axes[0,1].set_title(f\"{column} by {target}\")\n",
    "        else:\n",
    "            axes[0,1].axis(\"off\"); axes[0,1].text(0.1, 0.5, \"No data for boxplot\", fontsize=11)\n",
    "    else:\n",
    "        axes[0,1].axis(\"off\"); axes[0,1].text(0.1, 0.5, f\"Target '{target}' not found.\", fontsize=11)\n",
    "    axes[1,0].set_title(f\"{column} Density by {target}\")\n",
    "    if target in df.columns:\n",
    "        groups = df[target].dropna().unique(); plotted = False\n",
    "        x_all = pd.to_numeric(df[column], errors=\"coerce\")\n",
    "        for v in groups:\n",
    "            xv = x_all[df[target] == v].dropna().to_numpy()\n",
    "            if xv.size >= 3 and np.nanvar(xv) > 0:\n",
    "                try:\n",
    "                    pd.Series(xv).plot(kind=\"kde\", ax=axes[1,0], label=f\"{target}={v}\"); plotted = True\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if plotted:\n",
    "            axes[1,0].legend(loc=\"best\")\n",
    "        else:\n",
    "            axes[1,0].text(0.05, 0.5, \"KDE skipped (insufficient size/variance)\", transform=axes[1,0].transAxes, fontsize=9)\n",
    "    else:\n",
    "        axes[1,0].axis(\"off\")\n",
    "    axes[1,1].axis(\"off\"); desc = x.describe()\n",
    "    axes[1,1].text(0.05, 0.6, desc.to_string(), fontsize=10, family=\"monospace\")\n",
    "    fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50cda6e",
   "metadata": {},
   "source": [
    "## 7) Complete EDA Runner (saves figures to `/figures`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22defc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_complete_eda(\n",
    "    df: pd.DataFrame,\n",
    "    figures_dir: str | Path = FIGS,\n",
    "    save_figures: bool = True,\n",
    "    skip_cols=(\"customerID\",),\n",
    "    target: str = \"Churn\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Run Level-2 EDA: validate → per-column plots → business logic → features → re-validate.\"\"\"\n",
    "    ensure_dir(figures_dir)\n",
    "\n",
    "    print(\"1) Validation (raw)\")\n",
    "    validate_dataset(df)\n",
    "\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    numerical_cols   = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if skip_cols:\n",
    "        categorical_cols = [c for c in categorical_cols if c not in skip_cols]\n",
    "        numerical_cols   = [c for c in numerical_cols   if c not in skip_cols]\n",
    "\n",
    "    print(\"\\n2) Categorical analysis\")\n",
    "    for c in categorical_cols:\n",
    "        fig = analyze_categorical(df, c, target=target)\n",
    "        if save_figures: fig.savefig(Path(figures_dir) / f\"categorical_{c}.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"\\n3) Numerical analysis\")\n",
    "    for c in numerical_cols:\n",
    "        fig = analyze_numerical(df, c, target=target)\n",
    "        if save_figures: fig.savefig(Path(figures_dir) / f\"numerical_{c}.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"\\n4) Business logic corrections\")\n",
    "    df2 = apply_business_logic(df)\n",
    "\n",
    "    print(\"\\n5) Feature engineering\")\n",
    "    df3 = create_customer_segments(df2)\n",
    "\n",
    "    print(\"\\n6) Validation (enhanced)\")\n",
    "    validate_dataset(df3)\n",
    "\n",
    "    return df3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39d165",
   "metadata": {},
   "source": [
    "## 8) Execute Level-2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c202167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load & run\n",
    "df = load_telco_data(str(DATA), optimize_memory=True)\n",
    "_  = validate_dataset(df)\n",
    "investigate_object_columns(df)\n",
    "\n",
    "df_enhanced = perform_complete_eda(\n",
    "    df,\n",
    "    figures_dir=FIGS,\n",
    "    save_figures=True,\n",
    "    target=\"Churn\"\n",
    ")\n",
    "\n",
    "# Save enhanced dataset + quick numeric hist grid\n",
    "out_csv = FIGS / \"telco_enhanced.csv\"\n",
    "df_enhanced.to_csv(out_csv, index=False)\n",
    "print(\"Saved enhanced dataset to:\", out_csv)\n",
    "\n",
    "axes = df_enhanced.select_dtypes(\"number\").hist(figsize=(12, 12), layout=(4, 4))\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGS / \"all_numeric_histograms.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved numeric hist grid to:\", FIGS / \"all_numeric_histograms.png\")\n",
    "\n",
    "# Quick business-focused summaries (examples)\n",
    "churn_rate = df_enhanced[\"ChurnFlag\"].mean() if \"ChurnFlag\" in df_enhanced else float(\"nan\")\n",
    "print(f\"Overall churn rate: {churn_rate:.3f}\")\n",
    "if {\"ChurnFlag\",\"Contract\"}.issubset(df_enhanced.columns):\n",
    "    by_contract = df_enhanced.groupby(\"Contract\")[\"ChurnFlag\"].mean().sort_values(ascending=False)\n",
    "    print(\"\\nChurn rate by Contract:\"); print(by_contract)\n",
    "\n",
    "if {\"ChurnFlag\",\"PaymentMethod\"}.issubset(df_enhanced.columns):\n",
    "    by_pay = df_enhanced.groupby(\"PaymentMethod\")[\"ChurnFlag\"].mean().sort_values(ascending=False)\n",
    "    print(\"\\nChurn rate by PaymentMethod:\"); print(by_pay)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
