{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "# view variables in notebook\n",
    "%whos\n",
    "# reset variables\n",
    "# %reset -f\n",
    "\n",
    "# manual search for variable definitions\n",
    "# !grep -n \"df =\" 01_EDA.ipynb\n",
    "\n",
    "# manual search for target_cols\n",
    "# !grep -n \"target_cols\" 01_EDA.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552b23f",
   "metadata": {},
   "source": [
    "You got it. Letâ€™s make a little utility that:\n",
    "\n",
    "* Reads a Jupyter notebook (`.ipynb`)\n",
    "* Detects which section each cell belongs to by its nearest `# 2.x ...` markdown heading\n",
    "* Collects **all code cells** that live under sections **2.5, 2.6, 2.7, 2.8**\n",
    "* Writes them into a single `.py` file with comments separating them\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ Script: `aggregate_section_25_28.py`\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Aggregate all Python code cells from Sections 2.5â€“2.8 of a Jupyter notebook\n",
    "into a single .py script.\n",
    "\n",
    "Assumptions:\n",
    "- Section headers are markdown cells whose FIRST line looks like:\n",
    "    # 2.5 ðŸ§  Logic Checks â€” Internal Consistency & Business Rules\n",
    "  i.e. starts with \"# 2.<something>\"\n",
    "\n",
    "Usage:\n",
    "    python aggregate_section_25_28.py \\\n",
    "        --notebook path/to/Section2_notebook.ipynb \\\n",
    "        --output   resources/scripts/section_2_5_to_2_8.py\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "SECTION_PATTERN = re.compile(r\"^\\s*#\\s*2\\.(\\d+)\\b\")  # captures the \"5\" in \"# 2.5 ...\"\n",
    "\n",
    "\n",
    "def detect_section_from_markdown(source_lines) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Given the `source` list of a markdown cell, try to detect the Section number.\n",
    "    Returns an integer like 5, 6, 7, 8 or None if not matched.\n",
    "    \"\"\"\n",
    "    if not source_lines:\n",
    "        return None\n",
    "\n",
    "    first_line = source_lines[0]\n",
    "    m = SECTION_PATTERN.match(first_line)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def aggregate_sections(notebook_path: Path, out_path: Path) -> None:\n",
    "    with notebook_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        nb = json.load(f)\n",
    "\n",
    "    cells = nb.get(\"cells\", [])\n",
    "\n",
    "    current_section: Optional[int] = None\n",
    "    collected_blocks = []\n",
    "\n",
    "    for idx, cell in enumerate(cells):\n",
    "        cell_type = cell.get(\"cell_type\")\n",
    "        source = cell.get(\"source\", [])\n",
    "\n",
    "        # --- Track section based on markdown headers ---\n",
    "        if cell_type == \"markdown\":\n",
    "            sec = detect_section_from_markdown(source)\n",
    "            if sec is not None:\n",
    "                current_section = sec\n",
    "            continue\n",
    "\n",
    "        # --- Collect code cells only if in 2.5â€“2.8 ---\n",
    "        if cell_type == \"code\":\n",
    "            if current_section is not None and 5 <= current_section <= 8:\n",
    "                # Join source (list of lines) as one block\n",
    "                code_block = \"\".join(source)\n",
    "\n",
    "                header_comment = (\n",
    "                    f\"# ======================================================================\\n\"\n",
    "                    f\"# From Section 2.{current_section} â€” cell index {idx}\\n\"\n",
    "                    f\"# Source notebook: {notebook_path.name}\\n\"\n",
    "                    f\"# ======================================================================\\n\"\n",
    "                )\n",
    "                collected_blocks.append(header_comment + code_block.rstrip() + \"\\n\\n\")\n",
    "\n",
    "    # --- Write output ---\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        if not collected_blocks:\n",
    "            f.write(\n",
    "                \"# No cells found for Sections 2.5â€“2.8 in notebook \"\n",
    "                f\"{notebook_path.name}\\n\"\n",
    "            )\n",
    "        else:\n",
    "            f.write(\n",
    "                \"# Auto-generated aggregate of Sections 2.5â€“2.8 code cells\\n\"\n",
    "                f\"# Source notebook: {notebook_path.name}\\n\\n\"\n",
    "            )\n",
    "            for block in collected_blocks:\n",
    "                f.write(block)\n",
    "\n",
    "    print(f\"âœ… Wrote {len(collected_blocks)} code blocks to: {out_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Aggregate code cells from Sections 2.5â€“2.8 into a .py file.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--notebook\",\n",
    "        \"-n\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to the source .ipynb notebook\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        \"-o\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to the output .py file\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    notebook_path = Path(args.notebook).resolve()\n",
    "    out_path = Path(args.output).resolve()\n",
    "\n",
    "    if not notebook_path.is_file():\n",
    "        raise FileNotFoundError(f\"Notebook not found: {notebook_path}\")\n",
    "\n",
    "    aggregate_sections(notebook_path, out_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª How to use it in your Telco project\n",
    "\n",
    "From your project root (where the `.ipynb` lives), something like:\n",
    "\n",
    "```bash\n",
    "python scripts/aggregate_section_25_28.py \\\n",
    "  --notebook notebooks/Section2_data_quality.ipynb \\\n",
    "  --output resources/scripts/section2_25_28_aggregate.py\n",
    "```\n",
    "\n",
    "That `section2_25_28_aggregate.py` becomes your **single script version** of all the logic checks / downstream sections, ready for Stage C / Stage D refactor.\n",
    "\n",
    "If you want a variant that **also injects a small `if __name__ == \"__main__\"` driver** or wraps each section into a function, I can spit out that version too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 ðŸ§© Extract and Save All Code Cells From This Notebook\n",
    "# # 0.0 Aggregate > extract > save code from notebook\n",
    "from nbformat import read\n",
    "from pathlib import Path\n",
    "\n",
    "nb = read(\"01_EDA.ipynb\", as_version=4)\n",
    "code_cells = [cell.source for cell in nb.cells if cell.cell_type == \"code\"]\n",
    "Path(\"aggregated_code_10-30-25.py\").write_text(\"\\n\\n\".join(code_cells))\n",
    "print(\"âœ… Extracted code written to aggregated_code.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19774e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§¾ Inline Script (no functions)\n",
    "# fully inline version that you can just drop in a cell or run as a standalone `.py` script.\n",
    "# It extracts all markdown text from a Jupyter notebook and writes it into a single `.md` file.\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# --- Input / output setup ---\n",
    "if len(sys.argv) < 3:\n",
    "    print(\"Usage: python extract_markdown_cells.py notebook.ipynb output.md\")\n",
    "    sys.exit(1)\n",
    "\n",
    "input_path = Path(sys.argv[1])\n",
    "output_path = Path(sys.argv[2])\n",
    "\n",
    "# --- Read notebook JSON ---\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"âŒ Notebook not found: {input_path}\")\n",
    "if input_path.suffix != \".ipynb\":\n",
    "    raise ValueError(\"âŒ Input must be a .ipynb file\")\n",
    "\n",
    "with input_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# --- Collect markdown cell contents ---\n",
    "md_cells = []\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"markdown\":\n",
    "        text = \"\".join(cell.get(\"source\", []))\n",
    "        md_cells.append(text.strip())\n",
    "\n",
    "# --- Write combined markdown file ---\n",
    "if md_cells:\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined = \"\\n\\n---\\n\\n\".join(md_cells)\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(combined)\n",
    "    print(f\"âœ… Extracted {len(md_cells)} markdown cells â†’ {output_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No markdown cells found.\")\n",
    "\n",
    "### ðŸª„ Usage example\n",
    "# python extract_markdown_cells.py Level_3_Telco.ipynb Level_3_Telco_Markdown.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc699f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ§  Optional â€” Run inside a notebook instead of CLI\n",
    "# If you just want to run it **inside Jupyter** (no command-line args), simplify further:\n",
    "# That version is **function-free**, **flat**, and ready to paste into your Telco projectâ€™s tooling notebook or terminal script.\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "input_path = Path(\".Level_3/notebooks/01_EDA.ipynb\")\n",
    "output_path = Path(f\"{datetime.now().strftime('%m%d_%Y_%H%M%S')}_Agg_01_EDA_Telco_Markdown.md\")\n",
    "\n",
    "nb = json.loads(Path(input_path).read_text(encoding=\"utf-8\"))\n",
    "md_cells = [ \"\".join(c[\"source\"]).strip() for c in nb[\"cells\"] if c[\"cell_type\"] == \"markdown\" ]\n",
    "\n",
    "combined = \"\\n\\n---\\n\\n\".join(md_cells)\n",
    "Path(output_path).write_text(combined, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "print(f\"âœ… Wrote {len(md_cells)} markdown cells to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline Aggregate of markdown cells and code comments from a Jupyter notebook\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "input_path = Path(\"01_EDA.ipynb\")\n",
    "output_path = Path(f\"_Agg_md_01_EDA_Telco_{datetime.now().strftime('%m-%d-%Y_%H%M')}.md\")\n",
    "\n",
    "nb = json.loads(input_path.read_text(encoding=\"utf-8\"))\n",
    "md_blocks = []\n",
    "\n",
    "for cell in nb[\"cells\"]:\n",
    "    if cell[\"cell_type\"] == \"markdown\":\n",
    "        md_blocks.append(\"\".join(cell[\"source\"]).strip())\n",
    "    elif cell[\"cell_type\"] == \"code\":\n",
    "        lines = cell[\"source\"]\n",
    "        top_comments = []\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"#\"):\n",
    "                top_comments.append(line.lstrip(\"# \").rstrip())\n",
    "            elif line.strip() == \"\":\n",
    "                top_comments.append(\"\")  # allow spacing within header block\n",
    "            else:\n",
    "                break  # stop at first non-comment line\n",
    "        if top_comments:\n",
    "            md_blocks.append(\"\\n\".join(top_comments).strip())\n",
    "\n",
    "combined = \"\\n\\n---\\n\\n\".join(md_blocks)\n",
    "Path(output_path).write_text(combined, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… Wrote {len(md_blocks)} markdown or comment blocks â†’ {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hereâ€™s a compact Python script that walks a Jupyter notebook and extracts, for each cell:\n",
    "\n",
    "# 1. `document.title = \"...\"` (inside an HTML `<script>` in a **markdown** cell), or\n",
    "# 2. the **first Markdown `#` heading** line in a **markdown** cell, or\n",
    "# 3. the **first `#` comment** line in a **code** cell.\n",
    "\n",
    "# It prints a clean outline and also saves a CSV.\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Extract titles from a Jupyter notebook, using this precedence:\n",
    "  1) From <script> ... document.title=\"...\" ... </script> in a markdown cell\n",
    "  2) First Markdown heading line (# ... ) in a markdown cell\n",
    "  3) First comment line (# ... ) in a code cell\n",
    "Outputs to stdout and writes Notebook_Titles.csv\n",
    "\"\"\"\n",
    "\n",
    "import json, re, csv\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG\n",
    "input_path = Path(\"01_EDA.ipynb\")\n",
    "output_csv = Path(\"./report/Notebook_Titles.csv\")\n",
    "\n",
    "nb = json.loads(input_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Regexes\n",
    "re_doc_title = re.compile(r'document\\.title\\s*=\\s*([\\'\"])(.*?)\\1', re.IGNORECASE | re.DOTALL)\n",
    "re_html_title = re.compile(r'<title[^>]*>(.*?)</title>', re.IGNORECASE | re.DOTALL)\n",
    "re_md_heading = re.compile(r'^\\s{0,3}#{1,6}\\s+(.*\\S)\\s*$', re.MULTILINE)\n",
    "re_code_comment = re.compile(r'^\\s*#\\s*(.*\\S)\\s*$', re.MULTILINE)\n",
    "\n",
    "rows = []\n",
    "for i, cell in enumerate(nb.get(\"cells\", []), start=1):\n",
    "    ctype = cell.get(\"cell_type\")\n",
    "    src = \"\".join(cell.get(\"source\", []))\n",
    "    title = None\n",
    "    source_kind = None\n",
    "\n",
    "    if ctype == \"markdown\":\n",
    "        # 1) document.title in <script>...</script>\n",
    "        m = re_doc_title.search(src)\n",
    "        if m:\n",
    "            title = m.group(2).strip()\n",
    "            source_kind = \"md:script document.title\"\n",
    "        else:\n",
    "            # 1b) <title>...</title>\n",
    "            m = re_html_title.search(src)\n",
    "            if m:\n",
    "                title = re.sub(r'\\s+', ' ', m.group(1)).strip()\n",
    "                source_kind = \"md:<title>\"\n",
    "            else:\n",
    "                # 2) first Markdown # heading\n",
    "                m = re_md_heading.search(src)\n",
    "                if m:\n",
    "                    title = m.group(1).strip()\n",
    "                    source_kind = \"md:# heading\"\n",
    "\n",
    "    elif ctype == \"code\":\n",
    "        # 3) first comment line\n",
    "        m = re_code_comment.search(src)\n",
    "        if m:\n",
    "            title = m.group(1).strip()\n",
    "            source_kind = \"code:# comment\"\n",
    "\n",
    "    if title:\n",
    "        rows.append({\"cell_index\": i, \"cell_type\": ctype, \"source\": source_kind, \"title\": title})\n",
    "\n",
    "# --- Print a readable outline\n",
    "for r in rows:\n",
    "    print(f\"[{r['cell_index']:>3}] ({r['cell_type']:<8} | {r['source']:<22})  {r['title']}\")\n",
    "\n",
    "# --- Save CSV\n",
    "if rows:\n",
    "    with output_csv.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"cell_index\",\"cell_type\",\"source\",\"title\"])\n",
    "        w.writeheader()\n",
    "        w.writerows(rows)\n",
    "    print(f\"\\nâœ… Wrote {len(rows)} titles â†’ {output_csv}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ No titles/headings/comments matched the rules.\")\n",
    "\n",
    "\n",
    "# **Notes**\n",
    "\n",
    "# * It prefers `document.title=\"...\"` if present, then `<title>...</title>`, then Markdown `# ...`, then code `# ...`.\n",
    "# * It collapses whitespace inside `<title>` tags.\n",
    "# * Adjust `input_path` to your notebook file name.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
