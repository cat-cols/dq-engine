{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edae9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def aggregate_code_cells(input_ipynb: str, output_ipynb: str) -> Path:\n",
    "    \"\"\"\n",
    "    Aggregate all code cells from a Jupyter notebook into a new notebook\n",
    "    with a single combined code cell.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_ipynb : str\n",
    "        Path to the source .ipynb file.\n",
    "    output_ipynb : str\n",
    "        Path to the new .ipynb file to create.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        The path to the written aggregated notebook.\n",
    "    \"\"\"\n",
    "    input_path = Path(input_ipynb).expanduser().resolve()\n",
    "    output_path = Path(output_ipynb).expanduser()\n",
    "\n",
    "    if not input_path.is_file():\n",
    "        raise FileNotFoundError(f\"Input notebook not found: {input_path}\")\n",
    "\n",
    "    # --- 1) Load the source notebook ----------------------------------------\n",
    "    with input_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        nb = json.load(f)\n",
    "\n",
    "    cells = nb.get(\"cells\", [])\n",
    "    nbformat = nb.get(\"nbformat\", 4)\n",
    "    nbformat_minor = nb.get(\"nbformat_minor\", 5)\n",
    "\n",
    "    # --- 2) Collect all code from code cells --------------------------------\n",
    "    aggregated_source_lines = []\n",
    "\n",
    "    for idx, cell in enumerate(cells):\n",
    "        if cell.get(\"cell_type\") != \"code\":\n",
    "            continue\n",
    "\n",
    "        src = cell.get(\"source\", [])\n",
    "        if isinstance(src, str):\n",
    "            src_lines = [src]\n",
    "        else:\n",
    "            src_lines = src\n",
    "\n",
    "        # Mark original cell boundaries (optional but helpful)\n",
    "        aggregated_source_lines.append(f\"# ===== Cell {idx} =====\\n\")\n",
    "        aggregated_source_lines.extend(src_lines)\n",
    "\n",
    "        # Ensure a blank line between chunks\n",
    "        if not aggregated_source_lines[-1].endswith(\"\\n\"):\n",
    "            aggregated_source_lines.append(\"\\n\")\n",
    "        aggregated_source_lines.append(\"\\n\")\n",
    "\n",
    "    if not aggregated_source_lines:\n",
    "        aggregated_source_lines = [\"# No code cells found in source notebook.\\n\"]\n",
    "\n",
    "    # --- 3) Build the new notebook structure --------------------------------\n",
    "    aggregated_cell = {\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"source\": aggregated_source_lines,\n",
    "        \"outputs\": [],\n",
    "        \"execution_count\": None,\n",
    "    }\n",
    "\n",
    "    new_nb = {\n",
    "        \"cells\": [aggregated_cell],\n",
    "        \"metadata\": {\n",
    "            \"aggregated_from\": str(input_path),\n",
    "        },\n",
    "        \"nbformat\": nbformat,\n",
    "        \"nbformat_minor\": nbformat_minor,\n",
    "    }\n",
    "\n",
    "    # --- 4) Ensure parent dir exists & write the new notebook ---------------\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(new_nb, f, ensure_ascii=False, indent=1)\n",
    "\n",
    "    print(f\"âœ… Aggregated notebook written to: {output_path.resolve()}\")\n",
    "    return output_path.resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590853e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGGREGATE_PYTHON_CELLS_SCRIPT\n",
    "# Report Aggregator\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Aggregate all Python code cells from a source notebook into a new notebook\n",
    "stored one level up in a 'reports' folder, with:\n",
    "- section-based grouping (1.1, 1.2, etc.)\n",
    "- exactly ONE aggregated code cell per section group\n",
    "- rich metadata + TODO summary\n",
    "- integrity checks to ensure no cells are lost or duplicated\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import platform\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import nbformat\n",
    "from nbformat.v4 import new_notebook, new_markdown_cell\n",
    "\n",
    "# CONFIG\n",
    "\n",
    "# Absolute path to the source notebook\n",
    "NOTEBOOK_PATH = Path(\"/Users/b/DATA/PROJECTS/Telco/Level_3/notebooks/01_EDA.ipynb\")\n",
    "\n",
    "# Timestamp for filenames and metadata\n",
    "START_TIME_UTC = datetime.utcnow()\n",
    "TS_STR = START_TIME_UTC.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Output directory: one level up from \"notebooks\", into \"reports\"\n",
    "OUTPUT_DIR = NOTEBOOK_PATH.parent.parent.parent / \"reports\"\n",
    "OUTPUT_NOTEBOOK_NAME = f\"AGG_ALL_{TS_STR}.ipynb\"\n",
    "OUTPUT_NOTEBOOK_PATH = OUTPUT_DIR / OUTPUT_NOTEBOOK_NAME\n",
    "OUTPUT_METADATA_JSON = OUTPUT_DIR / f\"AGG_ALL_{TS_STR}_metadata.json\"\n",
    "\n",
    "# HELPERS\n",
    "\n",
    "def load_notebook(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Source notebook not found: {path}\")\n",
    "    return nbformat.read(path, as_version=4)\n",
    "\n",
    "def ensure_output_dir(path: Path):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def parse_section_header(md_source: str):\n",
    "    \"\"\"\n",
    "    Try to extract a numbered section tag from a markdown cell.\n",
    "\n",
    "    Looks for patterns like:\n",
    "      '# 1.1 Title', '## 2.3.4 Something', '1.2 Another title', etc.\n",
    "\n",
    "    Returns dict:\n",
    "        {\n",
    "          \"group_key\": \"1.1\",      # top-level or first two components\n",
    "          \"full_tag\": \"1.1.1\",     # full numeric string\n",
    "          \"title\": \"My Section\",   # title text (if present)\n",
    "        }\n",
    "    or None if no numbered header is found.\n",
    "    \"\"\"\n",
    "    for line in md_source.splitlines():\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "\n",
    "        # Remove leading '#' heading markers if present\n",
    "        text = re.sub(r'^#+\\s*', '', stripped)\n",
    "\n",
    "        # Match numeric tag at the start: 1.1, 2.3.4, etc.\n",
    "        m = re.match(r'(?P<tag>\\d+(?:\\.\\d+)+)\\s*(?P<title>.*)', text)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        full_tag = m.group(\"tag\")\n",
    "        title = (m.group(\"title\") or \"\").strip() or f\"Section {full_tag}\"\n",
    "\n",
    "        parts = full_tag.split(\".\")\n",
    "        if len(parts) >= 2:\n",
    "            group_key = \".\".join(parts[:2])  # group by 1.1, 1.2, etc.\n",
    "        else:\n",
    "            group_key = full_tag\n",
    "\n",
    "        return {\n",
    "            \"group_key\": group_key,\n",
    "            \"full_tag\": full_tag,\n",
    "            \"title\": title,\n",
    "        }\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_code_cells_and_groups(nb):\n",
    "    \"\"\"\n",
    "    Extract all non-empty code cells, tracking:\n",
    "      - section grouping (based on nearest numbered markdown header)\n",
    "      - TODO/FIXME comments\n",
    "      - integrity stats\n",
    "\n",
    "    Returns:\n",
    "        section_groups (dict): mapping group_key -> section info:\n",
    "            {\n",
    "                group_key: {\n",
    "                    \"title\": str,\n",
    "                    \"cells\": [\n",
    "                        {\n",
    "                            \"source\": str,\n",
    "                            \"source_index\": int,\n",
    "                            \"todo_lines\": [str],\n",
    "                            \"char_count\": int,\n",
    "                        },\n",
    "                        ...\n",
    "                    ],\n",
    "                    \"first_source_index\": int,\n",
    "                    \"full_tags\": set([...]),\n",
    "                },\n",
    "                ...\n",
    "            }\n",
    "        stats (dict): global stats for code extraction\n",
    "        todo_items (list[str]): list of TODO/FIXME lines (with cell indices)\n",
    "    \"\"\"\n",
    "    section_groups = {}\n",
    "\n",
    "    total_code = 0\n",
    "    non_empty_code = 0\n",
    "    empty_code = 0\n",
    "    non_empty_char_count = 0\n",
    "    todo_items = []\n",
    "\n",
    "    current_group_key = \"UNSECTIONED\"\n",
    "    current_section_title = \"Unsectioned / No numbered header yet\"\n",
    "    current_full_tag = None\n",
    "\n",
    "    for idx, cell in enumerate(nb.cells):\n",
    "        cell_type = cell.get(\"cell_type\")\n",
    "\n",
    "        # Update section context when we hit numbered markdown headers\n",
    "        if cell_type == \"markdown\":\n",
    "            info = parse_section_header(cell.get(\"source\", \"\") or \"\")\n",
    "            if info:\n",
    "                current_group_key = info[\"group_key\"]\n",
    "                current_section_title = info[\"title\"]\n",
    "                current_full_tag = info[\"full_tag\"]\n",
    "            continue\n",
    "\n",
    "        if cell_type != \"code\":\n",
    "            continue\n",
    "\n",
    "        total_code += 1\n",
    "        source = cell.get(\"source\", \"\") or \"\"\n",
    "        if not source.strip():\n",
    "            empty_code += 1\n",
    "            continue\n",
    "\n",
    "        non_empty_code += 1\n",
    "        non_empty_char_count += len(source)\n",
    "\n",
    "        # Collect TODO/FIXME lines\n",
    "        cell_todos = []\n",
    "        for line in source.splitlines():\n",
    "            stripped = line.strip()\n",
    "            if \"TODO\" in stripped or \"FIXME\" in stripped:\n",
    "                cell_todos.append(stripped)\n",
    "\n",
    "        if cell_todos:\n",
    "            todo_items.extend([f\"Cell {idx}: {line}\" for line in cell_todos])\n",
    "\n",
    "        # Ensure a group exists for the current section\n",
    "        if current_group_key not in section_groups:\n",
    "            section_groups[current_group_key] = {\n",
    "                \"title\": current_section_title,\n",
    "                \"cells\": [],\n",
    "                \"first_source_index\": idx,\n",
    "                \"full_tags\": set(),\n",
    "            }\n",
    "\n",
    "        grp = section_groups[current_group_key]\n",
    "        # Update first_source_index if this is earlier\n",
    "        if grp[\"first_source_index\"] is None or idx < grp[\"first_source_index\"]:\n",
    "            grp[\"first_source_index\"] = idx\n",
    "        # Track full tags\n",
    "        if current_full_tag:\n",
    "            grp[\"full_tags\"].add(current_full_tag)\n",
    "\n",
    "        # Append cell info\n",
    "        grp[\"cells\"].append(\n",
    "            {\n",
    "                \"source\": source,\n",
    "                \"source_index\": idx,\n",
    "                \"todo_lines\": cell_todos,\n",
    "                \"char_count\": len(source),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Sanity check: total code vs (empty + non-empty)\n",
    "    assert total_code == empty_code + non_empty_code, (\n",
    "        f\"Code cell accounting mismatch: total={total_code}, \"\n",
    "        f\"empty={empty_code}, non_empty={non_empty_code}\"\n",
    "    )\n",
    "\n",
    "    stats = {\n",
    "        \"total_code_cells_found\": total_code,\n",
    "        \"non_empty_code_cells_extracted\": non_empty_code,\n",
    "        \"empty_code_cells_skipped\": empty_code,\n",
    "        \"non_empty_code_char_count_source\": non_empty_char_count,\n",
    "        \"section_group_count\": len(section_groups),\n",
    "    }\n",
    "    return section_groups, stats, todo_items\n",
    "\n",
    "\n",
    "def build_metadata(nb, code_stats, todo_items, section_groups):\n",
    "    \"\"\"\n",
    "    Build a detailed metadata dict about the aggregation run.\n",
    "    (Also computes destination cell counts and integrity checks.)\n",
    "    \"\"\"\n",
    "    total_cells = len(nb.cells)\n",
    "    markdown_cells = sum(1 for c in nb.cells if c.get(\"cell_type\") == \"markdown\")\n",
    "    raw_cells = sum(1 for c in nb.cells if c.get(\"cell_type\") == \"raw\")\n",
    "    other_cells = total_cells - markdown_cells - raw_cells - code_stats[\"total_code_cells_found\"]\n",
    "\n",
    "    # Section breakdown list\n",
    "    section_breakdown = []\n",
    "    for group_key, grp in sorted(\n",
    "        section_groups.items(),\n",
    "        key=lambda kv: kv[1][\"first_source_index\"],\n",
    "    ):\n",
    "        section_breakdown.append(\n",
    "            {\n",
    "                \"section_group\": group_key,\n",
    "                \"title\": grp[\"title\"],\n",
    "                \"code_cells_in_group\": len(grp[\"cells\"]),\n",
    "                \"first_source_index\": grp[\"first_source_index\"],\n",
    "                \"full_tags\": sorted(t for t in grp[\"full_tags\"] if t),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Destination stats: 2 metadata cells + (header + code) per section\n",
    "    n_groups = len(section_groups)\n",
    "    dest_stats = {\n",
    "        \"total_cells_in_destination\": 2 + 2 * n_groups,\n",
    "        \"code_cells_in_destination\": n_groups,          # 1 per section\n",
    "        \"metadata_cells_in_destination\": 2,             # metadata + TODO\n",
    "        \"section_header_cells_in_destination\": n_groups,\n",
    "    }\n",
    "\n",
    "    # Integrity checks: ensure every non-empty code cell appears exactly once in a group\n",
    "    all_indices = []\n",
    "    for grp in section_groups.values():\n",
    "        for cell_info in grp[\"cells\"]:\n",
    "            all_indices.append(cell_info[\"source_index\"])\n",
    "    unique_indices = set(all_indices)\n",
    "\n",
    "    integrity_checks = {\n",
    "        \"source_non_empty_code_cells\": code_stats[\"non_empty_code_cells_extracted\"],\n",
    "        \"assigned_to_groups_total\": len(all_indices),\n",
    "        \"unique_source_indices_in_groups\": len(unique_indices),\n",
    "        \"all_source_code_cells_assigned_exactly_once\": (\n",
    "            len(all_indices) == len(unique_indices) == code_stats[\"non_empty_code_cells_extracted\"]\n",
    "        ),\n",
    "        \"non_empty_code_char_count_source\": code_stats[\"non_empty_code_char_count_source\"],\n",
    "    }\n",
    "\n",
    "    meta = {\n",
    "        \"run_timestamp_utc\": START_TIME_UTC.isoformat() + \"Z\",\n",
    "        \"run_timestamp_local\": datetime.now().isoformat(),\n",
    "        \"source_notebook\": str(NOTEBOOK_PATH),\n",
    "        \"output_notebook\": str(OUTPUT_NOTEBOOK_PATH),\n",
    "        \"output_metadata_json\": str(OUTPUT_METADATA_JSON),\n",
    "        \"environment\": {\n",
    "            \"python_version\": sys.version,\n",
    "            \"platform\": platform.platform(),\n",
    "            \"executable\": sys.executable,\n",
    "        },\n",
    "        \"notebook_structure\": {\n",
    "            \"total_cells_in_source\": total_cells,\n",
    "            \"code_cells_in_source\": code_stats[\"total_code_cells_found\"],\n",
    "            \"markdown_cells_in_source\": markdown_cells,\n",
    "            \"raw_cells_in_source\": raw_cells,\n",
    "            \"other_cells_in_source\": other_cells,\n",
    "        },\n",
    "        \"aggregation_stats\": {\n",
    "            # Scrape counts\n",
    "            \"total_code_cells_in_source\": code_stats[\"total_code_cells_found\"],\n",
    "            \"non_empty_code_cells_scraped_from_source\": code_stats[\"non_empty_code_cells_extracted\"],\n",
    "            \"empty_code_cells_skipped\": code_stats[\"empty_code_cells_skipped\"],\n",
    "            # Destination counts\n",
    "            \"total_cells_created_in_destination\": dest_stats[\"total_cells_in_destination\"],\n",
    "            \"code_cells_in_destination\": dest_stats[\"code_cells_in_destination\"],\n",
    "            \"metadata_cells_in_destination\": dest_stats[\"metadata_cells_in_destination\"],\n",
    "            \"section_header_cells_in_destination\": dest_stats[\"section_header_cells_in_destination\"],\n",
    "            \"section_group_count\": code_stats[\"section_group_count\"],\n",
    "        },\n",
    "        \"todo_summary\": {\n",
    "            \"todo_items_count\": len(todo_items),\n",
    "            \"todo_items_preview\": todo_items[:20],\n",
    "        },\n",
    "        \"section_breakdown\": section_breakdown,\n",
    "        \"integrity_checks\": integrity_checks,\n",
    "        \"tooling\": {\n",
    "            \"agg_script_name\": \"aggregate_python_cells.py\",\n",
    "            \"version\": \"3.0.0\",\n",
    "            \"description\": (\n",
    "                \"Aggregates Python/code cells from source notebook into a clean \"\n",
    "                \"notebook with exactly one Python cell per numbered section.\"\n",
    "            ),\n",
    "        },\n",
    "    }\n",
    "    return meta\n",
    "\n",
    "\n",
    "def build_metadata_markdown(metadata: dict) -> str:\n",
    "    \"\"\"\n",
    "    Build a human-readable markdown summary of the metadata.\n",
    "    \"\"\"\n",
    "    nb_struct = metadata[\"notebook_structure\"]\n",
    "    agg_stats = metadata[\"aggregation_stats\"]\n",
    "    env = metadata[\"environment\"]\n",
    "    integrity = metadata[\"integrity_checks\"]\n",
    "    sections = metadata[\"section_breakdown\"]\n",
    "\n",
    "    md = []\n",
    "    md.append(\"# ğŸ“¦ Aggregated Python Cells Notebook\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"This notebook was auto-generated by a Python aggregation script.\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"## ğŸ•’ Run Info\")\n",
    "    md.append(f\"- **Run UTC:** `{metadata['run_timestamp_utc']}`\")\n",
    "    md.append(f\"- **Run Local:** `{metadata['run_timestamp_local']}`\")\n",
    "    md.append(f\"- **Source Notebook:** `{metadata['source_notebook']}`\")\n",
    "    md.append(f\"- **Output Notebook:** `{metadata['output_notebook']}`\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"## ğŸ§± Source Notebook Structure\")\n",
    "    md.append(f\"- Total cells: **{nb_struct['total_cells_in_source']}**\")\n",
    "    md.append(f\"- Code cells: **{nb_struct['code_cells_in_source']}**\")\n",
    "    md.append(f\"- Markdown cells: **{nb_struct['markdown_cells_in_source']}**\")\n",
    "    md.append(f\"- Raw cells: **{nb_struct['raw_cells_in_source']}**\")\n",
    "    md.append(f\"- Other cells: **{nb_struct['other_cells_in_source']}**\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"## ğŸ§® Aggregation Stats\")\n",
    "    md.append(f\"- Code cells scraped from source (non-empty): \"\n",
    "              f\"**{agg_stats['non_empty_code_cells_scraped_from_source']}**\")\n",
    "    md.append(f\"- Empty code cells skipped: **{agg_stats['empty_code_cells_skipped']}**\")\n",
    "    md.append(\"\")\n",
    "    md.append(f\"- Cells created in destination notebook: \"\n",
    "              f\"**{agg_stats['total_cells_created_in_destination']}**\")\n",
    "    md.append(f\"  - Code cells (one per section): **{agg_stats['code_cells_in_destination']}**\")\n",
    "    md.append(f\"  - Metadata cells: **{agg_stats['metadata_cells_in_destination']}**\")\n",
    "    md.append(f\"  - Section header cells: **{agg_stats['section_header_cells_in_destination']}**\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"## ğŸ“š Section Grouping Overview\")\n",
    "    md.append(f\"- Number of section groups: **{agg_stats['section_group_count']}**\")\n",
    "    md.append(\"\")\n",
    "    if sections:\n",
    "        for sec in sections:\n",
    "            sec_title = sec[\"title\"]\n",
    "            sec_key = sec[\"section_group\"]\n",
    "            n_cells = sec[\"code_cells_in_group\"]\n",
    "            tags = sec[\"full_tags\"]\n",
    "            if tags:\n",
    "                tag_str = \", \".join(tags)\n",
    "                md.append(f\"- **{sec_key}** â€” {sec_title} \"\n",
    "                          f\"(original code cells merged: **{n_cells}**, tags: `{tag_str}`)\")\n",
    "            else:\n",
    "                md.append(f\"- **{sec_key}** â€” {sec_title} \"\n",
    "                          f\"(original code cells merged: **{n_cells}**)\")\n",
    "    else:\n",
    "        md.append(\"_No numbered sections detected; all cells are grouped under 'UNSECTIONED'._\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"## ğŸ§ª Integrity Checks\")\n",
    "    md.append(\n",
    "        f\"- Non-empty code cells in source: \"\n",
    "        f\"**{integrity['source_non_empty_code_cells']}**\"\n",
    "    )\n",
    "    md.append(\n",
    "        f\"- Total assignments into section groups: \"\n",
    "        f\"**{integrity['assigned_to_groups_total']}**\"\n",
    "    )\n",
    "    md.append(\n",
    "        f\"- Unique source code cell indices in groups: \"\n",
    "        f\"**{integrity['unique_source_indices_in_groups']}**\"\n",
    "    )\n",
    "    md.append(\n",
    "        f\"- All non-empty code cells assigned exactly once: \"\n",
    "        f\"**{'âœ… Yes' if integrity['all_source_code_cells_assigned_exactly_once'] else 'âŒ No (investigate)'}**\"\n",
    "    )\n",
    "    md.append(\n",
    "        f\"- Total characters across non-empty code cells (source): \"\n",
    "        f\"**{integrity['non_empty_code_char_count_source']}**\"\n",
    "    )\n",
    "    md.append(\"\")\n",
    "    md.append(\"## ğŸ’» Environment\")\n",
    "    md.append(f\"- Python: `{env['python_version'].splitlines()[0]}`\")\n",
    "    md.append(f\"- Platform: `{env['platform']}`\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"> Full metadata is also stored in the notebook metadata under `agg_metadata` \"\n",
    "              \"and in the JSON file next to this notebook.\")\n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "\n",
    "def build_todo_markdown(todo_items):\n",
    "    \"\"\"\n",
    "    Build a TODO summary markdown cell.\n",
    "    \"\"\"\n",
    "    md = []\n",
    "    md.append(\"## âœ… Summary of Things That Need To Be Done (Auto-detected TODOs)\")\n",
    "    if not todo_items:\n",
    "        md.append(\"\")\n",
    "        md.append(\"No `TODO` or `FIXME` comments were detected in the source notebook.\")\n",
    "        md.append(\"\")\n",
    "        md.append(\"You can add TODO comments like:\")\n",
    "        md.append(\"```python\")\n",
    "        md.append(\"# TODO: investigate missing values in MonthlyCharges\")\n",
    "        md.append(\"# FIXME: refactor this loop into a function\")\n",
    "        md.append(\"```\")\n",
    "        return \"\\n\".join(md)\n",
    "\n",
    "    md.append(\"\")\n",
    "    md.append(f\"Detected **{len(todo_items)}** TODO/FIXME comment(s) in the source notebook:\")\n",
    "    md.append(\"\")\n",
    "    for item in todo_items:\n",
    "        md.append(f\"- {item}\")\n",
    "    md.append(\"\")\n",
    "    md.append(\"> Tip: As you refactor 01_EDA.ipynb into functions/modules, you can update or clear \"\n",
    "              \"these TODOs and re-run this aggregation script to regenerate an updated TODO summary.\")\n",
    "    return \"\\n\".join(md)\n",
    "\n",
    "\n",
    "def build_aggregated_code_cell(group_key: str, grp: dict):\n",
    "    \"\"\"\n",
    "    Build a single aggregated code cell for a section group by concatenating\n",
    "    all original code cells for that group with clear BEGIN/END markers.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for i, cell_info in enumerate(grp[\"cells\"], start=1):\n",
    "        idx = cell_info[\"source_index\"]\n",
    "        parts.append(\n",
    "            f\"# ----- BEGIN original code cell {idx} \"\n",
    "            f\"(#{i} in section {group_key}) -----\"\n",
    "        )\n",
    "        parts.append(cell_info[\"source\"])\n",
    "        parts.append(f\"# ----- END original code cell {idx} -----\")\n",
    "        parts.append(\"\")  # spacer\n",
    "\n",
    "    combined_source = \"\\n\".join(parts).rstrip() + \"\\n\"\n",
    "    new_cell = nbformat.v4.new_code_cell(source=combined_source)\n",
    "    new_cell.execution_count = None\n",
    "    new_cell.outputs = []\n",
    "    new_cell.metadata[\"agg_source_section_group\"] = group_key\n",
    "    new_cell.metadata[\"agg_original_cell_indices\"] = [\n",
    "        ci[\"source_index\"] for ci in grp[\"cells\"]\n",
    "    ]\n",
    "    return new_cell\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def main():\n",
    "    print(f\"ğŸ” Loading source notebook: {NOTEBOOK_PATH}\")\n",
    "    nb_src = load_notebook(NOTEBOOK_PATH)\n",
    "\n",
    "    print(\"ğŸ“‚ Ensuring output directory exists...\")\n",
    "    ensure_output_dir(OUTPUT_DIR)\n",
    "    print(f\"   â†’ {OUTPUT_DIR}\")\n",
    "\n",
    "    print(\"ğŸ§¬ Extracting code cells + section groups...\")\n",
    "    section_groups, code_stats, todo_items = extract_code_cells_and_groups(nb_src)\n",
    "\n",
    "    print(\"ğŸ§¾ Building metadata...\")\n",
    "    metadata = build_metadata(nb_src, code_stats, todo_items, section_groups)\n",
    "\n",
    "    # Build new notebook\n",
    "    print(\"ğŸ› ï¸ Building aggregated notebook object...\")\n",
    "    nb_new = new_notebook()\n",
    "\n",
    "    # Carry over kernelspec/language_info if present\n",
    "    for key in (\"kernelspec\", \"language_info\"):\n",
    "        if key in nb_src.metadata:\n",
    "            nb_new.metadata[key] = nb_src.metadata[key]\n",
    "\n",
    "    # Attach the aggregation metadata\n",
    "    nb_new.metadata[\"agg_metadata\"] = metadata\n",
    "\n",
    "    # Add metadata + TODO cells\n",
    "    print(\"ğŸ§± Adding metadata + TODO summary markdown cells...\")\n",
    "    nb_new.cells.append(new_markdown_cell(build_metadata_markdown(metadata)))\n",
    "    nb_new.cells.append(new_markdown_cell(build_todo_markdown(todo_items)))\n",
    "\n",
    "    # Add grouped section headers + aggregated code cells\n",
    "    print(\"â• Adding section headers and aggregated code cell(s)...\")\n",
    "    sorted_groups = sorted(\n",
    "        section_groups.items(),\n",
    "        key=lambda kv: kv[1][\"first_source_index\"],\n",
    "    )\n",
    "\n",
    "    for group_key, grp in sorted_groups:\n",
    "        if group_key == \"UNSECTIONED\":\n",
    "            header_title = \"ğŸ§© Unsectioned Code Cells\"\n",
    "            header_desc = (\n",
    "                \"Cells that appear before any numbered section header \"\n",
    "                \"or in areas without a 1.x / 1.1-style heading.\"\n",
    "            )\n",
    "        else:\n",
    "            header_title = f\"ğŸ“š Section {group_key} â€” {grp['title']}\"\n",
    "            header_desc = \"All original code cells for this section merged into one.\"\n",
    "\n",
    "        header_md = []\n",
    "        header_md.append(f\"## {header_title}\")\n",
    "        header_md.append(\"\")\n",
    "        header_md.append(header_desc)\n",
    "        header_md.append(\"\")\n",
    "        header_md.append(f\"- Original code cells merged into this section: **{len(grp['cells'])}**\")\n",
    "        if grp[\"full_tags\"]:\n",
    "            tags_str = \", \".join(sorted(grp[\"full_tags\"]))\n",
    "            header_md.append(f\"- Full section tags seen: `{tags_str}`\")\n",
    "        nb_new.cells.append(new_markdown_cell(\"\\n\".join(header_md)))\n",
    "\n",
    "        # Single aggregated code cell for the section\n",
    "        agg_cell = build_aggregated_code_cell(group_key, grp)\n",
    "        nb_new.cells.append(agg_cell)\n",
    "\n",
    "    # Write notebook\n",
    "    print(f\"ğŸ’¾ Writing aggregated notebook to: {OUTPUT_NOTEBOOK_PATH}\")\n",
    "    nbformat.write(nb_new, OUTPUT_NOTEBOOK_PATH)\n",
    "\n",
    "    # Write metadata JSON\n",
    "    print(f\"ğŸ’¾ Writing metadata JSON to: {OUTPUT_METADATA_JSON}\")\n",
    "    with OUTPUT_METADATA_JSON.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    # Console summary\n",
    "    agg_stats = metadata[\"aggregation_stats\"]\n",
    "    print(\"\\nâœ… Done.\")\n",
    "    print(f\"   Aggregated notebook: {OUTPUT_NOTEBOOK_PATH}\")\n",
    "    print(f\"   Metadata JSON:       {OUTPUT_METADATA_JSON}\")\n",
    "    print(f\"   Non-empty code cells scraped from source: \"\n",
    "          f\"{agg_stats['non_empty_code_cells_scraped_from_source']}\")\n",
    "    print(f\"   Total cells created in destination: \"\n",
    "          f\"{agg_stats['total_cells_created_in_destination']}\")\n",
    "    print(f\"   â†’ Code cells in destination (1 per section): \"\n",
    "          f\"{agg_stats['code_cells_in_destination']}\")\n",
    "    print(f\"   â†’ Section groups: {agg_stats['section_group_count']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# AGGREGATE_PYTHON_CELLS_SCRIPT\n",
    "\"\"\"\n",
    "Aggregate all Python code cells from a Jupyter notebook into a single code cell\n",
    "in a new notebook, skipping this script cell.\n",
    "\n",
    "- Input:  SOURCE_NOTEBOOK\n",
    "- Output: reports/AGG_ALL_{timestamp}.ipynb (one level up from the notebook dir)\n",
    "\"\"\"\n",
    "\n",
    "import nbformat\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. CONFIG: paths\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "SOURCE_NOTEBOOK = Path(\"/Users/b/DATA/PROJECTS/Telco/Level_3/notebooks/01_EDA.ipynb\")\n",
    "\n",
    "# destination: one level up from \"notebooks/\" â†’ \"reports/\"\n",
    "REPORTS_DIR = SOURCE_NOTEBOOK.parent.parent / \"reports\"\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# marker used to identify this script cell so we can skip it\n",
    "SCRIPT_MARKER = \"AGGREGATE_PYTHON_CELLS_SCRIPT\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Load source notebook\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "nb = nbformat.read(SOURCE_NOTEBOOK, as_version=4)\n",
    "\n",
    "included_cells = []\n",
    "skipped_cells = 0\n",
    "total_cells = len(nb.cells)\n",
    "\n",
    "for idx, cell in enumerate(nb.cells):\n",
    "    if cell.cell_type != \"code\":\n",
    "        continue\n",
    "\n",
    "    # Normalize source to a single string\n",
    "    src = cell.source if isinstance(cell.source, str) else \"\".join(cell.source)\n",
    "\n",
    "    # Skip the aggregator script cell (any cell containing the marker)\n",
    "    if SCRIPT_MARKER in src:\n",
    "        skipped_cells += 1\n",
    "        continue\n",
    "\n",
    "    included_cells.append((idx, src))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Build aggregated source (one big code cell)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "aggregated_lines = []\n",
    "\n",
    "for logical_idx, (cell_idx, src) in enumerate(included_cells, start=1):\n",
    "    header = f\"# --- Source code cell {cell_idx} (logical #{logical_idx}) ---\\n\"\n",
    "    aggregated_lines.append(header)\n",
    "    aggregated_lines.append(src.rstrip() + \"\\n\\n\")\n",
    "\n",
    "agg_source = \"\".join(aggregated_lines).rstrip() + \"\\n\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. Create new notebook with single code cell\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_name = f\"AGG_ALL_{timestamp}.ipynb\"\n",
    "OUTPUT_PATH = REPORTS_DIR / output_name\n",
    "\n",
    "new_nb = nbformat.v4.new_notebook(\n",
    "    metadata={\n",
    "        \"kernelspec\": nb.metadata.get(\"kernelspec\", {}),\n",
    "        \"language_info\": nb.metadata.get(\"language_info\", {}),\n",
    "        \"aggregated_from\": str(SOURCE_NOTEBOOK),\n",
    "        \"aggregated_at_utc\": timestamp,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Header markdown cell\n",
    "new_nb.cells.append(\n",
    "    nbformat.v4.new_markdown_cell(\n",
    "        f\"# Aggregated Python Cells\\n\\n\"\n",
    "        f\"- Source: `{SOURCE_NOTEBOOK}`\\n\"\n",
    "        f\"- Generated: `{timestamp} UTC`\\n\"\n",
    "        f\"- Included code cells: `{len(included_cells)}`\\n\"\n",
    "        f\"- Skipped script cells (marker `{SCRIPT_MARKER}`): `{skipped_cells}`\\n\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Single big code cell\n",
    "new_nb.cells.append(\n",
    "    nbformat.v4.new_code_cell(agg_source)\n",
    ")\n",
    "\n",
    "nbformat.write(new_nb, OUTPUT_PATH)\n",
    "\n",
    "print(\"âœ… Aggregation complete\")\n",
    "print(f\"   Source notebook:       {SOURCE_NOTEBOOK}\")\n",
    "print(f\"   Total cells scanned:   {total_cells}\")\n",
    "print(f\"   Code cells included:   {len(included_cells)}\")\n",
    "print(f\"   Script cells skipped:  {skipped_cells}\")\n",
    "print(f\"   Output notebook:       {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b952d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# 1. SET THE PATH TO YOUR SOURCE NOTEBOOK\n",
    "# IMPORTANT: Change this to the actual path of the notebook you want to aggregate.\n",
    "notebook_path = Path(\"/Users/b/DATA/PROJECTS/Telco/Level_3/notebooks/01_EDA.ipynb\") \n",
    "\n",
    "# --- Setup Output Paths ---\n",
    "start_time_utc = datetime.utcnow()\n",
    "today_str = start_time_utc.strftime(\"%Y%m%d%H%M\")\n",
    "output_filename = f\"AGG_ALL_{today_str}.ipynb\"\n",
    "\n",
    "# Define output directory: one level up from notebook's folder, then into 'reports'\n",
    "OUTPUT_DIR = notebook_path.parent.parent / \"reports\"\n",
    "OUTPUT_PATH = OUTPUT_DIR / output_filename\n",
    "\n",
    "# Ensure the output directory exists\n",
    "try:\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERROR: Could not create output directory {OUTPUT_DIR}: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"Attempting to read source notebook: {notebook_path.resolve()}\")\n",
    "\n",
    "# --- Core Extraction Logic ---\n",
    "new_notebook_cells = []\n",
    "source_kernel_spec = {\n",
    "    \"display_name\": \"Python 3 (ipykernel)\", \n",
    "    \"language\": \"python\", \n",
    "    \"name\": \"python3\"\n",
    "}\n",
    "cells_extracted_count = 0\n",
    "\n",
    "if not notebook_path.exists():\n",
    "    print(f\"âŒ ERROR: Source file not found at {notebook_path.resolve()}\")\n",
    "else:\n",
    "    try:\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            notebook_json = json.load(f)\n",
    "\n",
    "        # Try to capture the source kernel spec for the new notebook\n",
    "        if 'kernelspec' in notebook_json.get('metadata', {}):\n",
    "            source_kernel_spec = notebook_json['metadata']['kernelspec']\n",
    "            \n",
    "        if 'cells' not in notebook_json:\n",
    "            print(\"âŒ ERROR: Invalid notebook format. Missing 'cells' key.\")\n",
    "        else:\n",
    "            \n",
    "            # --- 2. Iterate and Extract Code Cells (WITHOUT added comments) ---\n",
    "            for cell in notebook_json['cells']:\n",
    "                if cell.get('cell_type') == 'code':\n",
    "                    source_lines = cell.get('source', [])\n",
    "                    cell_code_list = []\n",
    "                    \n",
    "                    if isinstance(source_lines, list):\n",
    "                        # Join and strip to check if it's empty\n",
    "                        if not \"\".join(source_lines).strip():\n",
    "                            continue\n",
    "                        cell_code_list = source_lines\n",
    "                        \n",
    "                    elif isinstance(source_lines, str):\n",
    "                        if not source_lines.strip():\n",
    "                            continue\n",
    "                        cell_code_list = [source_lines]\n",
    "\n",
    "                    # Create the JSON structure for a clean code cell\n",
    "                    new_notebook_cells.append({\n",
    "                        \"cell_type\": \"code\",\n",
    "                        \"execution_count\": None, \n",
    "                        \"metadata\": {},\n",
    "                        \"outputs\": [],\n",
    "                        \"source\": cell_code_list\n",
    "                    })\n",
    "                    cells_extracted_count += 1\n",
    "\n",
    "            \n",
    "            # --- 3. Create Header Cell with Metadata ---\n",
    "            # This is done *after* extraction to get the correct cell count.\n",
    "            markdown_source = [\n",
    "                f\"# ğŸ“Š Aggregated Code Report: {notebook_path.name}\\n\\n\",\n",
    "                \"This notebook contains a cleaned, sequential aggregation of all \",\n",
    "                f\"**{cells_extracted_count}** non-empty Python code cells \",\n",
    "                \"extracted from the source notebook.\\n\\n\",\n",
    "                \"---\",\n",
    "                f\"\\n**Report Creation Time (UTC):** `{start_time_utc.strftime('%Y-%m-%d %H:%M:%S')}`\",\n",
    "                f\"\\n**Source Path:** `{notebook_path.resolve()}`\",\n",
    "                f\"\\n**Python Version:** `{platform.python_version()}`\",\n",
    "                f\"\\n**Kernel:** `{source_kernel_spec.get('display_name', 'Unknown')}`\",\n",
    "            ]\n",
    "            header_cell = {\n",
    "                \"cell_type\": \"markdown\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": markdown_source\n",
    "            }\n",
    "            \n",
    "            # Insert the header cell at the very beginning\n",
    "            new_notebook_cells.insert(0, header_cell)\n",
    "            \n",
    "            \n",
    "            # --- 4. Assemble and Save the New Notebook JSON ---\n",
    "            if cells_extracted_count > 0:\n",
    "                notebook_content = {\n",
    "                    \"cells\": new_notebook_cells,\n",
    "                    \"metadata\": {\n",
    "                        \"kernelspec\": source_kernel_spec,\n",
    "                        \"language_info\": {\"name\": \"python\"},\n",
    "                    },\n",
    "                    \"nbformat\": 4, \n",
    "                    \"nbformat_minor\": 5\n",
    "                }\n",
    "                \n",
    "                with open(OUTPUT_PATH, 'w', encoding='utf-8') as outfile:\n",
    "                    json.dump(notebook_content, outfile, indent=4)\n",
    "                \n",
    "                print(f\"\\nâœ… Success! Aggregated {cells_extracted_count} code cells.\")\n",
    "                print(f\"ğŸ’¾ Notebook saved to: {OUTPUT_PATH.resolve()}\")\n",
    "\n",
    "            else:\n",
    "                print(\"âš ï¸ No code cells found to aggregate.\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"âŒ ERROR: Could not decode JSON from {notebook_path.name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ An unexpected error occurred: {e}\")\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import nbformat\n",
    "from nbformat.v4 import new_notebook, new_markdown_cell, new_code_cell\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Locate the current notebook\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# This assumes you're running in an environment (e.g. VS Code / Windsurf)\n",
    "# where sys.argv[0] is the path to the .ipynb file.\n",
    "nb_candidate = Path(sys.argv[0])\n",
    "nb_path = Path('/Users/b/DATA/PROJECTS/Telco/Level_3/notebooks/01_EDA.ipynb').resolve()\n",
    "\n",
    "# if nb_candidate.suffix == \".ipynb\" and nb_candidate.exists():\n",
    "#     nb_path = nb_candidate.resolve()\n",
    "# else:\n",
    "#     raise RuntimeError(\n",
    "#         \"Could not automatically determine notebook path.\\n\"\n",
    "#         \"Set nb_path manually, e.g.:\\n\"\n",
    "#         \"  nb_path = Path('01_EDA.ipynb').resolve()\"\n",
    "#     )\n",
    "\n",
    "print(f\"ğŸ“„ Source notebook: {nb_path}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Read the notebook & collect all code (Python) cells\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "nb = nbformat.read(nb_path, as_version=4)\n",
    "\n",
    "code_cells = [cell for cell in nb.cells if cell.get(\"cell_type\") == \"code\"]\n",
    "n_code_cells = len(code_cells)\n",
    "print(f\"ğŸ”¢ Found {n_code_cells} code cells to aggregate.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Build header cell with metadata (markdown only)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "run_ts = datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
    "cwd = Path.cwd()\n",
    "py_ver = sys.version.split()[0]\n",
    "\n",
    "header_md = f\"\"\"# Aggregated Python Cells Report\n",
    "\n",
    "- **Source notebook:** `{nb_path.name}`\n",
    "- **Created at (UTC):** `{run_ts}`\n",
    "- **Number of code cells:** `{n_code_cells}`\n",
    "- **Working directory when created:** `{cwd}`\n",
    "- **Python version:** `{py_ver}`\n",
    "\n",
    "> This notebook was auto-generated by an inline aggregation script.\n",
    "> All code cells below are copied verbatim from the source notebook.\n",
    "\"\"\"\n",
    "\n",
    "header_cell = new_markdown_cell(header_md)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4. Construct the new notebook (header + raw code cells)\n",
    "#    NOTE: we do *not* modify any code cell contents.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "out_cells = [header_cell]\n",
    "\n",
    "for cell in code_cells:\n",
    "    # Copy source exactly; no comments/prints are added to the code.\n",
    "    out_cells.append(\n",
    "        new_code_cell(\n",
    "            source=cell.get(\"source\", \"\"),\n",
    "            metadata=cell.get(\"metadata\", {})\n",
    "        )\n",
    "    )\n",
    "\n",
    "out_nb = new_notebook(\n",
    "    cells=out_cells,\n",
    "    metadata={\n",
    "        \"aggregated_from\": str(nb_path),\n",
    "        \"created_utc\": run_ts,\n",
    "        \"n_code_cells\": n_code_cells,\n",
    "        \"tool\": \"agg_all_inline_v1\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5. Save as AGG_ALL_{date}.ipynb in ../reports\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# \"reports folder a level up\" relative to the notebook file:\n",
    "reports_dir = nb_path.parent.parent / \"reports\"\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ts_str = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = reports_dir / f\"AGG_ALL_{ts_str}.ipynb\"\n",
    "\n",
    "nbformat.write(out_nb, out_path)\n",
    "\n",
    "print(f\"âœ… Aggregated notebook written â†’ {out_path}\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# ============================================================================\n",
    "# 0. CONFIG: where your notebooks live, and which ones belong to each section\n",
    "# ============================================================================\n",
    "\n",
    "# Base notebooks directory\n",
    "BASE_NOTEBOOK_DIR = Path(\"/Users/b/DATA/PROJECTS/Telco/Level_3/notebooks\")\n",
    "\n",
    "# Map logical sections â†’ filename patterns (glob)\n",
    "# Adjust patterns to match your project naming.\n",
    "SECTION_PATTERNS = {\n",
    "    \"Section 1\": [\"01_*.ipynb\", \"1_*.ipynb\"],\n",
    "    \"Section 2\": [\"02_*.ipynb\", \"2_*.ipynb\"],\n",
    "    \"Section 3\": [\"03_*.ipynb\", \"3_*.ipynb\"],\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Helper: expand glob patterns to concrete notebook paths\n",
    "# ----------------------------------------------------------------------------\n",
    "def _expand_patterns(base_dir: Path, patterns):\n",
    "    paths = []\n",
    "    for pat in patterns:\n",
    "        paths.extend(sorted(base_dir.glob(pat)))\n",
    "    # De-duplicate while preserving order\n",
    "    seen = set()\n",
    "    uniq = []\n",
    "    for p in paths:\n",
    "        if p not in seen:\n",
    "            uniq.append(p)\n",
    "            seen.add(p)\n",
    "    return uniq\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Resolve notebooks per section + ensure all source notebooks are included\n",
    "# ============================================================================\n",
    "\n",
    "if not BASE_NOTEBOOK_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Notebook directory not found: {BASE_NOTEBOOK_DIR}\")\n",
    "\n",
    "sections_notebooks = {}\n",
    "all_assigned = set()\n",
    "\n",
    "for section_label, patterns in SECTION_PATTERNS.items():\n",
    "    nb_paths = _expand_patterns(BASE_NOTEBOOK_DIR, patterns)\n",
    "    sections_notebooks[section_label] = nb_paths\n",
    "    all_assigned.update(nb_paths)\n",
    "\n",
    "# All \"source\" notebooks in this dir (excluding previous AGG_ALL outputs)\n",
    "all_notebooks = sorted(\n",
    "    p for p in BASE_NOTEBOOK_DIR.glob(\"*.ipynb\")\n",
    "    if not p.name.startswith(\"AGG_ALL_\")\n",
    ")\n",
    "\n",
    "unassigned = [p for p in all_notebooks if p not in all_assigned]\n",
    "\n",
    "if unassigned:\n",
    "    print(\"âš ï¸ The following notebooks did not match any SECTION_PATTERNS \"\n",
    "          \"and will be auto-assigned to Section 3:\")\n",
    "    for p in unassigned:\n",
    "        print(f\"   - {p.name}\")\n",
    "    # Ensure Section 3 exists\n",
    "    sections_notebooks.setdefault(\"Section 3\", [])\n",
    "    sections_notebooks[\"Section 3\"].extend(unassigned)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Setup output paths\n",
    "# ============================================================================\n",
    "\n",
    "start_time_utc = datetime.utcnow()\n",
    "today_str = start_time_utc.strftime(\"%Y%m%d%H%M\")\n",
    "output_filename = f\"AGG_ALL_{today_str}.ipynb\"\n",
    "\n",
    "OUTPUT_DIR = BASE_NOTEBOOK_DIR.parent / \"reports\"\n",
    "OUTPUT_PATH = OUTPUT_DIR / output_filename\n",
    "\n",
    "try:\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERROR: Could not create output directory {OUTPUT_DIR}: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"ğŸ“‚ Base notebook directory: {BASE_NOTEBOOK_DIR.resolve()}\")\n",
    "print(f\"ğŸ’¾ Aggregated notebook will be saved to: {OUTPUT_PATH.resolve()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Aggregate code cells, grouped by Section 1 / Section 2 / Section 3\n",
    "# ============================================================================\n",
    "\n",
    "new_notebook_cells = []\n",
    "source_kernel_spec = {\n",
    "    \"display_name\": \"Python 3 (ipykernel)\",\n",
    "    \"language\": \"python\",\n",
    "    \"name\": \"python3\",\n",
    "}\n",
    "got_kernel_spec = False\n",
    "\n",
    "total_code_cells = 0\n",
    "section_code_counts = {sec: 0 for sec in sections_notebooks.keys()}\n",
    "per_notebook_counts = {}\n",
    "\n",
    "for section_label in [\"Section 1\", \"Section 2\", \"Section 3\"]:\n",
    "    nb_paths = sections_notebooks.get(section_label, [])\n",
    "    if not nb_paths:\n",
    "        continue\n",
    "\n",
    "    # Section header (markdown only)\n",
    "    new_notebook_cells.append({\n",
    "        \"cell_type\": \"markdown\",\n",
    "        \"metadata\": {},\n",
    "        \"source\": [f\"# {section_label}\\n\\n\"]\n",
    "    })\n",
    "\n",
    "    for nb_path in nb_paths:\n",
    "        nb_path = nb_path.resolve()\n",
    "        if not nb_path.exists():\n",
    "            print(f\"âŒ ERROR: Notebook not found: {nb_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"ğŸ” Processing {section_label}: {nb_path.name}\")\n",
    "\n",
    "        try:\n",
    "            with open(nb_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                notebook_json = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"âŒ ERROR: Could not decode JSON from {nb_path.name}. Skipping.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ERROR reading {nb_path.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Capture kernelspec once (from first valid source notebook)\n",
    "        if not got_kernel_spec and \"kernelspec\" in notebook_json.get(\"metadata\", {}):\n",
    "            source_kernel_spec = notebook_json[\"metadata\"][\"kernelspec\"]\n",
    "            got_kernel_spec = True\n",
    "\n",
    "        if \"cells\" not in notebook_json:\n",
    "            print(f\"âŒ ERROR: Invalid notebook format (no 'cells') in {nb_path.name}.\")\n",
    "            continue\n",
    "\n",
    "        nb_code_count = 0\n",
    "\n",
    "        # Per-notebook header (markdown only)\n",
    "        new_notebook_cells.append({\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                f\"## {nb_path.name}\\n\\n\",\n",
    "                f\"_Source: `{nb_path}`_\\n\"\n",
    "            ],\n",
    "        })\n",
    "\n",
    "        # Extract code cells (Python) without modifying their contents\n",
    "        for cell in notebook_json[\"cells\"]:\n",
    "            if cell.get(\"cell_type\") != \"code\":\n",
    "                continue\n",
    "\n",
    "            source_lines = cell.get(\"source\", [])\n",
    "            cell_code_list = []\n",
    "\n",
    "            if isinstance(source_lines, list):\n",
    "                if not \"\".join(source_lines).strip():\n",
    "                    continue  # skip truly empty code cells\n",
    "                cell_code_list = source_lines\n",
    "            elif isinstance(source_lines, str):\n",
    "                if not source_lines.strip():\n",
    "                    continue\n",
    "                cell_code_list = [source_lines]\n",
    "            else:\n",
    "                # Unknown source type, skip\n",
    "                continue\n",
    "\n",
    "            new_notebook_cells.append({\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": cell_code_list,  # â† exact code, no added text\n",
    "            })\n",
    "            nb_code_count += 1\n",
    "            total_code_cells += 1\n",
    "            section_code_counts[section_label] += 1\n",
    "\n",
    "        per_notebook_counts[str(nb_path)] = nb_code_count\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Build top-level header cell with metadata (after counts are known)\n",
    "# ============================================================================\n",
    "\n",
    "markdown_source = []\n",
    "\n",
    "markdown_source.append(\"# ğŸ“Š Aggregated Code Report: Sections 1â€“3\\n\\n\")\n",
    "markdown_source.append(\n",
    "    \"This notebook contains a cleaned, sequential aggregation of all \"\n",
    "    f\"**{total_code_cells}** non-empty Python code cells grouped into \"\n",
    "    \"**Section 1**, **Section 2**, and **Section 3**.\\n\\n\"\n",
    ")\n",
    "markdown_source.append(\"---\")\n",
    "\n",
    "markdown_source.append(\n",
    "    f\"\\n**Report Creation Time (UTC):** \"\n",
    "    f\"`{start_time_utc.strftime('%Y-%m-%d %H:%M:%S')}`\"\n",
    ")\n",
    "markdown_source.append(\n",
    "    f\"\\n**Notebook Base Directory:** `{BASE_NOTEBOOK_DIR.resolve()}`\"\n",
    ")\n",
    "markdown_source.append(\n",
    "    f\"\\n**Python Version:** `{platform.python_version()}`\"\n",
    ")\n",
    "markdown_source.append(\n",
    "    f\"\\n**Kernel (source):** \"\n",
    "    f\"`{source_kernel_spec.get('display_name', 'Unknown')}`\"\n",
    ")\n",
    "\n",
    "markdown_source.append(\"\\n\\n**Section breakdown (code cells):**\\n\")\n",
    "for sec in [\"Section 1\", \"Section 2\", \"Section 3\"]:\n",
    "    if sec in section_code_counts:\n",
    "        markdown_source.append(\n",
    "            f\"- {sec}: {section_code_counts[sec]} code cells\\n\"\n",
    "        )\n",
    "\n",
    "markdown_source.append(\"\\n**Included notebooks:**\\n\")\n",
    "for sec in [\"Section 1\", \"Section 2\", \"Section 3\"]:\n",
    "    nb_paths = sections_notebooks.get(sec, [])\n",
    "    if not nb_paths:\n",
    "        continue\n",
    "    markdown_source.append(f\"- {sec}:\\n\")\n",
    "    for nb_path in nb_paths:\n",
    "        nb_path_str = str(nb_path.resolve())\n",
    "        count = per_notebook_counts.get(nb_path_str, 0)\n",
    "        markdown_source.append(\n",
    "            f\"  - `{Path(nb_path_str).name}` ({count} code cells)\\n\"\n",
    "        )\n",
    "\n",
    "header_cell = {\n",
    "    \"cell_type\": \"markdown\",\n",
    "    \"metadata\": {},\n",
    "    \"source\": markdown_source,\n",
    "}\n",
    "\n",
    "# Insert header at very beginning\n",
    "new_notebook_cells.insert(0, header_cell)\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Assemble and save the new aggregated notebook\n",
    "# ============================================================================\n",
    "\n",
    "if total_code_cells == 0:\n",
    "    print(\"âš ï¸ No code cells found to aggregate. Notebook will not be written.\")\n",
    "else:\n",
    "    notebook_content = {\n",
    "        \"cells\": new_notebook_cells,\n",
    "        \"metadata\": {\n",
    "            \"kernelspec\": source_kernel_spec,\n",
    "            \"language_info\": {\"name\": \"python\"},\n",
    "            \"aggregated_sections\": [\"Section 1\", \"Section 2\", \"Section 3\"],\n",
    "            \"aggregated_from_dir\": str(BASE_NOTEBOOK_DIR.resolve()),\n",
    "            \"created_utc\": start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            \"total_code_cells\": total_code_cells,\n",
    "            \"section_code_counts\": section_code_counts,\n",
    "            \"tool\": \"agg_all_sections_v1\",\n",
    "        },\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 5,\n",
    "    }\n",
    "\n",
    "    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        json.dump(notebook_content, outfile, indent=4)\n",
    "\n",
    "    print(f\"\\nâœ… Success! Aggregated {total_code_cells} code cells in total.\")\n",
    "    print(f\"ğŸ’¾ Notebook saved to: {OUTPUT_PATH.resolve()}\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import platform\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. SET THE PATH TO YOUR SOURCE NOTEBOOK (fixed)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "notebook_path = Path(\"/Users/b/DATA/PROJECTS/Telco/Level_3/notebooks/01_EDA.ipynb\")\n",
    "\n",
    "# --- Setup Output Paths ---\n",
    "start_time_utc = datetime.utcnow()\n",
    "today_str = start_time_utc.strftime(\"%Y%m%d%H%M\")\n",
    "output_filename = f\"AGG_ALL_{today_str}.ipynb\"\n",
    "\n",
    "# Output: one level up from notebook folder, in 'reports'\n",
    "OUTPUT_DIR = notebook_path.parent.parent / \"reports\"\n",
    "OUTPUT_PATH = OUTPUT_DIR / output_filename\n",
    "\n",
    "# Ensure the output directory exists\n",
    "try:\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERROR: Could not create output directory {OUTPUT_DIR}: {e}\")\n",
    "    raise\n",
    "\n",
    "print(f\"Attempting to read source notebook: {notebook_path.resolve()}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Core Extraction Logic (Section 1 / 2 / 3)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Buckets for sectioned code cells\n",
    "section_cells = {\n",
    "    \"Section 1\": [],\n",
    "    \"Section 2\": [],\n",
    "    \"Section 3\": [],\n",
    "}\n",
    "\n",
    "source_kernel_spec = {\n",
    "    \"display_name\": \"Python 3 (ipykernel)\",\n",
    "    \"language\": \"python\",\n",
    "    \"name\": \"python3\",\n",
    "}\n",
    "cells_extracted_count = 0\n",
    "\n",
    "def _detect_section_from_markdown(md_source, current_section):\n",
    "    \"\"\"\n",
    "    Look at markdown text and update section if it contains 'Section 1/2/3'.\n",
    "    Returns the new current_section.\n",
    "    \"\"\"\n",
    "    if isinstance(md_source, list):\n",
    "        text = \"\".join(md_source)\n",
    "    else:\n",
    "        text = str(md_source)\n",
    "    lower = text.lower()\n",
    "\n",
    "    if \"section 3\" in lower:\n",
    "        return \"Section 3\"\n",
    "    if \"section 2\" in lower:\n",
    "        return \"Section 2\"\n",
    "    if \"section 1\" in lower:\n",
    "        return \"Section 1\"\n",
    "    return current_section\n",
    "\n",
    "if not notebook_path.exists():\n",
    "    print(f\"âŒ ERROR: Source file not found at {notebook_path.resolve()}\")\n",
    "else:\n",
    "    try:\n",
    "        with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            notebook_json = json.load(f)\n",
    "\n",
    "        # Try to capture the source kernel spec for the new notebook\n",
    "        if \"kernelspec\" in notebook_json.get(\"metadata\", {}):\n",
    "            source_kernel_spec = notebook_json[\"metadata\"][\"kernelspec\"]\n",
    "\n",
    "        if \"cells\" not in notebook_json:\n",
    "            print(\"âŒ ERROR: Invalid notebook format. Missing 'cells' key.\")\n",
    "        else:\n",
    "            # Default: assume we're in Section 1 until a header says otherwise\n",
    "            current_section = \"Section 1\"\n",
    "\n",
    "            # Walk through all cells in order\n",
    "            for cell in notebook_json[\"cells\"]:\n",
    "                cell_type = cell.get(\"cell_type\")\n",
    "\n",
    "                if cell_type == \"markdown\":\n",
    "                    # Update current_section if markdown mentions a Section heading\n",
    "                    current_section = _detect_section_from_markdown(\n",
    "                        cell.get(\"source\", \"\"), current_section\n",
    "                    )\n",
    "\n",
    "                elif cell_type == \"code\":\n",
    "                    # Extract code cell into current section bucket\n",
    "                    source_lines = cell.get(\"source\", [])\n",
    "                    cell_code_list = []\n",
    "\n",
    "                    if isinstance(source_lines, list):\n",
    "                        if not \"\".join(source_lines).strip():\n",
    "                            continue  # skip truly empty cells\n",
    "                        cell_code_list = source_lines\n",
    "                    elif isinstance(source_lines, str):\n",
    "                        if not source_lines.strip():\n",
    "                            continue\n",
    "                        cell_code_list = [source_lines]\n",
    "                    else:\n",
    "                        continue  # unknown format, skip\n",
    "\n",
    "                    # Create a clean code cell (NO added content to 'source')\n",
    "                    code_cell = {\n",
    "                        \"cell_type\": \"code\",\n",
    "                        \"execution_count\": None,\n",
    "                        \"metadata\": {},\n",
    "                        \"outputs\": [],\n",
    "                        \"source\": cell_code_list,\n",
    "                    }\n",
    "\n",
    "                    # Ensure section exists, then append\n",
    "                    section_cells.setdefault(current_section, []).append(code_cell)\n",
    "                    cells_extracted_count += 1\n",
    "\n",
    "            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            # 3. Build the new notebook cell list\n",
    "            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            new_notebook_cells = []\n",
    "\n",
    "            # Header markdown (overall metadata)\n",
    "            header_md = [\n",
    "                \"# ğŸ“Š Aggregated Code Report: 01_EDA Sections 1â€“3\\n\\n\",\n",
    "                \"This notebook contains a cleaned, sequential aggregation of all \",\n",
    "                f\"**{cells_extracted_count}** non-empty Python code cells \",\n",
    "                \"from the source notebook, grouped into **Section 1**, **Section 2**, and **Section 3** \",\n",
    "                \"based on markdown headings that mention those sections.\\n\\n\",\n",
    "                \"---\",\n",
    "                f\"\\n**Report Creation Time (UTC):** `{start_time_utc.strftime('%Y-%m-%d %H:%M:%S')}`\",\n",
    "                f\"\\n**Source Path:** `{notebook_path.resolve()}`\",\n",
    "                f\"\\n**Python Version:** `{platform.python_version()}`\",\n",
    "                f\"\\n**Kernel:** `{source_kernel_spec.get('display_name', 'Unknown')}`\",\n",
    "                \"\\n\\n**Section breakdown (code cells):**\\n\",\n",
    "            ]\n",
    "\n",
    "            for sec_name in [\"Section 1\", \"Section 2\", \"Section 3\"]:\n",
    "                header_md.append(\n",
    "                    f\"- {sec_name}: {len(section_cells.get(sec_name, []))} code cells\\n\"\n",
    "                )\n",
    "\n",
    "            header_cell = {\n",
    "                \"cell_type\": \"markdown\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": header_md,\n",
    "            }\n",
    "\n",
    "            new_notebook_cells.append(header_cell)\n",
    "\n",
    "            # Add per-section markdown headers + code cells\n",
    "            for sec_name in [\"Section 1\", \"Section 2\", \"Section 3\"]:\n",
    "                cells_in_section = section_cells.get(sec_name, [])\n",
    "                if not cells_in_section:\n",
    "                    continue  # skip empty sections\n",
    "\n",
    "                # Section header\n",
    "                new_notebook_cells.append(\n",
    "                    {\n",
    "                        \"cell_type\": \"markdown\",\n",
    "                        \"metadata\": {},\n",
    "                        \"source\": [f\"# {sec_name}\\n\\n\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Code cells (verbatim source)\n",
    "                new_notebook_cells.extend(cells_in_section)\n",
    "\n",
    "            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            # 4. Assemble and save the new notebook JSON\n",
    "            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            if cells_extracted_count > 0:\n",
    "                notebook_content = {\n",
    "                    \"cells\": new_notebook_cells,\n",
    "                    \"metadata\": {\n",
    "                        \"kernelspec\": source_kernel_spec,\n",
    "                        \"language_info\": {\"name\": \"python\"},\n",
    "                        \"aggregated_from\": str(notebook_path.resolve()),\n",
    "                        \"created_utc\": start_time_utc.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                        \"total_code_cells\": cells_extracted_count,\n",
    "                        \"section_code_counts\": {\n",
    "                            sec: len(cells)\n",
    "                            for sec, cells in section_cells.items()\n",
    "                        },\n",
    "                        \"tool\": \"agg_single_notebook_sections_v1\",\n",
    "                    },\n",
    "                    \"nbformat\": 4,\n",
    "                    \"nbformat_minor\": 5,\n",
    "                }\n",
    "\n",
    "                with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as outfile:\n",
    "                    json.dump(notebook_content, outfile, indent=4)\n",
    "\n",
    "                print(f\"\\nâœ… Success! Aggregated {cells_extracted_count} code cells.\")\n",
    "                print(f\"ğŸ’¾ Notebook saved to: {OUTPUT_PATH.resolve()}\")\n",
    "            else:\n",
    "                print(\"âš ï¸ No code cells found to aggregate.\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"âŒ ERROR: Could not decode JSON from {notebook_path.name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“œ AGGREGATE Python cells THAT START WITH \"# 1\"\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Define your notebook path ---\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")   # or Path(__file__).parent / \"01_Environment.ipynb\"\n",
    "OUTPUT_PATH   = NOTEBOOK_PATH.with_name(\"aggregated_section1.py\")\n",
    "\n",
    "# --- Load notebook JSON ---\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“˜ Loaded notebook â†’ {NOTEBOOK_PATH.name}\")\n",
    "print(\"ğŸ” Searching for Python cells starting with '# 1' ...\")\n",
    "\n",
    "# --- Extract code cells whose *first line* starts with '# 1'\n",
    "aggregated_blocks = []\n",
    "\n",
    "for cell in nb[\"cells\"]:\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        first_line = src.strip().splitlines()[0] if src.strip() else \"\"\n",
    "        if first_line.startswith(\"# 1\"):\n",
    "            aggregated_blocks.append(src.strip())\n",
    "\n",
    "# --- Combine all matches ---\n",
    "aggregated_script = \"\\n\\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\".join(aggregated_blocks)\n",
    "\n",
    "# --- Write output (if any) ---\n",
    "if aggregated_blocks:\n",
    "    OUTPUT_PATH.write_text(aggregated_script, encoding=\"utf-8\")\n",
    "    print(f\"âœ… Aggregated {len(aggregated_blocks)} cells â†’ {OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No code cells starting with '# 1' were found.\")\n",
    "\n",
    "# Optional: Display preview\n",
    "print(\"\\n--- Aggregated Script Preview ---\")\n",
    "print(\"\\n\".join(aggregated_script.splitlines()[:20]))\n",
    "\n",
    "# ğŸ“œ AGGREGATE Section 2.0 python\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Define your notebook path ---\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")   # or Path(__file__).parent / \"01_Environment.ipynb\"\n",
    "OUTPUT_PATH   = NOTEBOOK_PATH.with_name(\"aggregated_section2_0.py\")\n",
    "\n",
    "# --- Load notebook JSON ---\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“˜ Loaded notebook â†’ {NOTEBOOK_PATH.name}\")\n",
    "print(\"ğŸ” Searching for Python cells starting with '# 2.0' ...\")\n",
    "\n",
    "# --- Extract code cells whose *first line* starts with '# 2.0'\n",
    "aggregated_blocks = []\n",
    "\n",
    "for cell in nb[\"cells\"]:\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        first_line = src.strip().splitlines()[0] if src.strip() else \"\"\n",
    "        if first_line.startswith(\"# 2.0\"):\n",
    "            aggregated_blocks.append(src.strip())\n",
    "\n",
    "# --- Combine all matches ---\n",
    "aggregated_script = \"\\n\\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\\n\".join(aggregated_blocks)\n",
    "\n",
    "# --- Write output (if any) ---\n",
    "if aggregated_blocks:\n",
    "    OUTPUT_PATH.write_text(aggregated_script, encoding=\"utf-8\")\n",
    "    print(f\"âœ… Aggregated {len(aggregated_blocks)} cells â†’ {OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No code cells starting with '# 2.0' were found.\")\n",
    "\n",
    "# Optional: Display preview\n",
    "print(\"\\n--- Aggregated Script Preview ---\")\n",
    "print(\"\\n\".join(aggregated_script.splitlines()[:20]))\n",
    "\n",
    "# Aggregating Section 2 Code into .py\n",
    "import json, io, os\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1ï¸âƒ£ Try to infer current notebook name (works in most Jupyter setups)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "    if ip is not None and hasattr(ip, 'kernel'):\n",
    "        connection_file = Path(ip.kernel.connection_file)\n",
    "        notebook_name = next(\n",
    "            (p.name for p in Path('.').glob('*.ipynb') if str(p.stat().st_ino) in str(connection_file)),\n",
    "            None\n",
    "        )\n",
    "    else:\n",
    "        notebook_name = None\n",
    "except Exception:\n",
    "    notebook_name = None\n",
    "\n",
    "# fallback manual name if automatic detection fails\n",
    "if not notebook_name:\n",
    "    notebook_name = \"01_EDA.ipynb\"\n",
    "\n",
    "NOTEBOOK_PATH = Path(notebook_name)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2ï¸âƒ£ Load the notebook JSON\n",
    "# ---------------------------------------------------------------------\n",
    "if not NOTEBOOK_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found: {NOTEBOOK_PATH.resolve()}\")\n",
    "\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3ï¸âƒ£ Collect code cells whose first non-empty line starts with \"# 2\"\n",
    "# ---------------------------------------------------------------------\n",
    "section_code = []\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        if not src.strip():\n",
    "            continue\n",
    "        first_line = next((ln.strip() for ln in src.splitlines() if ln.strip()), \"\")\n",
    "        if first_line.startswith(\"# 2\"):\n",
    "            section_code.append(src.rstrip())\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4ï¸âƒ£ Aggregate and render inline\n",
    "# ---------------------------------------------------------------------\n",
    "# if section_code:\n",
    "#     combined = \"\\n\\n\".join(section_code)\n",
    "#     md = f\"```python\\n{combined}\\n```\"\n",
    "#     display(Markdown(f\"### ğŸ§© Aggregated Section 2 Code ({len(section_code)} cells)\\n\\n\" + md))\n",
    "# else:\n",
    "#     display(Markdown(\"> âš ï¸ **No code cells starting with `# 2` found in this notebook.**\"))\n",
    "\n",
    "Path(\"section2_aggregate.py\").write_text(combined, encoding=\"utf-8\")\n",
    "print(\"âœ… Saved section2_aggregate.py\")\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Settings ---\n",
    "notebook_path = Path(\"01_EDA.ipynb\")  # change as needed\n",
    "\n",
    "# --- Load notebook as JSON ---\n",
    "nb = json.loads(notebook_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# --- Find the first code cell and its first comment line ---\n",
    "first_comment = None\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        for line in cell.get(\"source\", []):\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                first_comment = line\n",
    "                break\n",
    "        if first_comment:\n",
    "            break\n",
    "\n",
    "# --- Output ---\n",
    "if first_comment:\n",
    "    print(f\"âœ… First section header found:\\n{first_comment}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No comment header found in any code cell.\")\n",
    "\n",
    "# MD AGG First line headers \n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Settings ---\n",
    "notebook_path = Path(\"01_EDA.ipynb\")  # adjust to your notebook name\n",
    "\n",
    "# --- Load notebook as JSON ---\n",
    "nb = json.loads(notebook_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# --- Collect top-of-cell comment headers ---\n",
    "headers = []\n",
    "\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = cell.get(\"source\", [])\n",
    "        if not src:\n",
    "            continue\n",
    "        # Find the first non-empty line\n",
    "        for line in src:\n",
    "            stripped = line.strip()\n",
    "            if stripped:  # skip blank lines\n",
    "                if stripped.startswith(\"#\"):\n",
    "                    headers.append(stripped)\n",
    "                break  # stop after the first meaningful line in this cell\n",
    "\n",
    "# --- Output results ---\n",
    "if headers:\n",
    "    print(f\"âœ… Found {len(headers)} section headers:\\n\")\n",
    "    for i, h in enumerate(headers, 1):\n",
    "        print(f\"{i:02}. {h}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No top-of-cell comment headers found.\")\n",
    "\n",
    "# agg_md.py\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Locate Level_3 base robustly ---\n",
    "cwd = Path.cwd()\n",
    "level3 = next((p for p in [cwd, *cwd.parents] if p.name == \"Level_3\"), None)\n",
    "\n",
    "if level3 is None:\n",
    "    # Fallback to your explicit absolute path\n",
    "    level3 = Path(\"/Users/b/DATA/PROJECTS/Telco/Level_3\")\n",
    "\n",
    "# --- Paths ---\n",
    "input_path  = level3 / \"notebooks\" / \"01_EDA.ipynb\"\n",
    "report_dir  = level3 / \"resources\" / \"reports\"\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp   = datetime.now().strftime(\"%m%d_%Y_%H%M%S\")\n",
    "output_path = report_dir / f\"{timestamp}_Aggggggggg_01_EDA_Telco_Markdown.md\"\n",
    "\n",
    "# --- Guard: make sure the notebook exists where we think it does ---\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"Could not find notebook at: {input_path}\\n\"\n",
    "                            f\"Current working dir: {cwd}\")\n",
    "\n",
    "# --- Extract markdown cells ---\n",
    "nb = json.loads(input_path.read_text(encoding=\"utf-8\"))\n",
    "md_cells = [\"\".join(c[\"source\"]).strip() for c in nb[\"cells\"] if c.get(\"cell_type\") == \"markdown\"]\n",
    "\n",
    "# --- Write to output ---\n",
    "combined = \"\\n\\n---\\n\\n\".join(md_cells)\n",
    "output_path.write_text(combined, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… Wrote {len(md_cells)} markdown cells to {output_path}\")\n",
    "\n",
    "# agg_code.py :1\n",
    "from nbformat import read\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "nb = read(\"01_EDA.ipynb\", as_version=4)\n",
    "code_cells = [cell.source for cell in nb.cells if cell.cell_type == \"code\"]\n",
    "Path(f\"aggregated_code_{datetime.now().strftime('%Y_%m%d_%H:%M')}.py\").write_text(\"\\n\\n\".join(code_cells))\n",
    "print(\"âœ… Extracted code written to aggregated_code_{datetime.now().strftime('%Y_%m%d_%H:%M')}.py\")\n",
    "#agg_code.py\n",
    "from nbformat import read\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Locate the notebook and compute the Level_3 root from it\n",
    "nb_path = Path(\"01_EDA.ipynb\").resolve()\n",
    "if not nb_path.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found at: {nb_path}\")\n",
    "\n",
    "level3_root = nb_path.parent.parent  # from .../notebooks -> .../Level_3\n",
    "\n",
    "# Output directory: Level_3/resources/reports/script_agg_report\n",
    "out_dir = level3_root / \"resources\" / \"reports\" / \"script_agg\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read notebook and aggregate code cells\n",
    "nb = read(str(nb_path), as_version=4)\n",
    "code_cells = [cell.source for cell in nb.cells if getattr(cell, \"cell_type\", \"\") == \"code\"]\n",
    "\n",
    "# Write output file with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y_%m%d_%H%M\")\n",
    "out_path = out_dir / f\"agg_{timestamp}.py\"\n",
    "out_path.write_text(\"\\n\\n\".join(code_cells), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"âœ… Extracted code written to {out_path}\")\n",
    "\n",
    "# agg all py cell/ first line\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- Settings ---\n",
    "notebook_path = Path(\"01_EDA.ipynb\")  # path to your notebook\n",
    "\n",
    "# --- Load the notebook JSON ---\n",
    "nb = json.loads(notebook_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# --- Extract first line of every code cell ---\n",
    "first_lines = []\n",
    "\n",
    "for i, cell in enumerate(nb.get(\"cells\", []), start=1):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = cell.get(\"source\", [])\n",
    "        # Skip empty cells\n",
    "        if not src:\n",
    "            continue\n",
    "        # Find the first non-empty line\n",
    "        for line in src:\n",
    "            stripped = line.strip()\n",
    "            if stripped:\n",
    "                first_lines.append((i, stripped))\n",
    "                break\n",
    "\n",
    "# --- Output results ---\n",
    "if first_lines:\n",
    "    print(f\"âœ… Found {len(first_lines)} code cells with content:\\n\")\n",
    "    for idx, line in first_lines:\n",
    "        print(f\"{idx:02}. {line}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No code cells with content found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a77776",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INLINE v9: Interactive notebook selection + interactive output directory\n",
    "# - Finds 01_EDA.ipynb in repo\n",
    "# - Lets you CLICK which notebook to use\n",
    "# - Lets you CLICK where to save output\n",
    "# - Aggregates a numeric section range into a new .ipynb\n",
    "\n",
    "import json, re, time\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIG â€” EDIT ONLY THESE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "RANGE_START_LABEL = \"2.5\"\n",
    "RANGE_END_LABEL   = \"7.2\"\n",
    "\n",
    "SOURCE_NOTEBOOK_NAME = \"02_DQ_IF.ipynb\"\n",
    "MAX_DEPTH = 4\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Repo discovery + basic search\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    \"\"\"Walk upward from start to find a folder containing .git.\"\"\"\n",
    "    current = start.resolve()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \".git\").is_dir():\n",
    "            return parent\n",
    "    return current\n",
    "\n",
    "\n",
    "def find_notebooks(repo_root: Path, name: str):\n",
    "    \"\"\"Return all matching paths inside the repo.\"\"\"\n",
    "    return list(repo_root.rglob(name))\n",
    "\n",
    "\n",
    "def extract_level_num(path: Path) -> int:\n",
    "    \"\"\"Extract numeric Level_# from path; non-matches get huge number.\"\"\"\n",
    "    m = re.search(r\"Level_(\\d+)\", str(path))\n",
    "    return int(m.group(1)) if m else 999999\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# INTERACTIVE NOTEBOOK CHOOSER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def format_notebook_label(path: Path, repo_root: Path) -> str:\n",
    "    \"\"\"Pretty label like 'Level_3  â†’ notebooks/01_EDA.ipynb'.\"\"\"\n",
    "    s = str(path)\n",
    "    level_match = re.search(r\"(Level_\\d+)\", s)\n",
    "    level = level_match.group(1) if level_match else \"NoLevel\"\n",
    "    try:\n",
    "        rel = path.relative_to(repo_root)\n",
    "    except ValueError:\n",
    "        rel = path\n",
    "    return f\"{level:<8} â†’ {rel}\"\n",
    "\n",
    "\n",
    "def choose_notebook_interactive(matches, repo_root: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Interactive notebook selector:\n",
    "    - Dropdown listing matches (sorted by Level_#)\n",
    "    - 'Browse notebooksâ€¦' to pick any .ipynb (if ipyfilechooser installed)\n",
    "    - 'Confirm' button to finalize selection\n",
    "    \"\"\"\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "\n",
    "    # sort matches by numeric level\n",
    "    matches = sorted(matches, key=extract_level_num)\n",
    "\n",
    "    # map label -> path\n",
    "    options = {format_notebook_label(m, repo_root): m for m in matches}\n",
    "\n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=options,\n",
    "        description='Notebook:',\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "    browse_button = widgets.Button(description='Browse notebooksâ€¦')\n",
    "    confirm_button = widgets.Button(description='Confirm', button_style='success')\n",
    "    path_label = widgets.Label()\n",
    "    out = widgets.Output()\n",
    "\n",
    "    selected_nb = {\"path\": list(options.values())[0]}\n",
    "    done_flag = {\"done\": False}\n",
    "\n",
    "    def update_label():\n",
    "        path_label.value = f\"Selected notebook: {selected_nb['path']}\"\n",
    "\n",
    "    def on_dropdown_change(change):\n",
    "        if change[\"name\"] == \"value\":\n",
    "            selected_nb[\"path\"] = change[\"new\"]\n",
    "            update_label()\n",
    "\n",
    "    dropdown.observe(on_dropdown_change)\n",
    "\n",
    "    def on_browse_click(b):\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            try:\n",
    "                # Optional: notebook navigator (pip install ipyfilechooser)\n",
    "                from ipyfilechooser import FileChooser\n",
    "\n",
    "                fc = FileChooser(str(repo_root))\n",
    "                fc.title = 'Pick a notebook (.ipynb)'\n",
    "                fc.use_dir_icons = True\n",
    "                fc.filter_pattern = '*.ipynb'\n",
    "\n",
    "                def on_done(chooser):\n",
    "                    if chooser.selected is None:\n",
    "                        return\n",
    "                    p = Path(chooser.selected)\n",
    "                    selected_nb[\"path\"] = p\n",
    "                    # Add to dropdown options dynamically\n",
    "                    label = format_notebook_label(p, repo_root)\n",
    "                    options[label] = p\n",
    "                    dropdown.options = options\n",
    "                    dropdown.value = p\n",
    "                    update_label()\n",
    "\n",
    "                fc.register_callback(on_done)\n",
    "                display(fc)\n",
    "\n",
    "            except ImportError:\n",
    "                print(\"ipyfilechooser not installed.\")\n",
    "                print(\"Run `pip install ipyfilechooser` for a clickable file navigator.\\n\")\n",
    "                print(\"For now, type a full .ipynb path below and press Enter.\\n\")\n",
    "\n",
    "                text = widgets.Text(\n",
    "                    value=str(selected_nb[\"path\"]),\n",
    "                    description='Notebook:',\n",
    "                    layout=widgets.Layout(width='100%')\n",
    "                )\n",
    "\n",
    "                def on_text_submit(change):\n",
    "                    p = Path(change[\"new\"]).expanduser()\n",
    "                    selected_nb[\"path\"] = p\n",
    "                    update_label()\n",
    "\n",
    "                text.on_submit(on_text_submit)\n",
    "                display(text)\n",
    "\n",
    "    browse_button.on_click(on_browse_click)\n",
    "\n",
    "    def on_confirm(b):\n",
    "        done_flag[\"done\"] = True\n",
    "\n",
    "    confirm_button.on_click(on_confirm)\n",
    "\n",
    "    # initialize label\n",
    "    update_label()\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        dropdown,\n",
    "        widgets.HBox([browse_button, confirm_button]),\n",
    "        path_label,\n",
    "        out\n",
    "    ])\n",
    "    display(ui)\n",
    "\n",
    "    # wait until user clicks Confirm\n",
    "    while not done_flag[\"done\"]:\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    print(f\"\\nâœ” Using notebook:\\n  {selected_nb['path']}\\n\")\n",
    "    return selected_nb[\"path\"]\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# INTERACTIVE OUTPUT DIRECTORY CHOOSER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def choose_output_path_interactive(default_dir: Path, default_name: str, repo_root: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Interactive directory chooser using widgets.\n",
    "\n",
    "    - Dropdown with default dir, repo root, cwd.\n",
    "    - 'Browseâ€¦' to pick a directory (ipyfilechooser if available).\n",
    "    - 'Confirm' to finalize.\n",
    "    \"\"\"\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "\n",
    "    default_dir = default_dir.resolve()\n",
    "    repo_root = repo_root.resolve()\n",
    "\n",
    "    choices = [\n",
    "        (\"Default (next to source)\", default_dir),\n",
    "        (\"Repo root\", repo_root),\n",
    "        (\"Current working dir\", Path.cwd().resolve()),\n",
    "    ]\n",
    "    options = {label: path for label, path in choices}\n",
    "\n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=options,\n",
    "        description='Save dir:',\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "    browse_button = widgets.Button(description='Browseâ€¦')\n",
    "    confirm_button = widgets.Button(description='Confirm', button_style='success')\n",
    "    path_label = widgets.Label()\n",
    "    out = widgets.Output()\n",
    "\n",
    "    selected_dir = {\"path\": default_dir}\n",
    "    done_flag = {\"done\": False}\n",
    "\n",
    "    def update_label():\n",
    "        path_label.value = f\"Output will be: {(selected_dir['path'] / default_name).resolve()}\"\n",
    "\n",
    "    def on_dropdown_change(change):\n",
    "        if change[\"name\"] == \"value\":\n",
    "            selected_dir[\"path\"] = change[\"new\"]\n",
    "            update_label()\n",
    "\n",
    "    dropdown.observe(on_dropdown_change)\n",
    "\n",
    "    def on_browse_click(b):\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            try:\n",
    "                from ipyfilechooser import FileChooser\n",
    "\n",
    "                fc = FileChooser(str(repo_root))\n",
    "                fc.title = 'Pick output directory'\n",
    "                fc.use_dir_icons = True\n",
    "                fc.show_only_dirs = True\n",
    "\n",
    "                def on_done(chooser):\n",
    "                    if chooser.selected_path is None:\n",
    "                        return\n",
    "                    selected_dir[\"path\"] = Path(chooser.selected_path)\n",
    "                    update_label()\n",
    "\n",
    "                fc.register_callback(on_done)\n",
    "                display(fc)\n",
    "\n",
    "            except ImportError:\n",
    "                print(\"ipyfilechooser not installed.\")\n",
    "                print(\"Run `pip install ipyfilechooser` for a clickable directory navigator,\\n\"\n",
    "                      \"or type a directory path below and press Enter.\\n\")\n",
    "\n",
    "                text = widgets.Text(\n",
    "                    value=str(selected_dir[\"path\"]),\n",
    "                    description='Dir:',\n",
    "                    layout=widgets.Layout(width='100%')\n",
    "                )\n",
    "\n",
    "                def on_text_submit(change):\n",
    "                    p = Path(change[\"new\"]).expanduser()\n",
    "                    selected_dir[\"path\"] = p\n",
    "                    update_label()\n",
    "\n",
    "                text.on_submit(on_text_submit)\n",
    "                display(text)\n",
    "\n",
    "    browse_button.on_click(on_browse_click)\n",
    "\n",
    "    def on_confirm(b):\n",
    "        done_flag[\"done\"] = True\n",
    "\n",
    "    confirm_button.on_click(on_confirm)\n",
    "\n",
    "    update_label()\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        dropdown,\n",
    "        widgets.HBox([browse_button, confirm_button]),\n",
    "        path_label,\n",
    "        out\n",
    "    ])\n",
    "    display(ui)\n",
    "\n",
    "    while not done_flag[\"done\"]:\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    out_path = (selected_dir[\"path\"] / default_name).resolve()\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\nâœ” Output will be saved to:\\n  {out_path}\\n\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Section parsing utilities\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def parse_label(label: str, max_depth: int = MAX_DEPTH):\n",
    "    \"\"\"Turn '2.5.1' into (2,5,1,0) for numeric comparison.\"\"\"\n",
    "    parts = [int(p) for p in label.split(\".\")]\n",
    "    if len(parts) < max_depth:\n",
    "        parts += [0] * (max_depth - len(parts))\n",
    "    return tuple(parts[:max_depth])\n",
    "\n",
    "\n",
    "def label_in_range(label: str, start: str, end: str) -> bool:\n",
    "    t = parse_label(label)\n",
    "    s = parse_label(start)\n",
    "    e = parse_label(end)\n",
    "    return s <= t <= e\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAIN FLOW\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "cwd = Path.cwd()\n",
    "repo_root = find_repo_root(cwd)\n",
    "print(\"ğŸ“‚ Repo root:\", repo_root)\n",
    "\n",
    "matches = find_notebooks(repo_root, SOURCE_NOTEBOOK_NAME)\n",
    "\n",
    "if not matches:\n",
    "    raise FileNotFoundError(f\"âŒ No match found for {SOURCE_NOTEBOOK_NAME} in repo.\")\n",
    "\n",
    "# Interactive notebook selection (even if there's just one, you can still confirm it)\n",
    "nb_path = choose_notebook_interactive(matches, repo_root)\n",
    "\n",
    "# Default output name\n",
    "default_output_name = (\n",
    "    f\"{nb_path.stem}_sections_\"\n",
    "    f\"{RANGE_START_LABEL.replace('.', '-')}_to_{RANGE_END_LABEL.replace('.', '-')}.ipynb\"\n",
    ")\n",
    "\n",
    "# Interactive output dir selection\n",
    "out_path = choose_output_path_interactive(nb_path.parent, default_output_name, repo_root)\n",
    "\n",
    "# Load source notebook\n",
    "with nb_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "cells = nb.get(\"cells\", [])\n",
    "\n",
    "# Match headings like \"# 2.5\", \"## 2.5.1\", \"### 7.2.3.1\"\n",
    "section_re = re.compile(r\"^\\s*#{1,6}\\s*(\\d+(?:\\.\\d+){0,3})\\b\")\n",
    "\n",
    "current_label = None\n",
    "seen_labels = set()\n",
    "collected = []\n",
    "\n",
    "for idx, cell in enumerate(cells):\n",
    "    ctype = cell.get(\"cell_type\")\n",
    "    src = cell.get(\"source\", [])\n",
    "\n",
    "    if ctype == \"markdown\" and src:\n",
    "        for line in src:\n",
    "            m = section_re.match(line)\n",
    "            if m:\n",
    "                current_label = m.group(1)\n",
    "                seen_labels.add(current_label)\n",
    "                break\n",
    "        continue\n",
    "\n",
    "    if ctype == \"code\" and current_label is not None:\n",
    "        if label_in_range(current_label, RANGE_START_LABEL, RANGE_END_LABEL):\n",
    "            collected.append({\n",
    "                \"cell_type\": \"code\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": src,\n",
    "                \"outputs\": [],\n",
    "                \"execution_count\": None\n",
    "            })\n",
    "\n",
    "# Build and write new notebook\n",
    "new_nb = {\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Aggregated Section Range\\n\",\n",
    "                f\"Range: {RANGE_START_LABEL} â†’ {RANGE_END_LABEL} (inclusive)\\n\\n\",\n",
    "                f\"Section labels detected in source: {sorted(seen_labels)}\\n\",\n",
    "                f\"Selected notebook: `{nb_path}`\\n\",\n",
    "                f\"Output notebook: `{out_path}`\\n\"\n",
    "            ]\n",
    "        }\n",
    "    ] + collected,\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": nb[\"metadata\"].get(\"kernelspec\", {}),\n",
    "        \"language_info\": nb[\"metadata\"].get(\"language_info\", {})\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": nb.get(\"nbformat_minor\", 5)\n",
    "}\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_nb, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Done.\")\n",
    "print(f\"   Range: {RANGE_START_LABEL} â†’ {RANGE_END_LABEL}\")\n",
    "print(f\"   Labels seen: {sorted(seen_labels)}\")\n",
    "print(f\"   Included {len(collected)} code cells.\")\n",
    "print(f\"   Output: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "621151f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Repo root: /Users/b/DATA/PROJECTS/Telco\n",
      "âœ” Found notebook: /Users/b/DATA/PROJECTS/Telco/Level_3/notebooks/02_DQ_IF.ipynb\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'choose_output_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 263\u001b[39m\n\u001b[32m    257\u001b[39m default_output_name = (\n\u001b[32m    258\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnb_path.stem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_sections_\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    259\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRANGE_START_LABEL.replace(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_to_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRANGE_END_LABEL.replace(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.ipynb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m )\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# ask user where to save\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m out_path = \u001b[43mchoose_output_path\u001b[49m(nb_path.parent, default_output_name)\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;66;03m# Load notebook + aggregate cells\u001b[39;00m\n\u001b[32m    268\u001b[39m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m nb_path.open(\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'choose_output_path' is not defined"
     ]
    }
   ],
   "source": [
    "# INLINE v8: Find 01_EDA.ipynb in repo, ask which one to use,\n",
    "# then aggregate a section range into a new .ipynb and ask where to save it.\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIG â€” EDIT ONLY THESE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "RANGE_START_LABEL = \"2.5\"\n",
    "RANGE_END_LABEL   = \"7.2\"\n",
    "\n",
    "SOURCE_NOTEBOOK_NAME = \"02_DQ_IF.ipynb\"\n",
    "MAX_DEPTH = 4\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Repo discovery + search / choose helpers\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    \"\"\"Walk upward from start to find a folder containing .git.\"\"\"\n",
    "    current = start.resolve()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \".git\").is_dir():\n",
    "            return parent\n",
    "    return current\n",
    "\n",
    "\n",
    "def find_notebooks(repo_root: Path, name: str):\n",
    "    \"\"\"Return all matching paths inside the repo.\"\"\"\n",
    "    return list(repo_root.rglob(name))\n",
    "\n",
    "\n",
    "def extract_level_num(path: Path) -> int:\n",
    "    \"\"\"Extract numeric Level_# from path; non-matches get huge number.\"\"\"\n",
    "    m = re.search(r\"Level_(\\d+)\", str(path))\n",
    "    return int(m.group(1)) if m else 999999\n",
    "\n",
    "\n",
    "def choose_notebook(matches):\n",
    "    \"\"\"Ask user which notebook to use, with the input box pushed down.\"\"\"\n",
    "    # sort matches by numeric level\n",
    "    matches = sorted(matches, key=extract_level_num)\n",
    "\n",
    "    print(\"\\nğŸ“„ Multiple notebooks found:\\n\")\n",
    "    for i, m in enumerate(matches):\n",
    "        print(f\"  [{i}] {m}\")\n",
    "\n",
    "    # push input widget down so it doesn't cover the list\n",
    "    print(\"\\n\" * 5)\n",
    "    import time\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"ğŸ‘‰ Enter the number of the notebook you want to use: \").strip()\n",
    "        if choice.isdigit():\n",
    "            idx = int(choice)\n",
    "            if 0 <= idx < len(matches):\n",
    "                print(f\"\\nâœ” Using: {matches[idx]}\\n\")\n",
    "                return matches[idx]\n",
    "        print(\"âŒ Invalid choice, try again.\\n\")\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Section parsing utilities\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def parse_label(label: str, max_depth: int = MAX_DEPTH):\n",
    "    \"\"\"Turn '2.5.1' into (2,5,1,0) for numeric comparison.\"\"\"\n",
    "    parts = [int(p) for p in label.split(\".\")]\n",
    "    if len(parts) < max_depth:\n",
    "        parts += [0] * (max_depth - len(parts))\n",
    "    return tuple(parts[:max_depth])\n",
    "\n",
    "\n",
    "def label_in_range(label: str, start: str, end: str) -> bool:\n",
    "    t = parse_label(label)\n",
    "    s = parse_label(start)\n",
    "    e = parse_label(end)\n",
    "    return s <= t <= e\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Output path chooser\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def choose_output_path_interactive(default_dir: Path, default_name: str, repo_root: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Interactive directory chooser using widgets.\n",
    "\n",
    "    - Shows a dropdown of common dirs (default, repo root, cwd).\n",
    "    - 'Browse...' button opens a directory navigator (if ipyfilechooser is installed),\n",
    "      or a text box fallback.\n",
    "    - 'Confirm' button finalizes the selection.\n",
    "    \"\"\"\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    import time\n",
    "\n",
    "    default_dir = default_dir.resolve()\n",
    "    repo_root = repo_root.resolve()\n",
    "\n",
    "    # ---- initial options you can click on ----\n",
    "    choices = [\n",
    "        (\"Default (next to source)\", default_dir),\n",
    "        (\"Repo root\", repo_root),\n",
    "        (\"Current working dir\", Path.cwd().resolve()),\n",
    "    ]\n",
    "    options = {label: path for label, path in choices}\n",
    "\n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=options,\n",
    "        description='Save dir:',\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "    browse_button = widgets.Button(description='Browseâ€¦')\n",
    "    confirm_button = widgets.Button(description='Confirm', button_style='success')\n",
    "    path_label = widgets.Label()\n",
    "    out = widgets.Output()\n",
    "\n",
    "    selected_dir = {\"path\": default_dir}\n",
    "    done_flag = {\"done\": False}\n",
    "\n",
    "    def update_label():\n",
    "        path_label.value = f\"Selected: {(selected_dir['path'] / default_name).resolve()}\"\n",
    "\n",
    "    def on_dropdown_change(change):\n",
    "        if change[\"name\"] == \"value\":\n",
    "            selected_dir[\"path\"] = change[\"new\"]\n",
    "            update_label()\n",
    "\n",
    "    dropdown.observe(on_dropdown_change)\n",
    "\n",
    "    def on_browse_click(b):\n",
    "        out.clear_output()\n",
    "        with out:\n",
    "            try:\n",
    "                # Optional: directory navigator with click support\n",
    "                from ipyfilechooser import FileChooser  # pip install ipyfilechooser\n",
    "\n",
    "                fc = FileChooser(str(repo_root))\n",
    "                fc.title = 'Pick output directory'\n",
    "                fc.use_dir_icons = True\n",
    "                fc.show_only_dirs = True\n",
    "\n",
    "                def on_done(chooser):\n",
    "                    selected_dir[\"path\"] = Path(chooser.selected_path)\n",
    "                    update_label()\n",
    "\n",
    "                fc.register_callback(on_done)\n",
    "                display(fc)\n",
    "\n",
    "            except ImportError:\n",
    "                print(\"ipyfilechooser not installed.\")\n",
    "                print(\"Run `pip install ipyfilechooser` for a clickable navigator,\")\n",
    "                print(\"or type a directory path below and press Enter.\\n\")\n",
    "\n",
    "                text = widgets.Text(\n",
    "                    value=str(selected_dir[\"path\"]),\n",
    "                    description='Dir:',\n",
    "                    layout=widgets.Layout(width='100%')\n",
    "                )\n",
    "\n",
    "                def on_text_submit(change):\n",
    "                    p = Path(change[\"new\"]).expanduser()\n",
    "                    selected_dir[\"path\"] = p\n",
    "                    update_label()\n",
    "\n",
    "                text.on_submit(on_text_submit)\n",
    "                display(text)\n",
    "\n",
    "    browse_button.on_click(on_browse_click)\n",
    "\n",
    "    def on_confirm(b):\n",
    "        done_flag[\"done\"] = True\n",
    "\n",
    "    confirm_button.on_click(on_confirm)\n",
    "\n",
    "    # initialize label\n",
    "    update_label()\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        dropdown,\n",
    "        widgets.HBox([browse_button, confirm_button]),\n",
    "        path_label,\n",
    "        out\n",
    "    ])\n",
    "    display(ui)\n",
    "\n",
    "    # wait until user clicks Confirm\n",
    "    while not done_flag[\"done\"]:\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    out_path = (selected_dir[\"path\"] / default_name).resolve()\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\nâœ” Output will be saved to:\\n  {out_path}\\n\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# def choose_output_path(default_dir: Path, default_name: str) -> Path:\n",
    "    \"\"\"\n",
    "    Ask the user where to save the output notebook.\n",
    "\n",
    "    - Press Enter â†’ use default_dir/default_name\n",
    "    - Enter a directory path â†’ save as that_dir/default_name\n",
    "    - Enter a path ending in .ipynb â†’ use that exact file path\n",
    "    \"\"\"\n",
    "    default_path = default_dir / default_name\n",
    "    print(f\"ğŸ’¾ Default output path:\\n  {default_path}\")\n",
    "    print(\"You can:\")\n",
    "    print(\"  â€¢ Press Enter to accept the default, or\")\n",
    "    print(\"  â€¢ Enter a directory path, or\")\n",
    "    print(\"  â€¢ Enter a full file path ending in .ipynb\\n\")\n",
    "\n",
    "    user_input = input(\"ğŸ“‚ Output path (optional): \").strip()\n",
    "\n",
    "    if not user_input:\n",
    "        out_path = default_path\n",
    "    else:\n",
    "        p = Path(user_input).expanduser()\n",
    "        # If user typed a file (ends with .ipynb), use it directly\n",
    "        if p.suffix == \".ipynb\":\n",
    "            out_path = p\n",
    "        else:\n",
    "            # Treat as directory; append default_name\n",
    "            out_path = p / default_name\n",
    "\n",
    "    out_path = out_path.resolve()\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\nâœ” Output will be saved to:\\n  {out_path}\\n\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Locate repo + pick notebook\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "cwd = Path.cwd()\n",
    "repo_root = find_repo_root(cwd)\n",
    "print(\"ğŸ“‚ Repo root:\", repo_root)\n",
    "\n",
    "matches = find_notebooks(repo_root, SOURCE_NOTEBOOK_NAME)\n",
    "\n",
    "if not matches:\n",
    "    raise FileNotFoundError(f\"âŒ No match found for {SOURCE_NOTEBOOK_NAME} in repo.\")\n",
    "\n",
    "if len(matches) == 1:\n",
    "    nb_path = matches[0]\n",
    "    print(f\"âœ” Found notebook: {nb_path}\")\n",
    "else:\n",
    "    nb_path = choose_notebook(matches)\n",
    "\n",
    "# default output naming\n",
    "default_output_name = (\n",
    "    f\"{nb_path.stem}_sections_\"\n",
    "    f\"{RANGE_START_LABEL.replace('.', '-')}_to_{RANGE_END_LABEL.replace('.', '-')}.ipynb\"\n",
    ")\n",
    "\n",
    "# ask user where to save\n",
    "out_path = choose_output_path(nb_path.parent, default_output_name)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Load notebook + aggregate cells\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "with nb_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "cells = nb.get(\"cells\", [])\n",
    "\n",
    "section_re = re.compile(r\"^\\s*#{1,6}\\s*(\\d+(?:\\.\\d+){0,3})\\b\")\n",
    "\n",
    "current_label = None\n",
    "seen_labels = set()\n",
    "collected = []\n",
    "\n",
    "for idx, cell in enumerate(cells):\n",
    "    ctype = cell.get(\"cell_type\")\n",
    "    src = cell.get(\"source\", [])\n",
    "\n",
    "    # Find section headers anywhere inside markdown\n",
    "    if ctype == \"markdown\" and src:\n",
    "        for line in src:\n",
    "            m = section_re.match(line)\n",
    "            if m:\n",
    "                current_label = m.group(1)\n",
    "                seen_labels.add(current_label)\n",
    "                break\n",
    "        continue\n",
    "\n",
    "    # Collect code cells\n",
    "    if ctype == \"code\" and current_label is not None:\n",
    "        if label_in_range(current_label, RANGE_START_LABEL, RANGE_END_LABEL):\n",
    "            collected.append({\n",
    "                \"cell_type\": \"code\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": src,\n",
    "                \"outputs\": [],\n",
    "                \"execution_count\": None\n",
    "            })\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Build + write new notebook\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "new_nb = {\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Aggregated Section Range\\n\",\n",
    "                f\"Range: {RANGE_START_LABEL} â†’ {RANGE_END_LABEL} (inclusive)\\n\\n\",\n",
    "                f\"Section labels detected in source: {sorted(seen_labels)}\\n\",\n",
    "                f\"Selected notebook: `{nb_path}`\\n\",\n",
    "                f\"Output notebook: `{out_path}`\\n\"\n",
    "            ]\n",
    "        }\n",
    "    ] + collected,\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": nb[\"metadata\"].get(\"kernelspec\", {}),\n",
    "        \"language_info\": nb[\"metadata\"].get(\"language_info\", {})\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": nb.get(\"nbformat_minor\", 5)\n",
    "}\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_nb, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Done.\")\n",
    "print(f\"   Range: {RANGE_START_LABEL} â†’ {RANGE_END_LABEL}\")\n",
    "print(f\"   Labels seen: {sorted(seen_labels)}\")\n",
    "print(f\"   Included {len(collected)} code cells.\")\n",
    "print(f\"   Output: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56322f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INLINE v7: Find 01_EDA.ipynb anywhere in the repo, ask user to choose match,\n",
    "# then aggregate a numeric section range into a new .ipynb.\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CONFIG â€” EDIT ONLY THESE TWO\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "RANGE_START_LABEL = \"2.0\"\n",
    "RANGE_END_LABEL   = \"2.4\"\n",
    "\n",
    "SOURCE_NOTEBOOK_NAME = \"01_EDA.ipynb\"\n",
    "MAX_DEPTH = 4\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Repo discovery + search functions\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    \"\"\"Walk upward from start to find a folder containing .git.\"\"\"\n",
    "    current = start.resolve()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \".git\").is_dir():\n",
    "            return parent\n",
    "    return current\n",
    "\n",
    "\n",
    "def find_notebooks(repo_root: Path, name: str):\n",
    "    \"\"\"Return all matching paths inside the repo.\"\"\"\n",
    "    return list(repo_root.rglob(name))\n",
    "\n",
    "def choose_notebook(matches):\n",
    "    \"\"\"v2. Ask user which notebook to use, but push the input box down so it doesn't cover the list.\"\"\"\n",
    "    print(\"\\nğŸ“„ Multiple notebooks found:\\n\")\n",
    "    for i, m in enumerate(matches):\n",
    "        print(f\"  [{i}] {m}\")\n",
    "\n",
    "    # MOVE THE INPUT BOX DOWN\n",
    "    print(\"\\n\" * 50)   # add vertical space so popup appears lower\n",
    "\n",
    "    # OPTIONAL: make sure output renders before the prompt\n",
    "    import time\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    # Now ask the user\n",
    "    while True:\n",
    "        choice = input(\"ğŸ‘‰ Enter the number of the notebook you want to use: \").strip()\n",
    "        if choice.isdigit():\n",
    "            idx = int(choice)\n",
    "            if 0 <= idx < len(matches):\n",
    "                print(f\"\\nâœ” Using: {matches[idx]}\\n\")\n",
    "                return matches[idx]\n",
    "        print(\"âŒ Invalid choice, try again.\\n\")\n",
    "\n",
    "# def choose_notebook(matches):\n",
    "    \"\"\"v1. Ask user which notebook to use.\"\"\"\n",
    "    print(\"\\nğŸ“„ Multiple notebooks found:\")\n",
    "    for i, m in enumerate(matches):\n",
    "        print(f\"  [{i}] {m}\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"\\nğŸ‘‰ Enter the number of the notebook you want to use: \").strip()\n",
    "        if choice.isdigit():\n",
    "            idx = int(choice)\n",
    "            if 0 <= idx < len(matches):\n",
    "                print(f\"âœ” Using: {matches[idx]}\\n\")\n",
    "                return matches[idx]\n",
    "        print(\"âŒ Invalid choice, try again.\")\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Section parsing utilities\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def parse_label(label: str, max_depth: int = MAX_DEPTH):\n",
    "    \"\"\"Turn '2.5.1' into (2,5,1,0).\"\"\"\n",
    "    parts = [int(p) for p in label.split(\".\")]\n",
    "    if len(parts) < max_depth:\n",
    "        parts += [0] * (max_depth - len(parts))\n",
    "    return tuple(parts[:max_depth])\n",
    "\n",
    "\n",
    "def label_in_range(label: str, start: str, end: str) -> bool:\n",
    "    t = parse_label(label)\n",
    "    s = parse_label(start)\n",
    "    e = parse_label(end)\n",
    "    return s <= t <= e\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Locate repo + pick notebook\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "cwd = Path.cwd()\n",
    "repo_root = find_repo_root(cwd)\n",
    "print(\"ğŸ“‚ Repo root:\", repo_root)\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_level_num(path: Path) -> int:\n",
    "    \"\"\"\n",
    "    Find something like 'Level_4' or 'Level_10' in the path.\n",
    "    If not found, return a huge number so those go last.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"Level_(\\d+)\", str(path))\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return 999999  # lowest priority for non-level folders\n",
    "\n",
    "# Sort matches x numeric level\n",
    "matches = sorted(matches, key=extract_level_num)\n",
    "\n",
    "# Sort matches x lexicographic\n",
    "# matches = find_notebooks(repo_root, SOURCE_NOTEBOOK_NAME)\n",
    "\n",
    "if not matches:\n",
    "    raise FileNotFoundError(f\"âŒ No match found for {SOURCE_NOTEBOOK_NAME} in repo.\")\n",
    "\n",
    "if len(matches) == 1:\n",
    "    nb_path = matches[0]\n",
    "    print(f\"âœ” Found notebook: {nb_path}\")\n",
    "else:\n",
    "    nb_path = choose_notebook(matches)\n",
    "\n",
    "# Output path\n",
    "output_name = f\"{nb_path.stem}_sections_{RANGE_START_LABEL.replace('.', '-')}_to_{RANGE_END_LABEL.replace('.', '-')}.ipynb\"\n",
    "out_path = nb_path.parent / output_name\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Load notebook + aggregate cells\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "with nb_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "cells = nb.get(\"cells\", [])\n",
    "\n",
    "section_re = re.compile(r\"^\\s*#{1,6}\\s*(\\d+(?:\\.\\d+){0,3})\\b\")\n",
    "\n",
    "current_label = None\n",
    "seen_labels = set()\n",
    "collected = []\n",
    "\n",
    "for idx, cell in enumerate(cells):\n",
    "    ctype = cell.get(\"cell_type\")\n",
    "    src = cell.get(\"source\", [])\n",
    "\n",
    "    # Find section headers anywhere inside markdown\n",
    "    if ctype == \"markdown\" and src:\n",
    "        for line in src:\n",
    "            m = section_re.match(line)\n",
    "            if m:\n",
    "                current_label = m.group(1)\n",
    "                seen_labels.add(current_label)\n",
    "                break\n",
    "        continue\n",
    "\n",
    "    # Collect code cells\n",
    "    if ctype == \"code\" and current_label is not None:\n",
    "        if label_in_range(current_label, RANGE_START_LABEL, RANGE_END_LABEL):\n",
    "            collected.append({\n",
    "                \"cell_type\": \"code\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": src,\n",
    "                \"outputs\": [],\n",
    "                \"execution_count\": None\n",
    "            })\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Build + write new notebook\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "new_nb = {\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# Aggregated Section Range\\n\",\n",
    "                f\"Range: {RANGE_START_LABEL} â†’ {RANGE_END_LABEL} (inclusive)\\n\\n\",\n",
    "                f\"Section labels detected in source: {sorted(seen_labels)}\\n\",\n",
    "                f\"Selected notebook: `{nb_path}`\\n\"\n",
    "            ]\n",
    "        }\n",
    "    ] + collected,\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": nb[\"metadata\"].get(\"kernelspec\", {}),\n",
    "        \"language_info\": nb[\"metadata\"].get(\"language_info\", {})\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": nb.get(\"nbformat_minor\", 5)\n",
    "}\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_nb, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Done.\")\n",
    "print(f\"   Range: {RANGE_START_LABEL} â†’ {RANGE_END_LABEL}\")\n",
    "print(f\"   Labels seen: {sorted(seen_labels)}\")\n",
    "print(f\"   Included {len(collected)} code cells.\")\n",
    "print(f\"   Output: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4668fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render one collapsible cell per each python cell in section 2\n",
    "import json\n",
    "import html\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1ï¸âƒ£  CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")  # change if your notebook has a different name\n",
    "\n",
    "if not NOTEBOOK_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found: {NOTEBOOK_PATH.resolve()}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2ï¸âƒ£  LOAD NOTEBOOK\n",
    "# ---------------------------------------------------------\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3ï¸âƒ£  FIND CODE CELLS STARTING WITH \"# 2\"\n",
    "# ---------------------------------------------------------\n",
    "cells_info = []  # list of dicts: {title, code}\n",
    "\n",
    "for idx, cell in enumerate(nb.get(\"cells\", []), start=1):\n",
    "    if cell.get(\"cell_type\") != \"code\":\n",
    "        continue\n",
    "\n",
    "    src = \"\".join(cell.get(\"source\", []))\n",
    "    if not src.strip():\n",
    "        continue\n",
    "\n",
    "    # First non-empty line\n",
    "    first_line = next((ln for ln in src.splitlines() if ln.strip()), \"\")\n",
    "    if not first_line.strip().startswith(\"# 2\"):\n",
    "        continue\n",
    "\n",
    "    # Title from first line (strip leading \"#\")\n",
    "    raw_title = first_line.lstrip(\"#\").strip()\n",
    "    title = raw_title or f\"Section 2 cell #{idx}\"\n",
    "\n",
    "    cells_info.append(\n",
    "        {\n",
    "            \"title\": title,\n",
    "            \"code\": src.rstrip(),\n",
    "            \"index\": idx,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4ï¸âƒ£  RENDER ONE COLLAPSIBLE PANEL PER MATCHING CELL\n",
    "# ---------------------------------------------------------\n",
    "if not cells_info:\n",
    "    display(HTML(\n",
    "        \"<p style='color:#b91c1c;font-family:-apple-system,BlinkMacSystemFont,\\\"Segoe UI\\\",sans-serif;'>\"\n",
    "        \"âš ï¸ No code cells starting with <code># 2</code> were found in this notebook.\"\n",
    "        \"</p>\"\n",
    "    ))\n",
    "else:\n",
    "    panels = []\n",
    "    for i, info in enumerate(cells_info, start=1):\n",
    "        title = html.escape(info[\"title\"])\n",
    "        code  = html.escape(info[\"code\"])\n",
    "\n",
    "        panel_html = f\"\"\"\n",
    "<details style=\"\n",
    "  margin:10px 0;\n",
    "  border:1px solid #e5e7eb;\n",
    "  border-radius:10px;\n",
    "  background:linear-gradient(135deg,#f9fafb,#eef2ff);\n",
    "  font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif;\n",
    "\">\n",
    "  <summary style=\"\n",
    "    cursor:pointer;\n",
    "    list-style:none;\n",
    "    padding:8px 12px;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "    justify-content:space-between;\n",
    "    gap:8px;\n",
    "    font-weight:600;\n",
    "    color:#0f172a;\n",
    "  \">\n",
    "    <span style=\"display:inline-flex;align-items:center;gap:6px;\">\n",
    "      ğŸ“œ <span>{i}. {title}</span>\n",
    "    </span>\n",
    "    <span style=\"\n",
    "      font-size:11px;\n",
    "      padding:2px 8px;\n",
    "      border-radius:999px;\n",
    "      background:#0f172a;\n",
    "      color:#f9fafb;\n",
    "      text-transform:uppercase;\n",
    "      letter-spacing:0.06em;\n",
    "    \">\n",
    "      toggle\n",
    "    </span>\n",
    "  </summary>\n",
    "\n",
    "  <pre style=\"\n",
    "    margin:0;\n",
    "    padding:10px 14px;\n",
    "    background:#020617;\n",
    "    color:#e5e7eb;\n",
    "    font-family:'Fira Code',ui-monospace,Consolas,'Courier New',monospace;\n",
    "    font-size:13px;\n",
    "    line-height:1.55;\n",
    "    white-space:pre-wrap;\n",
    "    word-break:break-word;\n",
    "    border-radius:0 0 10px 10px;\n",
    "    border-top:1px solid #1f2937;\n",
    "  \">{code}</pre>\n",
    "</details>\n",
    "\"\"\"\n",
    "        panels.append(panel_html)\n",
    "\n",
    "    wrapper = f\"\"\"\n",
    "<div style=\"margin:12px 0;\">\n",
    "  <div style=\"\n",
    "    font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif;\n",
    "    font-size:13px;\n",
    "    color:#4b5563;\n",
    "    margin-bottom:6px;\n",
    "  \">\n",
    "    Found <strong>{len(cells_info)}</strong> code cell(s) starting with <code># 2</code> in <code>{NOTEBOOK_PATH.name}</code>:\n",
    "  </div>\n",
    "  {''.join(panels)}\n",
    "</div>\n",
    "\"\"\"\n",
    "    display(HTML(wrapper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5030c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import html\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1ï¸âƒ£  CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")  # change if your notebook has a different name\n",
    "\n",
    "if not NOTEBOOK_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found: {NOTEBOOK_PATH.resolve()}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2ï¸âƒ£  LOAD NOTEBOOK\n",
    "# ---------------------------------------------------------\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3ï¸âƒ£  FIND CODE CELLS STARTING WITH \"# 2\"\n",
    "# ---------------------------------------------------------\n",
    "cells_info = []  # list of dicts: {title, code}\n",
    "\n",
    "for idx, cell in enumerate(nb.get(\"cells\", []), start=1):\n",
    "    if cell.get(\"cell_type\") != \"code\":\n",
    "        continue\n",
    "\n",
    "    src = \"\".join(cell.get(\"source\", []))\n",
    "    if not src.strip():\n",
    "        continue\n",
    "\n",
    "    # First non-empty line\n",
    "    first_line = next((ln for ln in src.splitlines() if ln.strip()), \"\")\n",
    "    if not first_line.strip().startswith(\"# 2\"):\n",
    "        continue\n",
    "\n",
    "    # Title from first line (strip leading \"#\")\n",
    "    raw_title = first_line.lstrip(\"#\").strip()\n",
    "    title = raw_title or f\"Section 2 cell #{idx}\"\n",
    "\n",
    "    cells_info.append(\n",
    "        {\n",
    "            \"title\": title,\n",
    "            \"code\": src.rstrip(),\n",
    "            \"index\": idx,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4ï¸âƒ£  RENDER ONE COLLAPSIBLE PANEL PER MATCHING CELL\n",
    "# ---------------------------------------------------------\n",
    "if not cells_info:\n",
    "    display(HTML(\n",
    "        \"<p style='color:#b91c1c;font-family:-apple-system,BlinkMacSystemFont,\\\"Segoe UI\\\",sans-serif;'>\"\n",
    "        \"âš ï¸ No code cells starting with <code># 2</code> were found in this notebook.\"\n",
    "        \"</p>\"\n",
    "    ))\n",
    "else:\n",
    "    panels = []\n",
    "    for i, info in enumerate(cells_info, start=1):\n",
    "        title = html.escape(info[\"title\"])\n",
    "        code  = html.escape(info[\"code\"])\n",
    "\n",
    "        panel_html = f\"\"\"\n",
    "<details style=\"\n",
    "  margin:10px 0;\n",
    "  border:1px solid #e5e7eb;\n",
    "  border-radius:10px;\n",
    "  background:linear-gradient(135deg,#f9fafb,#eef2ff);\n",
    "  font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif;\n",
    "\">\n",
    "  <summary style=\"\n",
    "    cursor:pointer;\n",
    "    list-style:none;\n",
    "    padding:8px 12px;\n",
    "    display:flex;\n",
    "    align-items:center;\n",
    "    justify-content:space-between;\n",
    "    gap:8px;\n",
    "    font-weight:600;\n",
    "    color:#0f172a;\n",
    "  \">\n",
    "    <span style=\"display:inline-flex;align-items:center;gap:6px;\">\n",
    "      ğŸ“œ <span>{i}. {title}</span>\n",
    "    </span>\n",
    "    <span style=\"\n",
    "      font-size:11px;\n",
    "      padding:2px 8px;\n",
    "      border-radius:999px;\n",
    "      background:#0f172a;\n",
    "      color:#f9fafb;\n",
    "      text-transform:uppercase;\n",
    "      letter-spacing:0.06em;\n",
    "    \">\n",
    "      toggle\n",
    "    </span>\n",
    "  </summary>\n",
    "\n",
    "  <pre style=\"\n",
    "    margin:0;\n",
    "    padding:10px 14px;\n",
    "    background:#020617;\n",
    "    color:#e5e7eb;\n",
    "    font-family:'Fira Code',ui-monospace,Consolas,'Courier New',monospace;\n",
    "    font-size:13px;\n",
    "    line-height:1.55;\n",
    "    white-space:pre-wrap;\n",
    "    word-break:break-word;\n",
    "    border-radius:0 0 10px 10px;\n",
    "    border-top:1px solid #1f2937;\n",
    "  \">{code}</pre>\n",
    "</details>\n",
    "\"\"\"\n",
    "        panels.append(panel_html)\n",
    "\n",
    "    wrapper = f\"\"\"\n",
    "<div style=\"margin:12px 0;\">\n",
    "  <div style=\"\n",
    "    font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',sans-serif;\n",
    "    font-size:13px;\n",
    "    color:#4b5563;\n",
    "    margin-bottom:6px;\n",
    "  \">\n",
    "    Found <strong>{len(cells_info)}</strong> code cell(s) starting with <code># 2</code> in <code>{NOTEBOOK_PATH.name}</code>:\n",
    "  </div>\n",
    "  {''.join(panels)}\n",
    "</div>\n",
    "\"\"\"\n",
    "    display(HTML(wrapper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217bb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1ï¸âƒ£  CONFIGURATION  â€” edit this if your file is named differently\n",
    "# ---------------------------------------------------------\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2ï¸âƒ£  LOAD NOTEBOOK\n",
    "# ---------------------------------------------------------\n",
    "if not NOTEBOOK_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found: {NOTEBOOK_PATH.resolve()}\")\n",
    "\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3ï¸âƒ£  GATHER CODE CELLS THAT START WITH \"# 2\"\n",
    "# ---------------------------------------------------------\n",
    "section_code = []\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        if not src.strip():\n",
    "            continue\n",
    "        first_line = next((ln.strip() for ln in src.splitlines() if ln.strip()), \"\")\n",
    "        if first_line.startswith(\"# 2\"):\n",
    "            section_code.append(src.rstrip())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4ï¸âƒ£  BUILD COLLAPSIBLE HTML\n",
    "# ---------------------------------------------------------\n",
    "if section_code:\n",
    "    combined = \"\\n\\n\".join(section_code)\n",
    "    html = f\"\"\"\n",
    "<details style='margin:12px 0; border:1px solid #e5e7eb; border-radius:10px;\n",
    "  background:linear-gradient(135deg,#f9fafb,#eef2ff); font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",sans-serif;'>\n",
    "  <summary style='cursor:pointer; list-style:none; padding:10px 14px; font-weight:600;\n",
    "    color:#0f172a; display:flex; justify-content:space-between; align-items:center;'>\n",
    "    <span style='display:flex;align-items:center;gap:8px;'>ğŸ“œ Aggregated Section 2 Code ({len(section_code)} cells)</span>\n",
    "    <span style='font-size:11px; background:#0f172a; color:#f9fafb; padding:2px 8px;\n",
    "      border-radius:999px; text-transform:uppercase; letter-spacing:0.06em;'>click to toggle</span>\n",
    "  </summary>\n",
    "\n",
    "  <pre style='margin:0; padding:12px 16px; background:#020617; color:#e5e7eb;\n",
    "    font-family:\"Fira Code\",ui-monospace,Consolas,\"Courier New\",monospace;\n",
    "    font-size:13px; line-height:1.55; white-space:pre-wrap; word-break:break-word;\n",
    "    border-radius:0 0 10px 10px; border-top:1px solid #1f2937;'>\n",
    "{combined}\n",
    "  </pre>\n",
    "</details>\n",
    "\"\"\"\n",
    "    display(HTML(html))\n",
    "else:\n",
    "    display(HTML(\"<p style='color:#b91c1c;'>âš ï¸ No code cells starting with '# 2' found in this notebook.</p>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb16251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# --- identify current notebook file ---\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")  # adjust if your notebook name differs\n",
    "\n",
    "# --- load the notebook ---\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# --- gather only code cells whose first nonblank line starts with '# 2' ---\n",
    "matching_cells = []\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        first_line = next((ln.strip() for ln in src.splitlines() if ln.strip()), \"\")\n",
    "        if first_line.startswith(\"# 2\"):\n",
    "            matching_cells.append(src.strip())\n",
    "\n",
    "# --- aggregate ---\n",
    "if matching_cells:\n",
    "    header = (\n",
    "        \"```python\\n\"\n",
    "        \"# ==============================================\\n\"\n",
    "        \"# Aggregated Python Cells from 01_EDA.ipynb\\n\"\n",
    "        \"# Matching pattern: lines starting with '# 2'\\n\"\n",
    "        \"# ==============================================\\n\\n\"\n",
    "    )\n",
    "    footer = \"\\n```\"\n",
    "    joined_code = \"\\n\\n\\n\".join(matching_cells)\n",
    "    display(Markdown(header + joined_code + footer))\n",
    "else:\n",
    "    display(Markdown(\"> âš ï¸ **No code cells starting with `# 2` were found.**\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1781e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, io, os\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1ï¸âƒ£ Try to infer current notebook name (works in most Jupyter setups)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "    if ip is not None and hasattr(ip, 'kernel'):\n",
    "        connection_file = Path(ip.kernel.connection_file)\n",
    "        notebook_name = next(\n",
    "            (p.name for p in Path('.').glob('*.ipynb') if str(p.stat().st_ino) in str(connection_file)),\n",
    "            None\n",
    "        )\n",
    "    else:\n",
    "        notebook_name = None\n",
    "except Exception:\n",
    "    notebook_name = None\n",
    "\n",
    "# fallback manual name if automatic detection fails\n",
    "if not notebook_name:\n",
    "    notebook_name = \"01_EDA.ipynb\"\n",
    "\n",
    "NOTEBOOK_PATH = Path(notebook_name)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2ï¸âƒ£ Load the notebook JSON\n",
    "# ---------------------------------------------------------------------\n",
    "if not NOTEBOOK_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found: {NOTEBOOK_PATH.resolve()}\")\n",
    "\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3ï¸âƒ£ Collect code cells whose first non-empty line starts with \"# 2\"\n",
    "# ---------------------------------------------------------------------\n",
    "section_code = []\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        if not src.strip():\n",
    "            continue\n",
    "        first_line = next((ln.strip() for ln in src.splitlines() if ln.strip()), \"\")\n",
    "        if first_line.startswith(\"# 2\"):\n",
    "            section_code.append(src.rstrip())\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4ï¸âƒ£ Aggregate and render inline\n",
    "# ---------------------------------------------------------------------\n",
    "# if section_code:\n",
    "#     combined = \"\\n\\n\".join(section_code)\n",
    "#     md = f\"```python\\n{combined}\\n```\"\n",
    "#     display(Markdown(f\"### ğŸ§© Aggregated Section 2 Code ({len(section_code)} cells)\\n\\n\" + md))\n",
    "# else:\n",
    "#     display(Markdown(\"> âš ï¸ **No code cells starting with `# 2` found in this notebook.**\"))\n",
    "\n",
    "Path(\"section2_aggregate.py\").write_text(combined, encoding=\"utf-8\")\n",
    "print(\"âœ… Saved section2_aggregate.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1ï¸âƒ£  CONFIGURATION  â€” edit this if your file is named differently\n",
    "# ---------------------------------------------------------\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2ï¸âƒ£  LOAD NOTEBOOK\n",
    "# ---------------------------------------------------------\n",
    "if not NOTEBOOK_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found: {NOTEBOOK_PATH.resolve()}\")\n",
    "\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3ï¸âƒ£  GATHER CODE CELLS THAT START WITH \"# 2\"\n",
    "# ---------------------------------------------------------\n",
    "section_code = []\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        if not src.strip():\n",
    "            continue\n",
    "        first_line = next((ln.strip() for ln in src.splitlines() if ln.strip()), \"\")\n",
    "        if first_line.startswith(\"# 2\"):\n",
    "            section_code.append(src.rstrip())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4ï¸âƒ£  BUILD COLLAPSIBLE HTML\n",
    "# ---------------------------------------------------------\n",
    "if section_code:\n",
    "    combined = \"\\n\\n\".join(section_code)\n",
    "    html = f\"\"\"\n",
    "<details style='margin:12px 0; border:1px solid #e5e7eb; border-radius:10px;\n",
    "  background:linear-gradient(135deg,#f9fafb,#eef2ff); font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",sans-serif;'>\n",
    "  <summary style='cursor:pointer; list-style:none; padding:10px 14px; font-weight:600;\n",
    "    color:#0f172a; display:flex; justify-content:space-between; align-items:center;'>\n",
    "    <span style='display:flex;align-items:center;gap:8px;'>ğŸ“œ Aggregated Section 2 Code ({len(section_code)} cells)</span>\n",
    "    <span style='font-size:11px; background:#0f172a; color:#f9fafb; padding:2px 8px;\n",
    "      border-radius:999px; text-transform:uppercase; letter-spacing:0.06em;'>click to toggle</span>\n",
    "  </summary>\n",
    "\n",
    "  <pre style='margin:0; padding:12px 16px; background:#020617; color:#e5e7eb;\n",
    "    font-family:\"Fira Code\",ui-monospace,Consolas,\"Courier New\",monospace;\n",
    "    font-size:13px; line-height:1.55; white-space:pre-wrap; word-break:break-word;\n",
    "    border-radius:0 0 10px 10px; border-top:1px solid #1f2937;'>\n",
    "{combined}\n",
    "  </pre>\n",
    "</details>\n",
    "\"\"\"\n",
    "    display(HTML(html))\n",
    "else:\n",
    "    display(HTML(\"<p style='color:#b91c1c;'>âš ï¸ No code cells starting with '# 2' found in this notebook.</p>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1747c08",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"\n",
    "    cursor:pointer;background:#f7f7fb;border:2px solid #297be7ff;\n",
    "padding:10px 12px;border-radius:10px;font-weight:700;\">\n",
    "extraction\n",
    "</summary>\n",
    "\n",
    "Perfect â€” you want a script that programmatically extracts all **Python code cells** from your `01_EDA.ipynb` Jupyter notebook that **begin with comments starting with `# 2`** (e.g., `# 2.0`, `# 2.3.1`, etc.), then aggregates them into one file or display block.\n",
    "\n",
    "Hereâ€™s a clean, production-ready script that does exactly that ğŸ‘‡\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© `aggregate_section2_cells.py`\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "aggregate_section2_cells.py\n",
    "-------------------------------------\n",
    "Extracts all Python code cells from 01_EDA.ipynb that start with \"# 2\"\n",
    "and concatenates them into a single file named section2_cells.py\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1ï¸âƒ£  CONFIGURATION\n",
    "# ------------------------------------------------------------------\n",
    "NOTEBOOK_PATH = Path(\"01_EDA.ipynb\")   # adjust path if needed\n",
    "OUTPUT_FILE   = Path(\"section2_cells.py\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2ï¸âƒ£  VALIDATE INPUT FILE\n",
    "# ------------------------------------------------------------------\n",
    "if not NOTEBOOK_PATH.exists():\n",
    "    raise FileNotFoundError(f\"âŒ Notebook not found: {NOTEBOOK_PATH.resolve()}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3ï¸âƒ£  LOAD NOTEBOOK\n",
    "# ------------------------------------------------------------------\n",
    "with open(NOTEBOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4ï¸âƒ£  FILTER CELLS THAT ARE PYTHON CODE STARTING WITH '# 2'\n",
    "# ------------------------------------------------------------------\n",
    "aggregated_code = []\n",
    "\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    if cell.get(\"cell_type\") == \"code\":\n",
    "        source = \"\".join(cell.get(\"source\", []))\n",
    "        # Check if the first non-blank line starts with '# 2'\n",
    "        first_line = next((line.strip() for line in source.splitlines() if line.strip()), \"\")\n",
    "        if first_line.startswith(\"# 2\"):\n",
    "            aggregated_code.append(source.strip())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5ï¸âƒ£  WRITE TO OUTPUT FILE\n",
    "# ------------------------------------------------------------------\n",
    "if not aggregated_code:\n",
    "    print(\"âš ï¸  No matching '# 2' cells found.\")\n",
    "else:\n",
    "    header = (\n",
    "        \"# ==============================================\\n\"\n",
    "        \"# Aggregated Python Cells from 01_EDA.ipynb\\n\"\n",
    "        \"# Matching pattern: lines starting with '# 2'\\n\"\n",
    "        \"# ==============================================\\n\\n\"\n",
    "    )\n",
    "    OUTPUT_FILE.write_text(header + \"\\n\\n\\n\".join(aggregated_code), encoding=\"utf-8\")\n",
    "    print(f\"âœ… Extracted {len(aggregated_code)} matching cells to {OUTPUT_FILE.resolve()}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ How it works\n",
    "\n",
    "* Reads your `01_EDA.ipynb` as JSON.\n",
    "* Filters only **code cells** (`cell_type == \"code\"`).\n",
    "* Checks the **first non-empty line** â€” if it starts with `# 2`, itâ€™s included.\n",
    "* Joins them into a single Python file `section2_cells.py`.\n",
    "* Keeps your notebook untouched.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§° Example usage\n",
    "\n",
    "In your terminal (from the project root):\n",
    "\n",
    "```bash\n",
    "python aggregate_section2_cells.py\n",
    "```\n",
    "\n",
    "Then open `section2_cells.py` and youâ€™ll see something like:\n",
    "\n",
    "```python\n",
    "# ==============================================\n",
    "# Aggregated Python Cells from 01_EDA.ipynb\n",
    "# Matching pattern: lines starting with '# 2'\n",
    "# ==============================================\n",
    "\n",
    "# 2.0 Data Quality Overview\n",
    "print(\"Running Section 2.0 Checks...\")\n",
    "\n",
    "# 2.1 Base Schema & Consistency\n",
    "...\n",
    "\n",
    "# 2.2 Numeric Validation\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Would you like the script to **output the aggregated code to the terminal instead of writing a file**, or to **append timestamps / section headers automatically** (so itâ€™s easy to track runs)?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
