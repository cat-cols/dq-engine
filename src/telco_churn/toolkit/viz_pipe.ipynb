{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "225b0e1e",
   "metadata": {},
   "source": [
    "How can I get a time-series (in order visual) of every df used in this dq pipeline. I want to see how it starts and how it branches and transforms through the pipeline. I also want to see when and where variables are created and what they are connected to visually.. Can I create something that makes it look like a plumbers pipe network?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4df815",
   "metadata": {},
   "source": [
    "Yes, you 100% can do this ‚Äì and it‚Äôs a *perfect* use-case for a little lineage registry + graph.\n",
    "\n",
    "Think of it in two layers:\n",
    "\n",
    "1. **A timeline / lineage table** of every ‚Äúversion‚Äù of `df` you create.\n",
    "2. **A DAG / graph** that shows how those versions flow and branch ‚Äì your plumber‚Äôs pipe network.\n",
    "\n",
    "Below is a concrete pattern you can drop into your project.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Add a tiny lineage registry (one-time helper)\n",
    "\n",
    "Put this in a helpers module, e.g. `src/telco_churn/lineage.py` (so your 2.x notebook can still be ‚Äúno-def‚Äù):\n",
    "\n",
    "```python\n",
    "# src/telco_churn/lineage.py\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "@dataclass\n",
    "class DFNode:\n",
    "    node_id: str           # unique id for the node (e.g. \"step_2.3.1_df_profiled\")\n",
    "    name: str              # friendly name (e.g. \"df_profiled\")\n",
    "    step: str              # section/step id (e.g. \"2.3.1\")\n",
    "    description: str       # what this step did\n",
    "    parents: List[str]     # list of parent node_ids\n",
    "    n_rows: int\n",
    "    n_cols: int\n",
    "    cols_added: List[str]\n",
    "    cols_removed: List[str]\n",
    "    timestamp: float       # time when registered (for ordering)\n",
    "    sample_hash: str       # hash of a small sample for ‚Äúshape-of-data‚Äù fingerprint\n",
    "\n",
    "class DFLineageRegistry:\n",
    "    def __init__(self):\n",
    "        self.nodes: Dict[str, DFNode] = {}\n",
    "        self.last_node_for_dfname: Dict[str, str] = {}  # df_name -> node_id\n",
    "\n",
    "    def _hash_sample(self, df: pd.DataFrame, n: int = 10) -> str:\n",
    "        if df.empty:\n",
    "            return \"empty\"\n",
    "        sample = df.head(n).to_json(orient=\"split\", default_handler=str)\n",
    "        return hashlib.md5(sample.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    def register(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        df_name: str,\n",
    "        step: str,\n",
    "        description: str = \"\",\n",
    "        parents: Optional[List[str]] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Register a new DF state and return its node_id.\"\"\"\n",
    "        if parents is None:\n",
    "            parents = []\n",
    "\n",
    "        # infer parents from last node of this df_name if none provided\n",
    "        if not parents and df_name in self.last_node_for_dfname:\n",
    "            parents = [self.last_node_for_dfname[df_name]]\n",
    "\n",
    "        node_id = f\"{step}_{df_name}\"\n",
    "\n",
    "        # column diffs vs first parent (if any)\n",
    "        cols = list(df.columns)\n",
    "        cols_added, cols_removed = [], []\n",
    "        if parents:\n",
    "            parent_node = self.nodes[parents[0]]\n",
    "            parent_cols = set(parent_node.cols_added) | set(parent_node.cols_removed) \\\n",
    "                          if False else set()  # we‚Äôll recompute from df sample\n",
    "            # simpler: use parent snapshot stored in registry? (future enhancement)\n",
    "        # for now: we‚Äôll compute added/removed by storing the parent‚Äôs column set separately:\n",
    "        # to keep it simple, we won‚Äôt use that trick here ‚Äì just leave cols_added/removed',\n",
    "        # or fill them in manually later if you want.\n",
    "\n",
    "        n_rows = int(df.shape[0])\n",
    "        n_cols = int(df.shape[1])\n",
    "\n",
    "        node = DFNode(\n",
    "            node_id=node_id,\n",
    "            name=df_name,\n",
    "            step=step,\n",
    "            description=description,\n",
    "            parents=parents,\n",
    "            n_rows=n_rows,\n",
    "            n_cols=n_cols,\n",
    "            cols_added=cols_added,\n",
    "            cols_removed=cols_removed,\n",
    "            timestamp=time.time(),\n",
    "            sample_hash=self._hash_sample(df),\n",
    "        )\n",
    "\n",
    "        self.nodes[node_id] = node\n",
    "        self.last_node_for_dfname[df_name] = node_id\n",
    "        return node_id\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame([asdict(n) for n in self.nodes.values()])\n",
    "```\n",
    "\n",
    "Then, in your notebook:\n",
    "\n",
    "```python\n",
    "from telco_churn.lineage import DFLineageRegistry\n",
    "\n",
    "df_lineage = DFLineageRegistry()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Instrument your pipeline steps\n",
    "\n",
    "Now, whenever you have a meaningful ‚Äúversion‚Äù of a dataframe, register it.\n",
    "\n",
    "### Example: early pipeline\n",
    "\n",
    "```python\n",
    "# After you load raw data\n",
    "df = pd.read_csv(raw_path)\n",
    "node_raw = df_lineage.register(\n",
    "    df=df,\n",
    "    df_name=\"df\",\n",
    "    step=\"2.0.0\",\n",
    "    description=\"Loaded raw Telco CSV\"\n",
    ")\n",
    "\n",
    "# After basic type coercions / schema normalization (2.1.x)\n",
    "# df = your coerced version\n",
    "node_21 = df_lineage.register(\n",
    "    df=df,\n",
    "    df_name=\"df\",\n",
    "    step=\"2.1.5\",\n",
    "    description=\"Post core numeric/categorical type alignment\"\n",
    ")\n",
    "\n",
    "# After profiling / quality diagnostics (2.3 final df used for diagnostics)\n",
    "node_23 = df_lineage.register(\n",
    "    df=df,\n",
    "    df_name=\"df\",\n",
    "    step=\"2.3.14\",\n",
    "    description=\"Post numeric/categorical diagnostics ‚Äì ready for cleaning\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Example: cleaning branch (using your 2.6 convention)\n",
    "\n",
    "If you‚Äôre using `df_before_clean` and `df_clean`:\n",
    "\n",
    "```python\n",
    "# 2.6.0 ‚Äì before & working copy\n",
    "df_before_clean = df.copy(deep=True)\n",
    "df_clean = df.copy(deep=True)\n",
    "\n",
    "node_before_clean = df_lineage.register(\n",
    "    df=df_before_clean,\n",
    "    df_name=\"df_before_clean\",\n",
    "    step=\"2.6.0\",\n",
    "    description=\"Snapshot before controlled cleaning\"\n",
    ")\n",
    "\n",
    "node_clean_260 = df_lineage.register(\n",
    "    df=df_clean,\n",
    "    df_name=\"df_clean\",\n",
    "    step=\"2.6.0\",\n",
    "    description=\"Initial working copy for cleaning\"\n",
    ")\n",
    "\n",
    "# After a cleaning step, e.g. 2.6.3 missing value imputation\n",
    "# df_clean[...] = ...\n",
    "node_clean_263 = df_lineage.register(\n",
    "    df=df_clean,\n",
    "    df_name=\"df_clean\",\n",
    "    step=\"2.6.3\",\n",
    "    description=\"After missing value imputation\",\n",
    ")\n",
    "```\n",
    "\n",
    "If you ever **branch** (e.g. create a temporary df for a scenario):\n",
    "\n",
    "```python\n",
    "df_outlier_clip = df_clean[df_clean[\"MonthlyCharges\"] < 300].copy()\n",
    "\n",
    "node_outlier_clip = df_lineage.register(\n",
    "    df=df_outlier_clip,\n",
    "    df_name=\"df_outlier_clip\",\n",
    "    step=\"2.6.4\",\n",
    "    description=\"Outlier-clipped copy for analysis\",\n",
    "    parents=[node_clean_263],  # explicitly set parent to show branch\n",
    ")\n",
    "```\n",
    "\n",
    "Later if you merge back:\n",
    "\n",
    "```python\n",
    "df_clean = df_outlier_clip  # or some merge logic\n",
    "node_clean_265 = df_lineage.register(\n",
    "    df=df_clean,\n",
    "    df_name=\"df_clean\",\n",
    "    step=\"2.6.5\",\n",
    "    description=\"After applying outlier decisions back to df_clean\",\n",
    "    parents=[node_outlier_clip],\n",
    ")\n",
    "```\n",
    "\n",
    "Now you‚Äôre accumulating a **time-ordered lineage of every dataframe** used in the pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. See the time-series / evolution (table + simple plots)\n",
    "\n",
    "At any point:\n",
    "\n",
    "```python\n",
    "lineage_df = df_lineage.to_dataframe().sort_values(\"timestamp\")\n",
    "display(lineage_df[[\"step\", \"name\", \"n_rows\", \"n_cols\", \"description\"]])\n",
    "```\n",
    "\n",
    "You can quickly plot, say, **row count over time**:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lineage_df = df_lineage.to_dataframe().sort_values(\"timestamp\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lineage_df[\"step\"], lineage_df[\"n_rows\"], marker=\"o\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"n_rows\")\n",
    "plt.title(\"Row count over pipeline steps\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "That gives you the **time-series** feel: how the dataset size changes as it flows through the pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Build the plumber-pipe graph (DAG)\n",
    "\n",
    "For the ‚Äúpipe network‚Äù visual, Graphviz is really nice.\n",
    "\n",
    "```python\n",
    "from graphviz import Digraph\n",
    "\n",
    "def build_dq_graph(registry: DFLineageRegistry) -> Digraph:\n",
    "    dot = Digraph(comment=\"Section 2 Data Quality Pipeline\")\n",
    "    dot.attr(rankdir=\"LR\")  # left-to-right like a pipe\n",
    "\n",
    "    # nodes\n",
    "    for node in registry.nodes.values():\n",
    "        label = f\"{node.step}\\\\n{node.name}\\\\nrows={node.n_rows}, cols={node.n_cols}\"\n",
    "        dot.node(\n",
    "            node.node_id,\n",
    "            label=label,\n",
    "            shape=\"box\",\n",
    "            style=\"rounded,filled\",\n",
    "        )\n",
    "\n",
    "    # edges\n",
    "    for node in registry.nodes.values():\n",
    "        for parent_id in node.parents:\n",
    "            dot.edge(parent_id, node.node_id)\n",
    "\n",
    "    return dot\n",
    "\n",
    "dq_graph = build_dq_graph(df_lineage)\n",
    "dq_graph\n",
    "```\n",
    "\n",
    "In Jupyter this will render as a **DAG**:\n",
    "\n",
    "* **Boxes** are dataframe states.\n",
    "* **Arrows** are transformations.\n",
    "* The left-to-right flow gives the ‚Äúpipes‚Äù vibe.\n",
    "\n",
    "You can tweak ‚Äúplumber aesthetics‚Äù further:\n",
    "\n",
    "```python\n",
    "dot.attr(\"node\", shape=\"box\", style=\"rounded,filled\", penwidth=\"1.5\")\n",
    "dot.attr(\"edge\", penwidth=\"1.5\")\n",
    "```\n",
    "\n",
    "You can also color nodes by **phase**:\n",
    "\n",
    "* 2.0‚Äì2.2 = ingestion/sanity (blue)\n",
    "* 2.3‚Äì2.5 = diagnostics (orange)\n",
    "* 2.6 = cleaning/apply (green)\n",
    "\n",
    "(Just parse `node.step` and set `fillcolor` based on prefixes.)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Tracking *where variables/columns are created*\n",
    "\n",
    "If you want to see **which step created which columns**, two options:\n",
    "\n",
    "### Option A ‚Äì cheap & good enough\n",
    "\n",
    "When you know you‚Äôre *adding* columns in a step, you can explicitly annotate in the description:\n",
    "\n",
    "```python\n",
    "node_2513 = df_lineage.register(\n",
    "    df=df,\n",
    "    df_name=\"df\",\n",
    "    step=\"2.5.13\",\n",
    "    description=\"Added flags: has_fiber, high_charges_flag\"\n",
    ")\n",
    "```\n",
    "\n",
    "Then you can filter `lineage_df` for descriptions containing `\"Added\"` or whatever pattern you choose.\n",
    "\n",
    "### Option B ‚Äì automated column diff\n",
    "\n",
    "If you‚Äôre okay adding a bit more machinery:\n",
    "\n",
    "* Store, inside `DFNode`, a `columns` field (list of column names).\n",
    "\n",
    "* When registering a new node, if there‚Äôs a parent, compute:\n",
    "\n",
    "  ```python\n",
    "  cols_added = sorted(list(set(current_cols) - set(parent_cols)))\n",
    "  cols_removed = sorted(list(set(parent_cols) - set(current_cols)))\n",
    "  ```\n",
    "\n",
    "* Save `cols_added` / `cols_removed` in the node.\n",
    "\n",
    "Then you can do:\n",
    "\n",
    "```python\n",
    "lineage_df = df_lineage.to_dataframe().explode(\"cols_added\")\n",
    "new_cols = lineage_df[~lineage_df[\"cols_added\"].isna()][[\"step\", \"cols_added\", \"description\"]]\n",
    "display(new_cols)\n",
    "```\n",
    "\n",
    "That becomes a **‚Äúcolumn origin map‚Äù**: each column and the step where it first appeared.\n",
    "\n",
    "We can also, if you want later, build a **bipartite graph** (nodes = dataframe snapshots + column nodes) so it *really* looks like a complex pipe manifold ‚Äì but the simple DAG with annotated labels is usually enough and easier to read.\n",
    "\n",
    "---\n",
    "\n",
    "If you‚Äôd like, I can next:\n",
    "\n",
    "* üí°üí° Sketch a concrete `DFLineageRegistry` v2 that **automatically** tracks `columns`, `cols_added`, `cols_removed` correctly, and\n",
    "* üí°üí° Show how to layer this into your existing **Section 2** naming (2.0.0, 2.1.3, 2.3.14, 2.6.10, etc.) with example calls right where you already have `print(\"2.5.3 ‚Ä¶\")` etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4bf6b",
   "metadata": {},
   "source": [
    "Can you create a version I don't have to put in the notebook but abstracts any \"df\" variable throughout the entire thing?\n",
    "\n",
    "Totally love this idea ‚Äì ‚Äúplumber‚Äôs pipe network‚Äù is exactly what data lineage *should* feel like. üßë‚Äçüîßü™†\n",
    "\n",
    "You *can‚Äôt* magically track every dataframe in a notebook with **zero** hooks, but we can get **very close**:\n",
    "\n",
    "* Put **all the logic in a separate module** (`lineage_auto.py`).\n",
    "* In the notebook, you just sprinkle **one small line per major step**, and it will:\n",
    "\n",
    "  * auto-discover any `df*` variable in `globals()` (e.g. `df`, `df_clean`, `df_before_clean`, `df_num_profile`, etc.),\n",
    "  * register them in a lineage registry,\n",
    "  * compute column diffs vs the previous version,\n",
    "  * later render:\n",
    "\n",
    "    * a **time-series table**, and\n",
    "    * a **Graphviz DAG** that looks like a pipe network.\n",
    "\n",
    "Below is that module + how to use it.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Drop this into `telco_churn/lineage_auto.py`\n",
    "\n",
    "```python\n",
    "# telco_churn/lineage_auto.py\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Optional, Iterable, Callable\n",
    "import pandas as pd\n",
    "import numpy as np  # noqa: F401  # might be handy later\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from graphviz import Digraph\n",
    "except ImportError:\n",
    "    Digraph = None  # graceful fallback\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Core data structure: one node = one snapshot of a df-like variable\n",
    "# -------------------------------------------------------------------\n",
    "@dataclass\n",
    "class DFNode:\n",
    "    node_id: str           # unique id: f\"{step}:{df_name}\"\n",
    "    df_name: str           # variable name: \"df\", \"df_clean\", \"df_before_clean\", etc.\n",
    "    step: str              # pipeline step: \"2.0.0\", \"2.3.14\", \"2.6.10\", ...\n",
    "    description: str       # human text of what we did\n",
    "    parents: List[str]     # node_ids of parents\n",
    "    n_rows: int\n",
    "    n_cols: int\n",
    "    columns: List[str]\n",
    "    cols_added: List[str]\n",
    "    cols_removed: List[str]\n",
    "    timestamp: float       # time.time()\n",
    "    sample_hash: str       # md5 of small JSON sample for \"shape\" fingerprint\n",
    "\n",
    "\n",
    "class DFLineageRegistry:\n",
    "    \"\"\"\n",
    "    Registry that tracks df-like variables across steps.\n",
    "    You don't touch this directly much; you'll mostly call register_step().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nodes: Dict[str, DFNode] = {}\n",
    "        self.last_node_for_dfname: Dict[str, str] = {}\n",
    "        self._columns_for_node: Dict[str, List[str]] = {}\n",
    "\n",
    "    # ------------- internals ------------- #\n",
    "\n",
    "    def _hash_sample(self, df: pd.DataFrame, n: int = 10) -> str:\n",
    "        if df is None or getattr(df, \"empty\", False):\n",
    "            return \"empty\"\n",
    "        try:\n",
    "            sample = df.head(n).to_json(orient=\"split\", default_handler=str)\n",
    "        except Exception:\n",
    "            sample = \"unhashable\"\n",
    "        return hashlib.md5(sample.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    def _compute_col_diff(\n",
    "        self,\n",
    "        current_cols: Iterable[str],\n",
    "        parent_node_id: Optional[str],\n",
    "    ) -> (List[str], List[str]):\n",
    "        current_cols = list(current_cols)\n",
    "        if not parent_node_id or parent_node_id not in self._columns_for_node:\n",
    "            # No parent info: can't diff; treat everything as \"existing\" not \"added\"\n",
    "            return [], []\n",
    "        parent_cols = set(self._columns_for_node[parent_node_id])\n",
    "        curr_cols_set = set(current_cols)\n",
    "        cols_added = sorted(list(curr_cols_set - parent_cols))\n",
    "        cols_removed = sorted(list(parent_cols - curr_cols_set))\n",
    "        return cols_added, cols_removed\n",
    "\n",
    "    # ------------- public methods ------------- #\n",
    "\n",
    "    def register_df(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        df_name: str,\n",
    "        step: str,\n",
    "        description: str = \"\",\n",
    "        parents: Optional[List[str]] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Register a single df snapshot.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node_id : str\n",
    "            The ID of the created node (e.g. \"2.3.14:df_clean\").\n",
    "        \"\"\"\n",
    "        if parents is None:\n",
    "            parents = []\n",
    "\n",
    "        # If parents not explicitly set, infer from last node of same df_name\n",
    "        if not parents and df_name in self.last_node_for_dfname:\n",
    "            parents = [self.last_node_for_dfname[df_name]]\n",
    "\n",
    "        node_id = f\"{step}:{df_name}\"\n",
    "\n",
    "        # Basic shape\n",
    "        n_rows = int(df.shape[0])\n",
    "        n_cols = int(df.shape[1])\n",
    "        cols = list(map(str, df.columns))\n",
    "\n",
    "        # Column diff vs first parent (if any)\n",
    "        parent_id = parents[0] if parents else None\n",
    "        cols_added, cols_removed = self._compute_col_diff(cols, parent_id)\n",
    "\n",
    "        node = DFNode(\n",
    "            node_id=node_id,\n",
    "            df_name=df_name,\n",
    "            step=step,\n",
    "            description=description,\n",
    "            parents=parents,\n",
    "            n_rows=n_rows,\n",
    "            n_cols=n_cols,\n",
    "            columns=cols,\n",
    "            cols_added=cols_added,\n",
    "            cols_removed=cols_removed,\n",
    "            timestamp=time.time(),\n",
    "            sample_hash=self._hash_sample(df),\n",
    "        )\n",
    "\n",
    "        self.nodes[node_id] = node\n",
    "        self.last_node_for_dfname[df_name] = node_id\n",
    "        self._columns_for_node[node_id] = cols\n",
    "        return node_id\n",
    "\n",
    "    def register_step(\n",
    "        self,\n",
    "        namespace: Dict[str, object],\n",
    "        step: str,\n",
    "        description: str = \"\",\n",
    "        name_filter: Optional[Callable[[str], bool]] = None,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Auto-register all df-like variables in a given namespace\n",
    "        (e.g. globals()) for a given pipeline step.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        namespace : dict\n",
    "            Usually globals() from your notebook cell.\n",
    "        step : str\n",
    "            Step identifier like \"2.3.14\" or \"2.6.10\".\n",
    "        description : str\n",
    "            Human text for this step (what it represents).\n",
    "        name_filter : callable or None\n",
    "            Function name -> bool. If None, defaults to variables whose names\n",
    "            start with \"df\" (df, df_clean, df_before_clean, df_num_profile, etc.).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        node_ids : list of str\n",
    "            Node IDs registered for this step.\n",
    "        \"\"\"\n",
    "        if name_filter is None:\n",
    "            def name_filter(n: str) -> bool:\n",
    "                return n.startswith(\"df\")\n",
    "\n",
    "        node_ids: List[str] = []\n",
    "        for name, value in namespace.items():\n",
    "            if not name_filter(name):\n",
    "                continue\n",
    "            # Only track pandas DataFrame objects\n",
    "            if isinstance(value, pd.DataFrame):\n",
    "                node_id = self.register_df(\n",
    "                    df=value,\n",
    "                    df_name=name,\n",
    "                    step=step,\n",
    "                    description=description,\n",
    "                )\n",
    "                node_ids.append(node_id)\n",
    "        return node_ids\n",
    "\n",
    "    # ----------- export helpers ----------- #\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        if not self.nodes:\n",
    "            return pd.DataFrame(columns=[\n",
    "                \"node_id\", \"df_name\", \"step\", \"description\",\n",
    "                \"parents\", \"n_rows\", \"n_cols\",\n",
    "                \"columns\", \"cols_added\", \"cols_removed\",\n",
    "                \"timestamp\", \"sample_hash\",\n",
    "            ])\n",
    "        return pd.DataFrame([asdict(n) for n in self.nodes.values()])\n",
    "\n",
    "    def build_graph(self, rankdir: str = \"LR\") -> \"Digraph\":\n",
    "        \"\"\"\n",
    "        Build a Graphviz Digraph representing the lineage graph.\n",
    "\n",
    "        rankdir:\n",
    "            \"LR\" = left-to-right (pipe-like),\n",
    "            \"TB\" = top-to-bottom, etc.\n",
    "        \"\"\"\n",
    "        if Digraph is None:\n",
    "            raise ImportError(\n",
    "                \"graphviz is not installed. `pip install graphviz` \"\n",
    "                \"and make sure Graphviz binaries are available.\"\n",
    "            )\n",
    "\n",
    "        dot = Digraph(comment=\"DQ Pipeline Lineage\")\n",
    "        dot.attr(rankdir=rankdir)\n",
    "        dot.attr(\"node\", shape=\"box\", style=\"rounded,filled\", penwidth=\"1.5\")\n",
    "        dot.attr(\"edge\", penwidth=\"1.5\")\n",
    "\n",
    "        # Node colors by phase for plumber-y vibe\n",
    "        def color_for_step(step: str) -> str:\n",
    "            if step.startswith(\"2.0\") or step.startswith(\"2.1\") or step.startswith(\"2.2\"):\n",
    "                return \"#cfe2ff\"  # ingestion/schema\n",
    "            if step.startswith(\"2.3\") or step.startswith(\"2.4\") or step.startswith(\"2.5\"):\n",
    "                return \"#ffe5b4\"  # diagnostics\n",
    "            if step.startswith(\"2.6\"):\n",
    "                return \"#d3f9d8\"  # cleaning/apply\n",
    "            return \"#e2e3e5\"      # default/other\n",
    "\n",
    "        for node in self.nodes.values():\n",
    "            label = (\n",
    "                f\"{node.step}\\\\n\"\n",
    "                f\"{node.df_name}\\\\n\"\n",
    "                f\"rows={node.n_rows}, cols={node.n_cols}\"\n",
    "            )\n",
    "            dot.node(\n",
    "                node.node_id,\n",
    "                label=label,\n",
    "                fillcolor=color_for_step(node.step),\n",
    "            )\n",
    "\n",
    "        for node in self.nodes.values():\n",
    "            for parent_id in node.parents:\n",
    "                if parent_id in self.nodes:\n",
    "                    dot.edge(parent_id, node.node_id)\n",
    "\n",
    "        return dot\n",
    "\n",
    "\n",
    "# Global singleton you can import & use everywhere\n",
    "LINEAGE = DFLineageRegistry()\n",
    "```\n",
    "\n",
    "That‚Äôs it ‚Äì this file lives in your project, *not* in the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Minimal usage in the notebook\n",
    "\n",
    "You only need **1‚Äì2 tiny lines per major step**, no heavy code.\n",
    "\n",
    "At the top of the Section 2 notebook:\n",
    "\n",
    "```python\n",
    "from telco_churn.lineage_auto import LINEAGE\n",
    "```\n",
    "\n",
    "Then, at natural ‚Äúcheckpoints‚Äù (end of 2.0.0, 2.1.x, 2.3.14, 2.6.0, 2.6.10, etc.), add:\n",
    "\n",
    "```python\n",
    "# After 2.0.0 bootstrap / load\n",
    "LINEAGE.register_step(\n",
    "    globals(),\n",
    "    step=\"2.0.0\",\n",
    "    description=\"Bootstrap & load raw Telco data\"\n",
    ")\n",
    "\n",
    "# After 2.1.x schema normalization\n",
    "LINEAGE.register_step(\n",
    "    globals(),\n",
    "    step=\"2.1.5\",\n",
    "    description=\"Post core numeric/categorical type alignment\"\n",
    ")\n",
    "\n",
    "# After 2.3.14 numeric/categorical diagnostics\n",
    "LINEAGE.register_step(\n",
    "    globals(),\n",
    "    step=\"2.3.14\",\n",
    "    description=\"Diagnostics complete ‚Äì ready for controlled cleaning\"\n",
    ")\n",
    "\n",
    "# 2.6.0 ‚Äì right after you create df_before_clean / df_clean\n",
    "LINEAGE.register_step(\n",
    "    globals(),\n",
    "    step=\"2.6.0\",\n",
    "    description=\"Snapshot before cleaning & initial df_clean\"\n",
    ")\n",
    "\n",
    "# After a big cleaning step (say, missing value imputation)\n",
    "LINEAGE.register_step(\n",
    "    globals(),\n",
    "    step=\"2.6.3\",\n",
    "    description=\"After missing-value imputation rules\"\n",
    ")\n",
    "\n",
    "# After full 2.6.x completed\n",
    "LINEAGE.register_step(\n",
    "    globals(),\n",
    "    step=\"2.6.12\",\n",
    "    description=\"Final cleaned df + audit metadata\"\n",
    ")\n",
    "```\n",
    "\n",
    "Because `register_step`:\n",
    "\n",
    "* looks at `globals()`,\n",
    "* finds any variable whose name **starts with `\"df\"`**,\n",
    "* and is a `pd.DataFrame`,\n",
    "\n",
    "you don‚Äôt have to spell out `df`, `df_clean`, `df_before_clean`, `df_cat_profile`, etc. It just scoops them all and wires parent relationships based on previous registrations of the same name.\n",
    "\n",
    "So it **abstracts any `df*` variable** without cluttering your notebook with lineage internals.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Time-series / evolution view\n",
    "\n",
    "At the end (or whenever you want a snapshot):\n",
    "\n",
    "```python\n",
    "lineage_df = LINEAGE.to_dataframe().sort_values(\"timestamp\")\n",
    "\n",
    "# High-level evolution:\n",
    "display(\n",
    "    lineage_df[\n",
    "        [\"step\", \"df_name\", \"n_rows\", \"n_cols\", \"cols_added\", \"cols_removed\", \"description\"]\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "If you want a quick time-series for `df_clean` only:\n",
    "\n",
    "```python\n",
    "df_clean_hist = (\n",
    "    lineage_df[lineage_df[\"df_name\"] == \"df_clean\"]\n",
    "    .sort_values(\"timestamp\")\n",
    ")\n",
    "\n",
    "display(df_clean_hist[[\"step\", \"n_rows\", \"n_cols\", \"cols_added\", \"cols_removed\"]])\n",
    "```\n",
    "\n",
    "You‚Äôll see how `df_clean` starts and changes over 2.6.x.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Plumber-pipe DAG visual\n",
    "\n",
    "If you have `graphviz` installed:\n",
    "\n",
    "```python\n",
    "from telco_churn.lineage_auto import LINEAGE\n",
    "\n",
    "dq_graph = LINEAGE.build_graph(rankdir=\"LR\")  # LR = left‚Üíright pipes\n",
    "dq_graph\n",
    "```\n",
    "\n",
    "That gives you a **graph** where:\n",
    "\n",
    "* Each box is a df snapshot (`2.3.14\\ndf`, `2.6.0\\ndf_before_clean`, `2.6.3\\ndf_clean`, etc.).\n",
    "* Arrows show flow.\n",
    "* Colors indicate phase:\n",
    "\n",
    "  * blue-ish = 2.0‚Äì2.2 (ingestion/schema),\n",
    "  * orange-ish = 2.3‚Äì2.5 (diagnostics),\n",
    "  * green-ish = 2.6 (cleaning).\n",
    "\n",
    "Which is very much the ‚Äúcopper pipes running through your wall‚Äù vibe.\n",
    "\n",
    "If you want to go even more plumber-core later, we can:\n",
    "\n",
    "* üí°üí° Add edge labels for ‚Äúwhat happened here?‚Äù (`Missing value rules`, `Outlier winsorization`, etc.).\n",
    "* üí°üí° Add a column-level bipartite option (nodes for columns + nodes for df snapshots), so you can trace an individual column through the pipe maze.\n",
    "\n",
    "---\n",
    "\n",
    "If you paste this module and the small `LINEAGE.register_step(globals(), ...)` calls into your flow, your pipeline will start *documenting itself* as it runs, without stuffing a ton of logic into the notebook itself.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
