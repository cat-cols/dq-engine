{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d175bc0",
   "metadata": {},
   "source": [
    "# X: ARTIFACT REGISTRY\n",
    "\n",
    "# 2 Types:\n",
    "# 1: NO FUNCTIONS\n",
    "# 2: FUNCTIONS\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "># V1: NO FUNCTIONS\n",
    "\n",
    "Got you ‚Äî **no `def`** anywhere. Below is the same ‚Äúlatest artifact registry‚Äù idea refactored into **drop-in, inline (procedural) snippets** you can paste into **2.0 bootstrap** and then reuse in sections by setting a few variables.\n",
    "\n",
    "I‚Äôm giving you three pieces:\n",
    "\n",
    "1. **Bootstrap constants + `_latest` setup** (goes in 2.0)\n",
    "2. **Publish block** (copy/paste anywhere after you save an artifact)\n",
    "3. **Resolve/consume block** (copy/paste anywhere you need to load an artifact, e.g., 2.9.5)\n",
    "\n",
    "---\n",
    "\n",
    "## 1) 2.0 bootstrap: create `_latest` + standard metadata suffix\n",
    "\n",
    "Put this **right after** you create `SEC2_LATEST_DIR` (you already do):\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "import os, json, shutil\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "assert \"SEC2_LATEST_DIR\" in globals(), \"‚ùå SEC2_LATEST_DIR missing; run Part 5 first.\"\n",
    "SEC2_LATEST_DIR = Path(SEC2_LATEST_DIR).resolve()\n",
    "SEC2_LATEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Convention: every published artifact has a sidecar meta json\n",
    "SEC2_LATEST_META_SUFFIX = \".meta.json\"\n",
    "\n",
    "print(\"üìå SEC2_LATEST_DIR ready:\", SEC2_LATEST_DIR)\n",
    "```\n",
    "\n",
    "No functions, just globals.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Publish block (copy/paste pattern)\n",
    "\n",
    "Use this anytime you generate an artifact that other sections should consume.\n",
    "\n",
    "### You set these variables:\n",
    "\n",
    "* `PUBLISH_SRC_PATH` (Path to the file you just wrote)\n",
    "* `PUBLISH_SECTION` (e.g., `\"2.3\"`)\n",
    "* `PUBLISH_TAGS` (list of strings)\n",
    "* optional `PUBLISH_NAME` (defaults to the filename)\n",
    "\n",
    "```python\n",
    "# -------------------------------\n",
    "# SEC2 LATEST PUBLISH (no funcs)\n",
    "# -------------------------------\n",
    "PUBLISH_SRC_PATH = Path(PUBLISH_SRC_PATH).expanduser().resolve()\n",
    "if not PUBLISH_SRC_PATH.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå publish: src not found: {PUBLISH_SRC_PATH}\")\n",
    "\n",
    "PUBLISH_NAME = globals().get(\"PUBLISH_NAME\", None) or PUBLISH_SRC_PATH.name\n",
    "PUBLISH_SECTION = globals().get(\"PUBLISH_SECTION\", None)\n",
    "PUBLISH_TAGS = globals().get(\"PUBLISH_TAGS\", []) or []\n",
    "PUBLISH_OVERWRITE = bool(globals().get(\"PUBLISH_OVERWRITE\", True))\n",
    "\n",
    "PUBLISH_DEST_PATH = (SEC2_LATEST_DIR / PUBLISH_NAME).resolve()\n",
    "\n",
    "if PUBLISH_DEST_PATH.exists() and not PUBLISH_OVERWRITE:\n",
    "    print(f\"   ‚ö†Ô∏è publish: exists and overwrite=False ‚Üí {PUBLISH_DEST_PATH}\")\n",
    "else:\n",
    "    # atomic copy: copy to tmp then replace\n",
    "    _tmp = PUBLISH_DEST_PATH.with_suffix(PUBLISH_DEST_PATH.suffix + \".tmp\")\n",
    "    _tmp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(PUBLISH_SRC_PATH, _tmp)\n",
    "    os.replace(_tmp, PUBLISH_DEST_PATH)\n",
    "\n",
    "    # write metadata sidecar\n",
    "    _meta = {\n",
    "        \"name\": PUBLISH_NAME,\n",
    "        \"published_at_utc\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\").replace(\"+00:00\", \"Z\"),\n",
    "        \"section\": PUBLISH_SECTION,\n",
    "        \"source_path\": str(PUBLISH_SRC_PATH),\n",
    "        \"size_bytes\": PUBLISH_DEST_PATH.stat().st_size if PUBLISH_DEST_PATH.exists() else None,\n",
    "        \"tags\": list(PUBLISH_TAGS),\n",
    "    }\n",
    "    _meta_path = Path(str(PUBLISH_DEST_PATH) + SEC2_LATEST_META_SUFFIX)\n",
    "    with _meta_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(_meta, f, indent=2)\n",
    "\n",
    "    print(f\"   ‚úÖ Published latest ‚Üí {PUBLISH_DEST_PATH}\")\n",
    "```\n",
    "\n",
    "### Example usage inside 2.3 after saving:\n",
    "\n",
    "```python\n",
    "PUBLISH_SRC_PATH = numeric_profile_path\n",
    "PUBLISH_SECTION = \"2.3\"\n",
    "PUBLISH_TAGS = [\"profile\", \"numeric\"]\n",
    "# PUBLISH_NAME = \"numeric_profile_df.csv\"  # optional (defaults to same)\n",
    "# PUBLISH_OVERWRITE = True                 # optional\n",
    "# then paste publish block\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Resolve/consume block (copy/paste pattern)\n",
    "\n",
    "This finds the artifact by checking:\n",
    "\n",
    "1. `_latest/<name>` first\n",
    "2. then any fallback dirs you provide\n",
    "3. optionally **recursive** search (rglob) for when artifacts are buried in subfolders\n",
    "\n",
    "### You set:\n",
    "\n",
    "* `RESOLVE_NAME` (like `\"numeric_profile_df.csv\"`)\n",
    "* `RESOLVE_DIRS` (list of dirs to search after `_latest`)\n",
    "* optional `RESOLVE_RECURSIVE` (`True/False`)\n",
    "* optional `RESOLVE_REQUIRED` (`True/False`)\n",
    "\n",
    "```python\n",
    "# -----------------------------------\n",
    "# SEC2 ARTIFACT RESOLVE (no funcs)\n",
    "# -----------------------------------\n",
    "RESOLVE_NAME = str(RESOLVE_NAME)\n",
    "RESOLVE_RECURSIVE = bool(globals().get(\"RESOLVE_RECURSIVE\", False))\n",
    "RESOLVE_REQUIRED = bool(globals().get(\"RESOLVE_REQUIRED\", False))\n",
    "\n",
    "RESOLVED_PATH = None\n",
    "\n",
    "# 1) prefer _latest\n",
    "_cand = (SEC2_LATEST_DIR / RESOLVE_NAME).resolve()\n",
    "if _cand.exists():\n",
    "    RESOLVED_PATH = _cand\n",
    "\n",
    "# 2) fallback dirs (direct)\n",
    "if RESOLVED_PATH is None:\n",
    "    for _d in (RESOLVE_DIRS or []):\n",
    "        if _d is None:\n",
    "            continue\n",
    "        _d = Path(_d).expanduser().resolve()\n",
    "        _cand = (_d / RESOLVE_NAME).resolve()\n",
    "        if _cand.exists():\n",
    "            RESOLVED_PATH = _cand\n",
    "            break\n",
    "\n",
    "# 3) optional recursive\n",
    "if RESOLVED_PATH is None and RESOLVE_RECURSIVE:\n",
    "    for _d in (RESOLVE_DIRS or []):\n",
    "        if _d is None:\n",
    "            continue\n",
    "        _d = Path(_d).expanduser().resolve()\n",
    "        if not _d.exists():\n",
    "            continue\n",
    "        _hits = list(_d.rglob(RESOLVE_NAME))\n",
    "        if _hits:\n",
    "            _hits.sort(key=lambda p: p.stat().st_mtime, reverse=True)  # newest wins\n",
    "            RESOLVED_PATH = _hits[0].resolve()\n",
    "            break\n",
    "\n",
    "if RESOLVED_PATH is None and RESOLVE_REQUIRED:\n",
    "    _msg = \"‚ùå resolve: artifact not found\\n\"\n",
    "    _msg += f\"   name: {RESOLVE_NAME}\\n\"\n",
    "    _msg += f\"   latest: {SEC2_LATEST_DIR}\\n\"\n",
    "    _msg += \"   searched:\\n\" + \"\\n\".join([f\"     - {Path(d).expanduser().resolve()}\" for d in (RESOLVE_DIRS or []) if d is not None])\n",
    "    raise FileNotFoundError(_msg)\n",
    "\n",
    "print(\"   üîé RESOLVED_PATH =\", RESOLVED_PATH)\n",
    "```\n",
    "\n",
    "### Example usage in 2.9.5 for each artifact:\n",
    "\n",
    "```python\n",
    "RESOLVE_NAME = \"numeric_profile_df.csv\"\n",
    "RESOLVE_DIRS = [\n",
    "    SEC2_REPORT_DIRS.get(\"2.3\"),\n",
    "    SEC2_REPORTS_DIR,\n",
    "]\n",
    "RESOLVE_RECURSIVE = True\n",
    "RESOLVE_REQUIRED = False\n",
    "# paste resolve block\n",
    "\n",
    "df_art = _safe_load_csv(RESOLVED_PATH) if RESOLVED_PATH else None\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Optional: `_latest` ‚Äúmanifest‚Äù view (no functions)\n",
    "\n",
    "```python\n",
    "rows = []\n",
    "for p in sorted(SEC2_LATEST_DIR.glob(\"*\")):\n",
    "    if p.name.endswith(SEC2_LATEST_META_SUFFIX):\n",
    "        continue\n",
    "    meta_path = Path(str(p) + SEC2_LATEST_META_SUFFIX)\n",
    "    published = None\n",
    "    section = None\n",
    "    tags = None\n",
    "    if meta_path.exists():\n",
    "        try:\n",
    "            meta = json.loads(meta_path.read_text(encoding=\"utf-8\"))\n",
    "            published = meta.get(\"published_at_utc\")\n",
    "            section = meta.get(\"section\")\n",
    "            tags = meta.get(\"tags\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    rows.append({\"name\": p.name, \"section\": section, \"published_at_utc\": published, \"tags\": tags, \"path\": str(p)})\n",
    "\n",
    "latest_manifest_df = pd.DataFrame(rows)\n",
    "display(latest_manifest_df)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí°üí° How this fixes your current pain (2.9.5)\n",
    "\n",
    "Once you add a `PUBLISH_*` block to each upstream producer (2.3, 2.4, 2.5, ‚Ä¶), 2.9.5 can just resolve from `_latest` and stop guessing file locations.\n",
    "\n",
    "If you want, paste the **list of artifacts you want standardized** (the ones you attempted to merge in 2.9.5), and I‚Äôll give you the exact **one-line ‚Äúset vars‚Äù** you should add at the end of each producing section to publish them to `_latest`.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "># V2: FUNCTIONS\n",
    "Absolutely. Here‚Äôs a **clean, minimal ‚Äúartifact registry‚Äù** you can drop into **2.0 bootstrap** that gives you:\n",
    "\n",
    "* **Publish:** copy an artifact to `SEC2_LATEST_DIR/<artifact_name>` (atomic, with metadata)\n",
    "* **Consume:** resolve an artifact by searching `_latest` first, then fallback dirs (optionally recursive)\n",
    "* **One-liner ergonomics** for 2.3‚Äì2.10 and 2.9.5 rollups\n",
    "\n",
    "Below is copy/paste-ready code.\n",
    "\n",
    "---\n",
    "\n",
    "# 1) Add this to 2.0 bootstrap (after SEC2_LATEST_DIR exists)\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "assert \"SEC2_LATEST_DIR\" in globals(), \"‚ùå SEC2_LATEST_DIR missing; run bootstrap Part 5 first.\"\n",
    "SEC2_LATEST_DIR = Path(SEC2_LATEST_DIR).resolve()\n",
    "SEC2_LATEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- Artifact Registry Helpers (Section 2) ----\n",
    "\n",
    "def sec2_publish_latest(\n",
    "    src_path,\n",
    "    *,\n",
    "    name=None,\n",
    "    section=None,\n",
    "    tags=None,\n",
    "    overwrite=True,\n",
    "    also_copy_to=None,   # optional additional destinations (list[Path])\n",
    "):\n",
    "    \"\"\"\n",
    "    Publish an artifact to SEC2_LATEST_DIR as the canonical cross-section input.\n",
    "\n",
    "    - Copies src_path -> SEC2_LATEST_DIR/name (atomic)\n",
    "    - Writes metadata -> SEC2_LATEST_DIR/name.meta.json\n",
    "    \"\"\"\n",
    "    src_path = Path(src_path).expanduser().resolve()\n",
    "    if not src_path.exists():\n",
    "        raise FileNotFoundError(f\"‚ùå publish_latest: src not found: {src_path}\")\n",
    "\n",
    "    dest_name = name or src_path.name\n",
    "    dest_path = (SEC2_LATEST_DIR / dest_name).resolve()\n",
    "\n",
    "    if dest_path.exists() and not overwrite:\n",
    "        print(f\"   ‚ö†Ô∏è publish_latest: exists and overwrite=False ‚Üí {dest_path}\")\n",
    "        return dest_path\n",
    "\n",
    "    # atomic copy\n",
    "    tmp_path = dest_path.with_suffix(dest_path.suffix + \".tmp\")\n",
    "    tmp_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(src_path, tmp_path)\n",
    "    os.replace(tmp_path, dest_path)\n",
    "\n",
    "    meta = {\n",
    "        \"name\": dest_name,\n",
    "        \"published_at_utc\": datetime.now(timezone.utc).isoformat(timespec=\"seconds\").replace(\"+00:00\", \"Z\"),\n",
    "        \"section\": section,\n",
    "        \"source_path\": str(src_path),\n",
    "        \"size_bytes\": dest_path.stat().st_size if dest_path.exists() else None,\n",
    "        \"tags\": list(tags) if tags else [],\n",
    "    }\n",
    "    meta_path = dest_path.with_suffix(dest_path.suffix + \".meta.json\")\n",
    "    with meta_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    # optional fan-out\n",
    "    if also_copy_to:\n",
    "        for d in also_copy_to:\n",
    "            d = Path(d).expanduser().resolve()\n",
    "            d.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(dest_path, (d / dest_name).resolve())\n",
    "\n",
    "    print(f\"   ‚úÖ Published latest ‚Üí {dest_path}\")\n",
    "    return dest_path\n",
    "\n",
    "\n",
    "def sec2_resolve_artifact(\n",
    "    name,\n",
    "    *,\n",
    "    section=None,\n",
    "    search_dirs=None,\n",
    "    prefer_latest=True,\n",
    "    recursive=False,\n",
    "    required=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Resolve an artifact path.\n",
    "\n",
    "    Search order (default):\n",
    "      1) SEC2_LATEST_DIR / name        (if prefer_latest)\n",
    "      2) section dir (SEC2_REPORT_DIRS[section] or SEC2_ARTIFACT_DIRS[section]) if provided in search_dirs\n",
    "      3) any additional search_dirs\n",
    "\n",
    "    If recursive=True, rglob(name) within each search_dir.\n",
    "    \"\"\"\n",
    "    name = str(name)\n",
    "\n",
    "    # 1) latest first\n",
    "    if prefer_latest:\n",
    "        p = (SEC2_LATEST_DIR / name).resolve()\n",
    "        if p.exists():\n",
    "            return p\n",
    "\n",
    "    # 2) build dirs\n",
    "    dirs = []\n",
    "    if search_dirs:\n",
    "        dirs.extend([Path(d).expanduser().resolve() for d in search_dirs if d is not None])\n",
    "\n",
    "    # 3) try direct lookup\n",
    "    for d in dirs:\n",
    "        cand = (d / name).resolve()\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "\n",
    "    # 4) optionally recursive\n",
    "    if recursive:\n",
    "        for d in dirs:\n",
    "            if d.exists():\n",
    "                hits = list(d.rglob(name))\n",
    "                if hits:\n",
    "                    # newest wins\n",
    "                    hits.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "                    return hits[0].resolve()\n",
    "\n",
    "    if required:\n",
    "        raise FileNotFoundError(\n",
    "            \"‚ùå sec2_resolve_artifact: not found\\n\"\n",
    "            f\"   name: {name}\\n\"\n",
    "            f\"   prefer_latest: {prefer_latest}\\n\"\n",
    "            f\"   recursive: {recursive}\\n\"\n",
    "            \"   searched:\\n\" + \"\\n\".join([f\"     - {d}\" for d in dirs])\n",
    "        )\n",
    "    return None\n",
    "\n",
    "\n",
    "def sec2_latest_manifest():\n",
    "    \"\"\"\n",
    "    Quick view of what's in _latest (filenames + timestamps if meta exists).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for p in sorted(SEC2_LATEST_DIR.glob(\"*\")):\n",
    "        if p.name.endswith(\".meta.json\"):\n",
    "            continue\n",
    "        meta_path = p.with_suffix(p.suffix + \".meta.json\")\n",
    "        published = None\n",
    "        section = None\n",
    "        if meta_path.exists():\n",
    "            try:\n",
    "                meta = json.loads(meta_path.read_text(encoding=\"utf-8\"))\n",
    "                published = meta.get(\"published_at_utc\")\n",
    "                section = meta.get(\"section\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        rows.append({\"name\": p.name, \"section\": section, \"published_at_utc\": published, \"path\": str(p)})\n",
    "    return pd.DataFrame(rows)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 2) Use it when creating artifacts in 2.x sections (publish once you save)\n",
    "\n",
    "Example: in **2.3 numeric profile** after you save `numeric_profile_df.csv`:\n",
    "\n",
    "```python\n",
    "numeric_profile_path = SEC2_REPORT_DIRS[\"2.3\"] / \"numeric_profile_df.csv\"\n",
    "numeric_profile_df.to_csv(numeric_profile_path, index=False)\n",
    "\n",
    "sec2_publish_latest(\n",
    "    numeric_profile_path,\n",
    "    section=\"2.3\",\n",
    "    tags=[\"profile\", \"numeric\"]\n",
    ")\n",
    "```\n",
    "\n",
    "Same idea for 2.4 categorical profile, 2.5 logic readiness, etc.\n",
    "\n",
    "---\n",
    "\n",
    "# 3) Update 2.9.5 to consume from `_latest` first (no hunting)\n",
    "\n",
    "In 2.9.5, instead of hardcoding per-section paths, do:\n",
    "\n",
    "```python\n",
    "SECTION2_ARTIFACTS = {\n",
    "    \"numeric_profile_df.csv\": (\"feature\", [\"missing_pct\", \"outlier_pct\"]),\n",
    "    \"categorical_profile_df.csv\": (\"feature\", [\"missing_pct\", \"domain_violation_pct\"]),\n",
    "    \"logic_readiness_report.csv\": (\"feature\", [\"logic_violation_pct\", \"contract_breach_flags\"]),\n",
    "    \"drift_report.csv\": (\"feature\", [\"drift_score\"]),\n",
    "    \"effect_stability_metrics.csv\": (\"feature\", [\"effect_stability_score\"]),\n",
    "    \"statistical_readiness_index.csv\": (\"feature\", [\"sri_score\"]),\n",
    "    \"signal_to_noise_report.csv\": (\"feature\", [\"snr_bucket\", \"bias_risk_flag\"]),\n",
    "}\n",
    "\n",
    "# fallback dirs if not in _latest\n",
    "fallback_dirs = [\n",
    "    SEC2_REPORT_DIRS.get(\"2.3\"),\n",
    "    SEC2_REPORT_DIRS.get(\"2.4\"),\n",
    "    SEC2_REPORT_DIRS.get(\"2.5\"),\n",
    "    SEC2_REPORT_DIRS.get(\"2.6\"),\n",
    "    SEC2_REPORT_DIRS.get(\"2.7\"),\n",
    "    SEC2_REPORT_DIRS.get(\"2.8\"),\n",
    "    SEC2_REPORTS_DIR,\n",
    "]\n",
    "\n",
    "for fname, (key, metric_cols) in SECTION2_ARTIFACTS.items():\n",
    "    df_path = sec2_resolve_artifact(\n",
    "        fname,\n",
    "        search_dirs=fallback_dirs,\n",
    "        prefer_latest=True,\n",
    "        recursive=True,     # handles your subfolder situation\n",
    "        required=False\n",
    "    )\n",
    "    if df_path is None:\n",
    "        print(f\"   ‚ö†Ô∏è 2.9.5: {fname} not found (latest+fallback); skipping.\")\n",
    "        continue\n",
    "\n",
    "    df_art = _safe_load_csv(df_path)\n",
    "    ...\n",
    "```\n",
    "\n",
    "Now 2.9.5 ‚Äújust works‚Äù as soon as upstream sections publish.\n",
    "\n",
    "---\n",
    "\n",
    "# 4) Sanity check: see what‚Äôs currently published\n",
    "\n",
    "Run:\n",
    "\n",
    "```python\n",
    "display(sec2_latest_manifest())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí°üí° One tiny policy that makes this shine\n",
    "\n",
    "When you create any rollup-worthy artifact, always save it with:\n",
    "\n",
    "* a `feature` column (not index)\n",
    "* stable filename (don‚Äôt version the name ‚Äî version the run elsewhere)\n",
    "\n",
    "Then `_latest` becomes your ‚Äúsemantic interface‚Äù between sections.\n",
    "\n",
    "---\n",
    "\n",
    "If you want, paste the list of artifacts you consider ‚Äúcross-section inputs‚Äù (the ones 2.9.5 should roll up), and I‚Äôll give you a **standard publish call** for each one (and where it should live: reports vs artifacts).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2305384",
   "metadata": {},
   "source": [
    "Usually, yes: **prefer `setup_summary` for ‚Äúrecorded truths‚Äù** (where your data/config actually are), and use the filesystem discovery (`.git` ‚Üí `PROJECT_ROOT`, then `PROJECT_ROOT/_T2/Level_3`) for **structure truths** (where this notebook *lives*).\n",
    "\n",
    "Here‚Äôs the clean rule that keeps you out of trouble:\n",
    "\n",
    "* **Use filesystem discovery for:**\n",
    "\n",
    "  * `PROJECT_ROOT` (via `.git`)\n",
    "  * `LEVEL_ROOT = PROJECT_ROOT / TIER_LEVEL / LEVEL_NAME`\n",
    "  * `REPORTS_DIR / ARTIFACTS_DIR / FIGURES_DIR / ‚Ä¶` (derived from `LEVEL_ROOT`)\n",
    "  * `SRC_ROOT` (derived from `LEVEL_ROOT`)\n",
    "\n",
    "* **Use `setup_summary` for:**\n",
    "\n",
    "  * `CONFIG_PATH` (but auto-fix if it points to an old non-tier path)\n",
    "  * `RAW_DATA` / `PROCESSED_DIR` (because those may be project-global, not level-scoped)\n",
    "  * anything ‚Äúwhere did we last write/read the canonical artifact?‚Äù\n",
    "\n",
    "Why: `setup_summary` can go stale when you move folders (like you did), but **it‚Äôs still the best single place to remember where the dataset + config were**‚Äîas long as you add a ‚Äúrepair‚Äù step.\n",
    "\n",
    "üí°üí° Best practice pattern (what I‚Äôd do in your notebook)\n",
    "\n",
    "1. Discover structure first:\n",
    "\n",
    "```python\n",
    "PROJECT_ROOT = find_git_root()\n",
    "LEVEL_ROOT = PROJECT_ROOT / TIER_LEVEL / LEVEL_NAME\n",
    "```\n",
    "\n",
    "2. Load `setup_summary` next, but **treat its paths as hints**:\n",
    "\n",
    "* If `setup_summary[\"project\"][\"config_path\"]` is missing, rebuild to `LEVEL_ROOT/config/project_config.yaml`\n",
    "* If `setup_summary` says `.../Telco/Level_3/...`, rewrite it to `.../Telco/_T2/Level_3/...` and (optionally) save a patched copy.\n",
    "\n",
    "So the ‚Äúbetter‚Äù answer is:\n",
    "\n",
    "‚úÖ **Better to load from `setup_summary` for config/data locations**\n",
    "‚úÖ **Better to derive from `LEVEL_ROOT` for level directories**\n",
    "‚ùå Don‚Äôt let `setup_summary` dictate `LEVEL_ROOT` (because you *want* tiering to be the source of truth now)\n",
    "\n",
    "If you want, paste your current `setup_summary` JSON structure (just the `project` + `paths` keys), and I‚Äôll give you a compact ‚Äúload + auto-repair + (optional) rewrite setup_summary‚Äù cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e914e",
   "metadata": {},
   "source": [
    "should I keep the sec2_diagnostics_rows.append in addition to the summary_272 = pd.DataFrame ??\n",
    "\n",
    "If your goal is **one source of truth** (the CSV you build via `append_sec2`), then **no ‚Äî you don‚Äôt *need* to keep** `sec2_diagnostics_rows.append(...)`.\n",
    "\n",
    "### What I‚Äôd do (cleanest)\n",
    "\n",
    "* **Keep**: `summary_272 = pd.DataFrame([...])` + `append_sec2(summary_272, SECTION2_REPORT_PATH)`\n",
    "* **Drop**: `sec2_diagnostics_rows.append(...)`\n",
    "\n",
    "Because otherwise you‚Äôre maintaining **two parallel logs** that will eventually disagree (or one will be missing rows), and you‚Äôll waste time debugging ‚Äúwhy is it in memory but not on disk?‚Äù\n",
    "\n",
    "### When keeping `sec2_diagnostics_rows.append(...)` *is* useful\n",
    "\n",
    "Only keep it if you‚Äôre using `sec2_diagnostics_rows` **later in the same run** to generate something like:\n",
    "\n",
    "* a single ‚Äúend-of-section‚Äù table in the notebook,\n",
    "* a combined HTML summary,\n",
    "* quick `display(pd.DataFrame(sec2_diagnostics_rows))` without re-reading the master CSV.\n",
    "\n",
    "If that‚Äôs your use case, then keep it ‚Äî but treat it explicitly as a **convenience cache**, not truth.\n",
    "\n",
    "üí°üí° Best compromise pattern:\n",
    "\n",
    "* Keep `sec2_diagnostics_rows.append(...)` **only if** `sec2_diagnostics_rows` exists, and only append the *exact same row* you wrote to the master:\n",
    "\n",
    "```python\n",
    "# master truth\n",
    "append_sec2(summary_272, SECTION2_REPORT_PATH)\n",
    "\n",
    "# optional cache (same row, for in-notebook display only)\n",
    "if \"sec2_diagnostics_rows\" in globals() and isinstance(sec2_diagnostics_rows, list):\n",
    "    sec2_diagnostics_rows.append(summary_272.iloc[0].to_dict())\n",
    "```\n",
    "\n",
    "That way you don‚Äôt diverge.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
