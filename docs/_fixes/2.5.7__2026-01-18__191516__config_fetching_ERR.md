# PART B | 2.5.7-2.5.9 ðŸ” Cross-Domain Consistency (Num â†” Cat Bridging)
print("PART B | 2.5.7-2.5.9 ðŸ” Cross-Domain Consistency (Num â†” Cat Bridging)")

# ðŸ§© Cross-Logic / Cross-Domain Layer
# Assumes:
#   - df is loaded
#   - pandas as pd, os, Path imported
#   - CONFIG and/or C() available
#   - SECTION2_REPORT_PATH and Section 2 summary pattern (like 2.5.6)
#   - pandas as pd, np, os, Path imported
#   - PROJECT_ROOT and/or REPORTS_DIR resolved by 2.0.x

n_rows_25B = int(df.shape[0])

# 2.5.7 | Categoricalâ€“Numeric Alignment Audit
print("\n2.5.7 ðŸ” Categoricalâ€“numeric alignment audit")

# 1) Pull CATNUM_ALIGNMENT.RULES from config
catnum_rules_257 = None

catnum_rules_257 = (globals().get("C") or CONFIG).get("CATNUM_ALIGNMENT", {}).get("RULES", {})

if "C" in globals() and callable(C):
    try:
        catnum_rules_257 = C("CATNUM_ALIGNMENT.RULES", None)
    except Exception:
        catnum_rules_257 = None

if catnum_rules_257 is None and "CONFIG" in globals():
    cfg_257 = CONFIG
    for _k_257 in "CATNUM_ALIGNMENT.RULES".split("."):
        if isinstance(cfg_257, dict) and _k_257 in cfg_257:
            cfg_257 = cfg_257[_k_257]
        else:
            cfg_257 = None
            break
    if cfg_257 is not None:
        catnum_rules_257 = cfg_257

alignment_rows_257 = []
n_rules_evaluated_257 = 0
n_rules_with_violations_257 = 0

if isinstance(catnum_rules_257, dict) and len(catnum_rules_257) > 0:
    print(f"   ðŸ”§ CATNUM_ALIGNMENT.RULES found: {len(catnum_rules_257)} rule(s).")
    for rule_id_257, rule_cfg_257 in catnum_rules_257.items():
        if not isinstance(rule_cfg_257, dict):
            continue

        rule_id_257 = str(rule_id_257)
        group_col_257 = str(rule_cfg_257.get("group_col", "") or "").strip()
        numeric_col_257 = str(rule_cfg_257.get("numeric_col", "") or "").strip()
        expectation_257 = str(rule_cfg_257.get("expectation", "") or "").strip()
        group_order_257 = rule_cfg_257.get("group_order", None)

        if not group_col_257 or not numeric_col_257:
            alignment_rows_257.append(
                {
                    "rule_id": rule_id_257,
                    "group_col": group_col_257,
                    "group_value": "",
                    "numeric_col": numeric_col_257,
                    "mean_value": float("nan"),
                    "median_value": float("nan"),
                    "count": 0,
                    "expected_relation": expectation_257,
                    "violation_flag": False,
                    "violation_gap": float("nan"),
                    "rule_severity": "info",
                    "notes": "Missing group_col or numeric_col in rule config",
                }
            )
            continue

        if group_col_257 not in df.columns or numeric_col_257 not in df.columns:
            alignment_rows_257.append(
                {
                    "rule_id": rule_id_257,
                    "group_col": group_col_257,
                    "group_value": "",
                    "numeric_col": numeric_col_257,
                    "mean_value": float("nan"),
                    "median_value": float("nan"),
                    "count": 0,
                    "expected_relation": expectation_257,
                    "violation_flag": False,
                    "violation_gap": float("nan"),
                    "rule_severity": "info",
                    "notes": "group_col or numeric_col not found in df; rule skipped",
                }
            )
            continue

        # We consider this rule evaluated
        n_rules_evaluated_257 += 1

        # 2) Build grouped numeric stats
        sub_257 = df[[group_col_257, numeric_col_257]].copy()
        sub_257[numeric_col_257] = pd.to_numeric(sub_257[numeric_col_257], errors="coerce")
        sub_257 = sub_257.dropna(subset=[group_col_257, numeric_col_257])

        if sub_257.empty:
            alignment_rows_257.append(
                {
                    "rule_id": rule_id_257,
                    "group_col": group_col_257,
                    "group_value": "",
                    "numeric_col": numeric_col_257,
                    "mean_value": float("nan"),
                    "median_value": float("nan"),
                    "count": 0,
                    "expected_relation": expectation_257,
                    "violation_flag": False,
                    "violation_gap": float("nan"),
                    "rule_severity": "info",
                    "notes": "No valid rows (after NA filtering) to evaluate",
                }
            )
            continue

        grp_257 = (
            sub_257.groupby(group_col_257)[numeric_col_257]
            .agg(["mean", "median", "count", "std", "min", "max"])
            .reset_index()
            .rename(columns={group_col_257: "group_value"})
        )

        if group_order_257 and isinstance(group_order_257, (list, tuple)):
            grp_257["__order_key_257"] = grp_257["group_value"].apply(
                lambda x: group_order_257.index(x) if x in group_order_257 else len(group_order_257)
            )
            grp_257 = grp_257.sort_values("__order_key_257").drop(columns=["__order_key_257"])
        else:
            grp_257 = grp_257.sort_values("group_value")

        grp_257["violation_flag"] = False
        grp_257["violation_gap"] = 0.0

        # 3) Apply expectation logic (only monotonic expectations supported here)
        if expectation_257 in ("monotonic_increasing", "monotonic_decreasing") and len(grp_257) > 1:
            means_257 = grp_257["mean"].tolist()
            idxs_257 = grp_257.index.tolist()

            total_violations_rule_257 = 0
            for i_257 in range(1, len(means_257)):
                prev_mean_257 = means_257[i_257 - 1]
                curr_mean_257 = means_257[i_257]
                if pd.isna(prev_mean_257) or pd.isna(curr_mean_257):
                    continue

                if expectation_257 == "monotonic_increasing" and curr_mean_257 < prev_mean_257:
                    gap_257 = float(prev_mean_257 - curr_mean_257)
                    grp_257.loc[idxs_257[i_257], "violation_flag"] = True
                    grp_257.loc[idxs_257[i_257], "violation_gap"] = gap_257
                    total_violations_rule_257 += 1
                elif expectation_257 == "monotonic_decreasing" and curr_mean_257 > prev_mean_257:
                    gap_257 = float(curr_mean_257 - prev_mean_257)
                    grp_257.loc[idxs_257[i_257], "violation_flag"] = True
                    grp_257.loc[idxs_257[i_257], "violation_gap"] = gap_257
                    total_violations_rule_257 += 1
        else:
            total_violations_rule_257 = int(grp_257["violation_flag"].sum())

        # 4) Determine rule-level severity
        if len(grp_257) == 0:
            rule_severity_257 = "info"
        else:
            if total_violations_rule_257 == 0:
                rule_severity_257 = "ok"
            else:
                frac_viol_257 = float(total_violations_rule_257) / float(len(grp_257))
                if frac_viol_257 <= 0.25:
                    rule_severity_257 = "warn"
                else:
                    rule_severity_257 = "fail"
                n_rules_with_violations_257 += 1

        # 5) Append per-group rows
        for idx_row_257, row_257 in grp_257.iterrows():
            alignment_rows_257.append(
                {
                    "rule_id": rule_id_257,
                    "group_col": group_col_257,
                    "group_value": row_257["group_value"],
                    "numeric_col": numeric_col_257,
                    "mean_value": float(row_257["mean"]) if pd.notna(row_257["mean"]) else float("nan"),
                    "median_value": float(row_257["median"]) if pd.notna(row_257["median"]) else float("nan"),
                    "count": int(row_257["count"]),
                    "expected_relation": expectation_257,
                    "violation_flag": bool(row_257["violation_flag"]),
                    "violation_gap": float(row_257["violation_gap"]),
                    "rule_severity": rule_severity_257,
                    "notes": "",
                }
            )
else:
    print("   â„¹ï¸ No CATNUM_ALIGNMENT.RULES config found; 2.5.7 will record INFO status with no rule checks.")

alignment_df_257 = pd.DataFrame(alignment_rows_257)
alignment_path_257 = sec25_reports_dir / "catnum_alignment_report.csv"
alignment_tmp_257 = alignment_path_257.with_suffix(".tmp.csv")

if not alignment_df_257.empty:
    try:
        alignment_df_257.to_csv(alignment_tmp_257, index=False)
        os.replace(alignment_tmp_257, alignment_path_257)
    except Exception:
        if alignment_tmp_257.exists():
            alignment_tmp_257.unlink()

status_257 = "INFO"
if isinstance(catnum_rules_257, dict) and len(catnum_rules_257) > 0:
    if n_rules_with_violations_257 == 0:
        status_257 = "OK"
    else:
        status_257 = "WARN"

print(f"ðŸ’¾ 2.5.7 catnum_alignment_report.csv â†’ {alignment_path_257}")
print(f"   Rules evaluated: {n_rules_evaluated_257} | with violations: {n_rules_with_violations_257}")
if not alignment_df_257.empty:
    print("   ðŸ“‹ Alignment preview (top 10):")
    display(
        alignment_df_257.loc[
            :, ["rule_id", "group_col", "group_value", "numeric_col",
                "mean_value", "count", "expected_relation",
                "violation_flag", "violation_gap", "rule_severity"]
        ].head(10)
    )

#
summary_257 = pd.DataFrame([{
    "section": "2.5.7",
    "section_name": "Categoricalâ€“numeric alignment audit",
    "check": "Validate numeric patterns within categories against configured expectations",
    "level": "info",
    "status": status_257,
    "n_rules_evaluated": int(n_rules_evaluated_257),
    "n_rules_with_violations": int(n_rules_with_violations_257),
    "detail": "catnum_alignment_report.csv",
    "timestamp": pd.Timestamp.utcnow(),
    "notes": f"Evaluated {n_rules_evaluated_257} rules; {n_rules_with_violations_257} had violations"
}])
append_sec2(summary_257, SECTION2_REPORT_PATH)

display(summary_257)

# 2.5.8 | One-Hot Sum Integrity (Encoding Cross-Check)
print("\n2.5.8 ðŸ” One-hot sum integrity (encoding cross-check)")

# TODO:
# 3V2) Derive summary metrics
# n_groups_configured_258 = len(onehot_cfg_258) if isinstance(onehot_cfg_258, dict) else 0
# n_groups_valid_cfg_258 = int(n_groups_checked_258)

# if not onehot_df_258.empty:
#     # "evaluated" = at least one column existed in df, so n_rows > 0
#     n_groups_evaluated_258 = int((onehot_df_258["n_rows"] > 0).sum())
# else:
#     n_groups_evaluated_258 = 0

# 1) Pull ONEHOT.GROUPS from config
onehot_cfg_258 = None

if "C" in globals() and callable(C):
    try:
        onehot_cfg_258 = C("ONEHOT.GROUPS", None)
    except Exception:
        onehot_cfg_258 = None

if onehot_cfg_258 is None and "CONFIG" in globals():
    _cfg_258 = CONFIG
    for _k_258 in "ONEHOT.GROUPS".split("."):
        if isinstance(_cfg_258, dict) and _k_258 in _cfg_258:
            _cfg_258 = _cfg_258[_k_258]
        else:
            _cfg_258 = None
            break
    if _cfg_258 is not None:
        onehot_cfg_258 = _cfg_258

onehot_rows_258 = []
n_groups_checked_258 = 0
n_groups_with_violations_258 = 0

if isinstance(onehot_cfg_258, dict) and len(onehot_cfg_258) > 0:
    print(f"   ðŸ”§ ONEHOT.GROUPS found: {len(onehot_cfg_258)} group(s).")
    for _gid_258, _gcfg_258 in onehot_cfg_258.items():
        if not isinstance(_gcfg_258, dict):
            continue

        group_id_258 = str(_gid_258)
        cols_258 = _gcfg_258.get("columns", [])
        mode_258 = str(_gcfg_258.get("mode", "mutually_exclusive") or "mutually_exclusive").strip()

        if not isinstance(cols_258, (list, tuple)) or len(cols_258) == 0:
            onehot_rows_258.append(
                {
                    "group_id": group_id_258,
                    "mode": mode_258,
                    "columns": "",
                    "n_rows": 0,
                    "n_all_zero": 0,
                    "n_single": 0,
                    "n_multi": 0,
                    "pct_all_zero": float("nan"),
                    "pct_multi": float("nan"),
                    "group_severity": "info",
                    "notes": "No columns configured for group",
                }
            )
            continue

        missing_cols_258 = [c for c in cols_258 if c not in df.columns]
        present_cols_258 = [c for c in cols_258 if c in df.columns]

        if not present_cols_258:
            onehot_rows_258.append(
                {
                    "group_id": group_id_258,
                    "mode": mode_258,
                    "columns": ", ".join(cols_258),
                    "n_rows": 0,
                    "n_all_zero": 0,
                    "n_single": 0,
                    "n_multi": 0,
                    "pct_all_zero": float("nan"),
                    "pct_multi": float("nan"),
                    "group_severity": "info",
                    "notes": f"All configured columns missing from df: {', '.join(missing_cols_258)}",
                }
            )
            continue

        n_groups_checked_258 += 1

        _flags_258 = df[present_cols_258].copy()
        for _c_258 in present_cols_258:
            _flags_258[_c_258] = pd.to_numeric(_flags_258[_c_258], errors="coerce").fillna(0.0)

        row_sum_258 = _flags_258.sum(axis=1)

        n_rows_grp_258 = int(len(row_sum_258))
        n_all_zero_258 = int((row_sum_258 == 0).sum())
        n_single_258 = int((row_sum_258 == 1).sum())
        n_multi_258 = int((row_sum_258 > 1).sum())

        pct_all_zero_258 = float(n_all_zero_258) / float(n_rows_grp_258) if n_rows_grp_258 > 0 else float("nan")
        pct_multi_258 = float(n_multi_258) / float(n_rows_grp_258) if n_rows_grp_258 > 0 else float("nan")

        # Severity based on mode
        if n_rows_grp_258 == 0:
            group_severity_258 = "info"
            notes_258 = "No rows to evaluate"
        else:
            if mode_258 == "mutually_exclusive":
                if n_multi_258 == 0:
                    group_severity_258 = "ok"
                else:
                    if pct_multi_258 <= 0.01 and n_multi_258 <= 10:
                        group_severity_258 = "warn"
                    else:
                        group_severity_258 = "fail"
                    n_groups_with_violations_258 += 1
                notes_258 = ""
            else:
                # "one_or_more" or other modes: watch all-zero pattern
                if n_all_zero_258 == 0:
                    group_severity_258 = "ok"
                else:
                    if pct_all_zero_258 <= 0.1:
                        group_severity_258 = "warn"
                    else:
                        group_severity_258 = "fail"
                    n_groups_with_violations_258 += 1
                notes_258 = ""

        if missing_cols_258:
            if notes_258:
                notes_258 = notes_258 + "; "
            notes_258 = notes_258 + f"Missing columns: {', '.join(missing_cols_258)}"

        onehot_rows_258.append(
            {
                "group_id": group_id_258,
                "mode": mode_258,
                "columns": ", ".join(cols_258),
                "n_rows": int(n_rows_grp_258),
                "n_all_zero": int(n_all_zero_258),
                "n_single": int(n_single_258),
                "n_multi": int(n_multi_258),
                "pct_all_zero": float(pct_all_zero_258),
                "pct_multi": float(pct_multi_258),
                "group_severity": group_severity_258,
                "notes": notes_258,
            }
        )
else:
    print("   â„¹ï¸ No ONEHOT.GROUPS config found; 2.5.8 will record INFO status with no group checks.")

onehot_df_258 = pd.DataFrame(onehot_rows_258)
onehot_path_258 = sec25_reports_dir / "onehot_integrity_report.csv"
onehot_tmp_258 = onehot_path_258.with_suffix(".tmp.csv")

# 2) Persist report
if not onehot_df_258.empty:
    try:
        onehot_df_258.to_csv(onehot_tmp_258, index=False)
        os.replace(onehot_tmp_258, onehot_path_258)
    except Exception:
        if onehot_tmp_258.exists():
            onehot_tmp_258.unlink()

# 3V1)
n_groups_configured_258 = len(onehot_cfg_258) if isinstance(onehot_cfg_258, dict) else 0

if not onehot_df_258.empty:
    # "valid config" = has a non-empty columns string
    n_groups_valid_cfg_258 = int(onehot_df_258["columns"].str.len().gt(0).sum())
    # "evaluated" = at least one row (i.e., at least one column existed in df)
    n_groups_evaluated_258 = int((onehot_df_258["n_rows"] > 0).sum())
else:
    n_groups_valid_cfg_258 = 0
    n_groups_evaluated_258 = 0

status_258 = "INFO"
if n_groups_configured_258 > 0:
    # If we actually evaluated any rows, interpret violations as WARN
    if n_groups_evaluated_258 > 0:
        status_258 = "OK" if n_groups_with_violations_258 == 0 else "WARN"
    else:
        status_258 = "INFO"  # config-only run, no row-wise checks performed

summary_258 = pd.DataFrame([{
    "section": "2.5.8",
    "section_name": "One-hot sum integrity (encoding cross-check)",
    "check": "Validate mutually exclusive and grouped dummy columns via row-wise sums",
    "level": "info",
    "status": status_258,
    "n_groups_configured": int(n_groups_configured_258),
    "n_groups_valid_config": int(n_groups_valid_cfg_258),
    "n_groups_evaluated": int(n_groups_evaluated_258),
    "n_groups_with_violations": int(n_groups_with_violations_258),
    "detail": "onehot_integrity_report.csv",
    "timestamp": pd.Timestamp.utcnow(),
}])

append_sec2(summary_258, SECTION2_REPORT_PATH)
display(summary_258)

# 4) Console UX
print(f"ðŸ’¾ 2.5.8 onehot_integrity_report.csv â†’ {onehot_path_258}")
print(f"   Groups configured: {n_groups_configured_258}")
print(f"   Groups with valid column config: {n_groups_valid_cfg_258}")
print(f"   Groups evaluated (cols present in df): {n_groups_evaluated_258}")
print(f"   Groups with violations: {n_groups_with_violations_258}")

if n_groups_configured_258 == 0:
    print("   â„¹ï¸ No ONEHOT.GROUPS config found; 2.5.8 recorded INFO status only.")
elif n_groups_evaluated_258 == 0:
    print("   â„¹ï¸ All configured groups had missing columns in df; "
          "this run recorded config only (no row-wise integrity checks).")

if not onehot_df_258.empty:
    # Show problematic groups first if any, otherwise just a small sample
    problem_mask_258 = onehot_df_258["group_severity"].isin(["warn", "fail"])
    if problem_mask_258.any():
        print("   ðŸ”Ž Preview of groups with issues (warn/fail):")
        preview_258 = onehot_df_258.loc[
            problem_mask_258,
            [
                "group_id", "mode", "n_rows", "n_all_zero", "n_single", "n_multi",
                "pct_all_zero", "pct_multi", "group_severity", "notes",
            ],
        ].head(10)
    else:
        print("   ðŸ“‹ One-hot integrity preview (top 10):")
        preview_258 = onehot_df_258.loc[
            :,
            [
                "group_id", "mode", "n_rows", "n_all_zero", "n_single", "n_multi",
                "pct_all_zero", "pct_multi", "group_severity", "notes",
            ],
        ].head(10)

    display(preview_258)

# 2.5.9 ðŸ§¾ Reporting: reconciliation helper stats + ledger row
print("\n2.5.9 ðŸ§¾ Reporting: reconciliation helper stats + ledger row")

helpers_259 = [
    "expected_total_from_tenure_monthly",
    "expected_total_for_zero_tenure",
    "expected_min_total_from_contract",
    "expected_total_senior",
    "expected_total_from_payment_profile",
]

created_259 = [c for c in helpers_259 if c in df.columns]
missing_259 = [c for c in helpers_259 if c not in df.columns]

# Per-helper stats artifact (min/max/mean + basic coverage)
stats_rows_259 = []

for c in helpers_259:
    if c not in df.columns:
        stats_rows_259.append({
            "helper": c,
            "present": False,
            "n_total_rows": int(len(df)),
            "n_nonnull": 0,
            "pct_nonnull": 0.0,
            "min": None,
            "max": None,
            "mean": None,
            "note": "missing_helper_column",
        })
        continue

    s = pd.to_numeric(df[c], errors="coerce")

    n_total = int(len(s))
    n_nonnull = int(s.notna().sum())
    pct_nonnull = float(n_nonnull) / float(n_total) if n_total > 0 else float("nan")

    # compute stats safely
    _min = float(s.min()) if n_nonnull > 0 else None
    _max = float(s.max()) if n_nonnull > 0 else None
    _mean = float(s.mean()) if n_nonnull > 0 else None

    stats_rows_259.append({
        "helper": c,
        "present": True,
        "n_total_rows": n_total,
        "n_nonnull": n_nonnull,
        "pct_nonnull": pct_nonnull,
        "min": _min,
        "max": _max,
        "mean": _mean,
        "note": None,
    })

recon_helpers_report_259 = pd.DataFrame(
    stats_rows_259,
    columns=["helper", "present", "n_total_rows", "n_nonnull", "pct_nonnull", "min", "max", "mean", "note"]
)

# Write artifact (atomic)
recon_report_path_259 = (sec25_reports_dir / "reconciliation_helpers_2_5_9_report.csv").resolve()
tmp_259 = recon_report_path_259.with_suffix(".tmp.csv")
recon_helpers_report_259.to_csv(tmp_259, index=False)
os.replace(tmp_259, recon_report_path_259)

print(f"ðŸ’¾ 2.5.9 helper stats report â†’ {recon_report_path_259}")
display(recon_helpers_report_259)

# Keep append_sec2 as ledger only (no full payload)
coverage_259 = {}
for c in created_259:
    try:
        coverage_259[c] = int(pd.to_numeric(df[c], errors="coerce").notna().sum())
    except Exception:
        coverage_259[c] = None

status_259 = "OK" if len(missing_259) == 0 else "WARN"
level_259 = "info" if status_259 == "OK" else "warn"

summary_259 = pd.DataFrame([{
    "section": "2.5.9",
    "section_name": "Reconciliation helper columns",
    "check": "Create helper columns + write helper stats artifact (min/max/mean)",
    "level": level_259,
    "status": status_259,
    "n_helpers_expected": int(len(helpers_259)),
    "n_helpers_created": int(len(created_259)),
    "helpers_created_json": json.dumps(created_259),
    "helpers_missing_json": json.dumps(missing_259),
    "coverage_nonnull_json": json.dumps(coverage_259, sort_keys=True),
    "artifact": recon_report_path_259.name,
    "timestamp": pd.Timestamp.utcnow(),
    "detail": f"Helper stats written: {recon_report_path_259.name}",
    "notes": None if status_259 == "OK" else "Some helper columns were skipped due to missing input columns.",
}])

append_sec2(summary_259, SECTION2_REPORT_PATH)
display(summary_259)

---------------------------------------------------------------------------
AttributeErrorÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Traceback (most recent call last)
Cell In[28], line 21
Â  Â  Â 18 # 1) Pull CATNUM_ALIGNMENT.RULES from config
Â  Â  Â 19 catnum_rules_257 = None
---> 21 catnum_rules_257 = (globals().get("C") or CONFIG).get("CATNUM_ALIGNMENT", {}).get("RULES", {})
Â  Â  Â 23 if "C" in globals() and callable(C):
Â  Â  Â 24Â  Â  Â try:

AttributeError: 'function' object has no attribute 'get'

The error occurs because of how the code attempts to fetch the configuration on line 21. It assumes that `C` (your config helper function) is a dictionary and tries to call `.get()` on it. Since `C` is a function, Python raises an `AttributeError`.

### The Fix

Replace the logic on line 21 with a more robust check that distinguishes between the helper function `C` and the raw `CONFIG` dictionary.

**Replace this:**

```python
catnum_rules_257 = (globals().get("C") or CONFIG).get("CATNUM_ALIGNMENT", {}).get("RULES", {})

```

**With this:**

```python
# Safely initialize rules
catnum_rules_257 = None

# Try the helper function first
if "C" in globals() and callable(C):
    try:
        catnum_rules_257 = C("CATNUM_ALIGNMENT.RULES", None)
    except Exception:
        pass

# Fallback to direct dictionary access if helper failed or returned None
if catnum_rules_257 is None and "CONFIG" in globals():
    catnum_rules_257 = CONFIG.get("CATNUM_ALIGNMENT", {}).get("RULES", {})

```

---

### Why this matters: Num â†” Cat Bridging

The logic you are implementing here (Section 2.5.7) is a "Semantic Validation" step. Unlike standard data type checks, cross-domain consistency ensures that the **business logic** holds true across different data types.

For example, if you have a categorical column `Seniority_Level` and a numeric column `Salary`, you might expect a `monotonic_increasing` relationship. The code you've written is designed to catch "logical outliers" where the data might be technically valid (not null, correct type) but contextually impossible.

### Summary of Changes in Part B

* **2.5.7 (Alignment):** Fixes the `AttributeError` by correctly invoking the config helper.
* **2.5.8 (One-Hot Sums):** Validates that dummy variables are actually mutually exclusive (e.g., a customer isn't marked as both `Contract_Month-to-month` and `Contract_Two_year`).
* **2.5.9 (Reconciliation):** Generates a ledger of "helper columns" which act as the ground truth for auditing final numeric totals against categorical labels.

**Would you like me to help you define a few sample `CATNUM_ALIGNMENT.RULES` in your configuration to test the monotonicity logic?**