# skip to line 275 -- not sure if this is fitting for this particular "fix" notes
You‚Äôre *very* close. The main issue in what you pasted isn‚Äôt ‚Äúconfig‚Äù anymore ‚Äî it‚Äôs **structural bugs introduced during the refactor** (a couple will hard-crash, a couple will silently misbehave).

Here‚Äôs exactly what to fix, with copy-paste patches.

---

## 1) 2.4.2 is currently broken (indentation + duplicate loops + missing init)

### Problems

* You have an `else:` with a `for` that has **no body** (syntax error):

```python
else:
    for col_242, dom_config_242 in valid_domains_242.items():
```

* You removed `unexpected_rows_242 = []` (so you‚Äôll get `NameError`)
* You duplicated the ‚Äúfinal safety‚Äù + ‚Äúskip print‚Äù + the whole `for col_242...` loop twice.

### Fix: Replace your entire 2.4.2 block with this clean version

```python
# 2.4.2 | Unexpected Categorical Values
print("\n2.4.2 üö´ Unexpected categorical values")

valid_domains_242 = C("CATEGORICAL.VALID_DOMAINS", {})

unexpected_rows_242 = []

if not valid_domains_242:
    print("   ‚ÑπÔ∏è 2.4.2: No configured VALID_DOMAINS; skipping unexpected-value checks.")
else:
    for col_242, dom_config_242 in valid_domains_242.items():
        if col_242 not in df.columns:
            continue

        s_242 = df[col_242].astype("string")
        role_242 = role_map_24.get(col_242, "feature")
        fgroup_242 = feature_group_map_24.get(col_242, "unknown")

        values_242 = s_242.value_counts(dropna=False)
        uniques_242 = values_242.index.tolist()

        allowed_values_242 = set()
        regex_list_242 = []
        domain_name_242 = col_242

        # Accept either:
        # - list of allowed values
        # - dict {"values":[...], "regex":[...], "name":"..."}
        if isinstance(dom_config_242, dict):
            vals_242 = dom_config_242.get("values", [])
            regs_242 = dom_config_242.get("regex", [])
            for v in vals_242:
                allowed_values_242.add(str(v))
            for rg in regs_242:
                try:
                    regex_list_242.append(re.compile(rg))
                except re.error:
                    pass
            if "name" in dom_config_242:
                domain_name_242 = dom_config_242["name"]
        else:
            try:
                for v in dom_config_242:
                    allowed_values_242.add(str(v))
            except TypeError:
                pass

        for val in uniques_242:
            if pd.isna(val):
                continue

            v_str_242 = str(val)
            in_set_242 = v_str_242 in allowed_values_242
            matches_regex_242 = any(r.search(v_str_242) for r in regex_list_242) if regex_list_242 else False

            if in_set_242 or matches_regex_242:
                continue

            count_242 = int(values_242.loc[val])
            pct_242 = float(count_242 / n_rows_24 * 100.0) if n_rows_24 else 0.0

            if col_242 in target_cols_24 or role_242 in {"id", "target"} or fgroup_242 == "model_feature":
                severity_242 = "critical"
            else:
                severity_242 = "warn"

            unexpected_rows_242.append(
                {
                    "column": col_242,
                    "offending_value": v_str_242,
                    "count": count_242,
                    "pct": round(pct_242, 5),
                    "expected_domain_name": domain_name_242,
                    "severity": severity_242,
                    "role": role_242,
                    "feature_group": fgroup_242,
                }
            )

unexpected_df_242 = pd.DataFrame(unexpected_rows_242)

unexpected_path_242 = sec24_reports_dir / "unexpected_values.csv"
tmp_242 = unexpected_path_242.with_suffix(".tmp.csv")
unexpected_df_242.to_csv(tmp_242, index=False)
os.replace(tmp_242, unexpected_path_242)

n_cols_with_domains_242 = len([c for c in valid_domains_242.keys() if c in df.columns]) if valid_domains_242 else 0
n_cols_with_unexp_242 = len(set(unexpected_df_242["column"])) if not unexpected_df_242.empty else 0
n_unexp_total_242 = int(unexpected_df_242.shape[0]) if not unexpected_df_242.empty else 0

if not unexpected_df_242.empty:
    _crit_cols_242 = (unexpected_df_242["severity"] == "critical").groupby(unexpected_df_242["column"]).any()
    n_critical_unexp_242 = int(_crit_cols_242.sum())
else:
    n_critical_unexp_242 = 0

if n_cols_with_unexp_242 == 0:
    status_242 = "OK"
elif n_critical_unexp_242 > 0:
    status_242 = "FAIL"
else:
    status_242 = "WARN"

summary_242 = pd.DataFrame([{
    "section": "2.4.2",
    "section_name": "Unexpected categorical values",
    "check": "Compare observed values against configured valid domains",
    "level": "info",
    "status": status_242,
    "n_columns_with_domains": int(n_cols_with_domains_242),
    "n_columns_with_unexpected_values": int(n_cols_with_unexp_242),
    "n_unexpected_values_total": int(n_unexp_total_242),
    "detail": "unexpected_values.csv",
    "timestamp": pd.Timestamp.utcnow(),
}])

print(f"üíæ 2.4.2 unexpected_values.csv ‚Üí {unexpected_path_242}")
print("\nüìä 2.4.2 unexpected_values (head):")
if not unexpected_df_242.empty:
    display(unexpected_df_242.head(20))
else:
    print("   (no unexpected values detected)")

append_sec2(summary_242, SECTION2_REPORT_PATH)
display(summary_242)
```

That is the ‚Äúcorrect‚Äù post-refactor 2.4.2.

---

## 2) 2.4.4 is missing its thresholds (will NameError)

You reference:

* `dominant_top_pct_244`
* `fragmented_top_pct_244`

‚Ä¶but never define them in the cell.

### Add this near the top of 2.4.4 (right after `freq_rows_244 = []`)

```python
dominant_top_pct_244 = float(C("CATEGORICAL.DOMAIN_FREQUENCY.DOMINANT_TOP_PCT", 95.0))
fragmented_top_pct_244 = float(C("CATEGORICAL.DOMAIN_FREQUENCY.FRAGMENTED_TOP_PCT", 10.0))
```

If you don‚Äôt have those keys in YAML, it‚Äôll use defaults and still run.

(If you prefer to reuse your existing `DATA_QUALITY` thresholds, point C() there.)

---

## 3) 2.4.5 and 2.4.6 still contain legacy fallback-walk blocks ‚Äî you can delete them now

You‚Äôre still doing the ‚Äúif C exists then fallback to CONFIG then fallback to DATA_QUALITY ‚Ä¶‚Äù dance.

Since your goal is ‚Äúuse C() everywhere‚Äù, collapse those.

### 2.4.5 thresholds (replace your entire ‚ÄúEnsure cardinality thresholds exist‚Äù block with this)

```python
high_card_limit_245 = int(C(
    "CATEGORICAL.HIGH_CARDINALITY_LIMIT",
    C("DATA_QUALITY.HIGH_CARD_THRESHOLD", 50)
))

near_unique_threshold_245 = float(C("CATEGORICAL.NEAR_UNIQUE_THRESHOLD", 0.9))
```

### 2.4.6 threshold (replace the whole ‚ÄúEnsure rare-category threshold exists‚Äù block with this)

```python
rare_threshold_pct_246 = float(C(
    "CATEGORICAL.RARE_PCT_THRESHOLD",
    C("DATA_QUALITY.RARE_PCT_THRESHOLD", 1.0)
))
```

Also: in 2.4.6 you loop `for col in cat_cols:` but you **didn‚Äôt filter out missing columns** like you did in 2.4.1/2.4.3/2.4.4. That can crash if `cat_cols` contains engineered cols not present.

Fix it like the others:

```python
valid_cat_cols_246 = [c for c in cat_cols if c in df.columns]
missing_cat_cols_246 = [c for c in cat_cols if c not in df.columns]
if missing_cat_cols_246:
    print(f"   ‚ö†Ô∏è 2.4.6: Skipping missing categorical columns (not in df): {missing_cat_cols_246}")

for col in valid_cat_cols_246:
    ...
```

---

## 4) You‚Äôre using `case_mode_243` / `unicode_norm_243` but not applying them in 2.4.1

Not required, but right now 2.4.1 scans raw tokens without normalization. That‚Äôs fine, but if you *intend* normalization, apply it consistently.

If you want normalization, change:

```python
val_str = str(val)
```

to:

```python
val_str = str(val).strip()
if case_mode_243 == "lower":
    val_str = val_str.lower()
elif case_mode_243 == "upper":
    val_str = val_str.upper()
elif case_mode_243 == "title":
    val_str = val_str.title()
if unicode_norm_243:
    try:
        val_str = unicodedata.normalize(str(unicode_norm_243), val_str)
    except Exception:
        pass
```

(Then normalize `suspect_tokens_241` similarly or keep them in canonical form.)

---

## 5) Tiny but important: make sure `C()` is actually the bound one

If you still have old notebook cells that do `C = get_config`, they will override your import and silently break everything.

Right before Part A starts, add:

```python
print("C() comes from:", getattr(C, "__module__", "unknown"))
```

You want it to say something like `dq_engine.utils.config`.

---

## What I‚Äôd do right now (minimal surgery)

1. Replace 2.4.2 with the clean block above ‚úÖ
2. Add the 2.4.4 threshold definitions ‚úÖ
3. Replace 2.4.5 and 2.4.6 threshold blocks with the 2-liner `C()` versions ‚úÖ
4. Filter missing `cat_cols` in 2.4.6 like the others ‚úÖ

Once those are done, this whole ‚ÄúPart A‚Äù will run cleanly and the config lookup will be consistent and honest.


># ---

# 2.4.2 | Unexpected Categorical Values
print("\n2.4.2 üö´ Unexpected categorical values")

valid_domains_242 = C("CATEGORICAL.VALID_DOMAINS", {})

unexpected_rows_242 = []

if not valid_domains_242:
    print("   ‚ÑπÔ∏è 2.4.2: No configured VALID_DOMAINS; skipping unexpected-value checks.")
else:
    for col_242, dom_config_242 in valid_domains_242.items():
        if col_242 not in df.columns:
            continue

        s_242 = df[col_242].astype("string")
        role_242 = role_map_24.get(col_242, "feature")
        fgroup_242 = feature_group_map_24.get(col_242, "unknown")

        values_242 = s_242.value_counts(dropna=False)
        uniques_242 = values_242.index.tolist()

        allowed_values_242 = set()
        regex_list_242 = []
        domain_name_242 = col_242

        # Accept either:
        # - list of allowed values
        # - dict {"values":[...], "regex":[...], "name":"..."}
        if isinstance(dom_config_242, dict):
            vals_242 = dom_config_242.get("values", [])
            regs_242 = dom_config_242.get("regex", [])
            for v in vals_242:
                allowed_values_242.add(str(v))
            for rg in regs_242:
                try:
                    regex_list_242.append(re.compile(rg))
                except re.error:
                    pass
            if "name" in dom_config_242:
                domain_name_242 = dom_config_242["name"]
        else:
            try:
                for v in dom_config_242:
                    allowed_values_242.add(str(v))
            except TypeError:
                pass

        for val in uniques_242:
            if pd.isna(val):
                continue

            v_str_242 = str(val)
            in_set_242 = v_str_242 in allowed_values_242
            matches_regex_242 = any(r.search(v_str_242) for r in regex_list_242) if regex_list_242 else False

            if in_set_242 or matches_regex_242:
                continue

            count_242 = int(values_242.loc[val])
            pct_242 = float(count_242 / n_rows_24 * 100.0) if n_rows_24 else 0.0

            if col_242 in target_cols_24 or role_242 in {"id", "target"} or fgroup_242 == "model_feature":
                severity_242 = "critical"
            else:
                severity_242 = "warn"

            unexpected_rows_242.append(
                {
                    "column": col_242,
                    "offending_value": v_str_242,
                    "count": count_242,
                    "pct": round(pct_242, 5),
                    "expected_domain_name": domain_name_242,
                    "severity": severity_242,
                    "role": role_242,
                    "feature_group": fgroup_242,
                }
            )

unexpected_df_242 = pd.DataFrame(unexpected_rows_242)

unexpected_path_242 = sec24_reports_dir / "unexpected_values.csv"
tmp_242 = unexpected_path_242.with_suffix(".tmp.csv")
unexpected_df_242.to_csv(tmp_242, index=False)
os.replace(tmp_242, unexpected_path_242)

n_cols_with_domains_242 = len([c for c in valid_domains_242.keys() if c in df.columns]) if valid_domains_242 else 0
n_cols_with_unexp_242 = len(set(unexpected_df_242["column"])) if not unexpected_df_242.empty else 0
n_unexp_total_242 = int(unexpected_df_242.shape[0]) if not unexpected_df_242.empty else 0

if not unexpected_df_242.empty:
    _crit_cols_242 = (unexpected_df_242["severity"] == "critical").groupby(unexpected_df_242["column"]).any()
    n_critical_unexp_242 = int(_crit_cols_242.sum())
else:
    n_critical_unexp_242 = 0

if n_cols_with_unexp_242 == 0:
    status_242 = "OK"
elif n_critical_unexp_242 > 0:
    status_242 = "FAIL"
else:
    status_242 = "WARN"

summary_242 = pd.DataFrame([{
    "section": "2.4.2",
    "section_name": "Unexpected categorical values",
    "check": "Compare observed values against configured valid domains",
    "level": "info",
    "status": status_242,
    "n_columns_with_domains": int(n_cols_with_domains_242),
    "n_columns_with_unexpected_values": int(n_cols_with_unexp_242),
    "n_unexpected_values_total": int(n_unexp_total_242),
    "detail": "unexpected_values.csv",
    "timestamp": pd.Timestamp.utcnow(),
}])

print(f"üíæ 2.4.2 unexpected_values.csv ‚Üí {unexpected_path_242}")
print("\nüìä 2.4.2 unexpected_values (head):")
if not unexpected_df_242.empty:
    display(unexpected_df_242.head(20))
else:
    print("   (no unexpected values detected)")

append_sec2(summary_242, SECTION2_REPORT_PATH)
display(summary_242)

Why is it still telling me:
2.4.2 üö´ Unexpected categorical values
   ‚ÑπÔ∏è 2.4.2: No configured VALID_DOMAINS; skipping unexpected-value checks.
üíæ 2.4.2 unexpected_values.csv ‚Üí /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/runs/20260113_011438/reports/2_4/unexpected_values.csv

üìä 2.4.2 unexpected_values (head):
   (no unexpected values detected)
üßæ Appended diagnostics ‚Üí /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/runs/20260113_011438/reports/section2_unified.csv

Your YAML **does** have `CATEGORICAL.VALID_DOMAINS` configured ‚Äî it‚Äôs wired via an anchor:

* `EXPECTED_LEVELS: &EXPECTED_LEVELS` ‚Ä¶ then
* `CATEGORICAL: VALID_DOMAINS: *EXPECTED_LEVELS` 

So if your notebook still prints:

> ‚ÄúNo configured VALID_DOMAINS‚Ä¶‚Äù

that means **your `C()` is not looking at the same `CONFIG` object you think it is** (or it‚Äôs loading a different config file).

## The #1 cause (and it matches your symptoms)

You set `CONFIG = load_and_bind_config(...)` in the **notebook**, but your imported `C()` very likely looks up **module-level** `CONFIG` using `globals()` *inside* `dq_engine/utils/config.py`.

So you end up with:

* Notebook has a `CONFIG` variable ‚úÖ
* Module `dq_engine.utils.config` has its own `CONFIG` (still `{}` / `None`) ‚ùå
* `C("CATEGORICAL.VALID_DOMAINS", {})` returns `{}` ‚Üí your 2.4.2 prints ‚Äúskipping‚Äù

That‚Äôs exactly consistent with your earlier `ModuleNotFoundError: No module named 'src'` situation too: you‚Äôve been bouncing between ‚Äúlocal fallback C‚Äù and ‚Äúmodule C‚Äù, and they don‚Äôt share state.

---

## Fix 1: Stop importing via `src.` (your import path is wrong)

Given your tree is `Level_3/src/dq_engine/...`, you want **`dq_engine...`**, not `src.dq_engine...`.

In your notebook, do this **once near the top**:

```python
import sys
from pathlib import Path

LEVEL3 = Path("/Users/b/DATA/PROJECTS/Telco/_T2/Level_3")
sys.path.insert(0, str(LEVEL3 / "src"))

from dq_engine.utils.config import load_and_bind_config, C, config_source
```

Now the import should work.

---

## Fix 2: Refactor `config.py` so `C()` reads the bound config (not notebook globals)

Here‚Äôs the clean pattern: the module owns a private config store, and `load_and_bind_config()` sets it. `C()` reads it by default, but can also accept an explicit `config=` override.

Put this in: `Level_3/src/dq_engine/utils/config.py`

```python
from __future__ import annotations

from pathlib import Path
import yaml

_CONFIG: dict = {}
_CONFIG_SOURCE: str | None = None

def load_and_bind_config(path: str | Path) -> dict:
    """Load YAML config and bind it to this module (so C() can see it)."""
    global _CONFIG, _CONFIG_SOURCE
    p = Path(path).expanduser().resolve()
    with p.open("r", encoding="utf-8") as f:
        _CONFIG = yaml.safe_load(f) or {}
    _CONFIG_SOURCE = str(p)
    return _CONFIG

def config_source() -> str | None:
    return _CONFIG_SOURCE

def C(key: str, default=None, *, required: bool = False, config: dict | None = None):
    """
    Safe access into config using dotted keys, e.g. C("CATEGORICAL.VALID_DOMAINS").
    Reads the module-bound config unless an explicit `config=` is provided.
    """
    cfg = _CONFIG if config is None else config
    if not isinstance(cfg, dict):
        if required:
            raise TypeError("Config is not a dict")
        return default

    cur = cfg
    for part in key.split("."):
        if isinstance(cur, dict) and part in cur:
            cur = cur[part]
        else:
            if required:
                raise KeyError(f"Missing config key: {key}")
            return default
    return cur
```

### Then in the notebook:

```python
PROJECT_CONFIG_PATH = "/Users/b/DATA/PROJECTS/Telco/_T2/Level_3/config/project_config.yaml"

CONFIG = load_and_bind_config(PROJECT_CONFIG_PATH)

print("CONFIG bound from:", config_source())
print("Has CATEGORICAL?", "CATEGORICAL" in CONFIG)
print("VALID_DOMAINS keys sample:", list(C("CATEGORICAL.VALID_DOMAINS", {}).keys())[:5])
```

If that prints keys like `gender`, `SeniorCitizen`, etc., you‚Äôre done ‚Äî and **2.4.2 will stop skipping**.

---

## Why 2.4.2 is skipping right now (concrete)

Because `valid_domains_242 = C("CATEGORICAL.VALID_DOMAINS", {})` is evaluating to `{}`.

But your YAML clearly defines it , so either:

1. `C()` isn‚Äôt reading the bound config (module-vs-notebook globals mismatch), **or**
2. you‚Äôre loading a different config file than the one you edited (Section 2 bootstrap might be pulling an older path from `setup_summary.json`), **or**
3. your import path points at a different `config.py` than you think.

The refactor above fixes (1) and makes (2)/(3) obvious via `config_source()`.

---

## Tiny ‚Äúsmoke test‚Äù you can drop right before 2.4.2

```python
vd = C("CATEGORICAL.VALID_DOMAINS", None)
print("DEBUG valid_domains_242 type:", type(vd))
print("DEBUG valid_domains_242 is None?", vd is None)
print("DEBUG valid_domains_242 len:", (len(vd) if isinstance(vd, dict) else "n/a"))
```

Expected: `type == dict` and `len > 0`.

---

One extra nerdy note: your YAML anchor setup is good ‚Äî `VALID_DOMAINS: *EXPECTED_LEVELS` should load as a normal dict with `yaml.safe_load`. The config file is not the problem; it‚Äôs **which Python namespace is holding the config**.

># ---

DEBUG valid_domains_242 type: <class 'NoneType'>
DEBUG valid_domains_242 is None? True
DEBUG valid_domains_242 len: n/a

> ---
> DEBUG valid_domains_242 type: <class 'NoneType'>
> DEBUG valid_domains_242 is None? True
> DEBUG valid_domains_242 len: n/a

DEBUG valid_domains_242 type: <class 'NoneType'>
DEBUG valid_domains_242 is None? True
DEBUG valid_domains_242 len: n/a

That debug output is the smoking gun: **your `C()` is not seeing any loaded config at all** (or it‚Äôs looking in the wrong place). In other words, `C("CATEGORICAL.VALID_DOMAINS", None)` is returning `None` because **the config store that `C()` reads from is empty / unbound**.

This usually happens for one of these reasons:

1. You loaded YAML into a **notebook variable** named `CONFIG`, but `C()` is reading **a different variable** (often `globals().get("CONFIG")` inside *the module*, not the notebook).
2. You think you‚Äôre importing one `config.py`, but Python is actually importing a **different file** (path confusion).
3. Your `config.py` has **multiple `C` definitions** (you pasted duplicates), and the one you‚Äôre calling doesn‚Äôt use the bound config.

Here‚Äôs how to nail it down and fix it *without guessing*.

---

## 1) Prove which `config.py` you‚Äôre actually using (must do)

Run this at the top of the notebook (one cell):

```python
import sys
from pathlib import Path

LEVEL3 = Path("/Users/b/DATA/PROJECTS/Telco/_T2/Level_3")
sys.path.insert(0, str(LEVEL3 / "src"))

import dq_engine.utils.config as cfg

print("cfg module file:", cfg.__file__)
print("sys.path[0]:", sys.path[0])
```

You want `cfg.__file__` to be exactly something like:
`.../Level_3/src/dq_engine/utils/config.py`

If it isn‚Äôt, you‚Äôve been importing the wrong module.

---

## 2) Load config in the SAME module that `C()` lives in

Do **not** do `from dq_engine.utils.config import C` for this test. Use the module object so there‚Äôs zero ambiguity:

```python
PROJECT_CONFIG_PATH = "/Users/b/DATA/PROJECTS/Telco/_T2/Level_3/config/project_config.yaml"

CONFIG = cfg.load_and_bind_config(PROJECT_CONFIG_PATH)

print("config_source:", cfg.config_source())
print("top keys:", sorted(CONFIG.keys())[:15])
print("CATEGORICAL exists:", "CATEGORICAL" in CONFIG)

vd = cfg.C("CATEGORICAL.VALID_DOMAINS", None)
print("VALID_DOMAINS type:", type(vd))
print("VALID_DOMAINS len:", (len(vd) if isinstance(vd, dict) else None))
```

Expected: `VALID_DOMAINS type: <class 'dict'>` and `len > 0`.

If you still see `NoneType`, your `load_and_bind_config()` is not binding the same storage that `C()` reads.

---

## 3) Minimal refactor for `config.py` (the correct pattern)

Open **the exact file printed by `cfg.__file__`** and make it look like this (this is the important part: `load_and_bind_config()` must set a module-level store that `C()` reads):

```python
# Level_3/src/dq_engine/utils/config.py
from __future__ import annotations
from pathlib import Path
import yaml

_CONFIG: dict = {}
_CONFIG_SOURCE: str | None = None

def load_and_bind_config(path: str | Path) -> dict:
    global _CONFIG, _CONFIG_SOURCE
    p = Path(path).expanduser().resolve()
    with p.open("r", encoding="utf-8") as f:
        _CONFIG = yaml.safe_load(f) or {}
    _CONFIG_SOURCE = str(p)
    return _CONFIG

def config_source() -> str | None:
    return _CONFIG_SOURCE

def C(key: str, default=None, *, required: bool = False, config: dict | None = None):
    cfg = _CONFIG if config is None else config
    if not isinstance(cfg, dict):
        if required:
            raise TypeError("Config is not a dict")
        return default

    cur = cfg
    for part in key.split("."):
        if isinstance(cur, dict) and part in cur:
            cur = cur[part]
        else:
            if required:
                raise KeyError(f"Missing config key: {key}")
            return default
    return cur
```

### üö® Also do this cleanup:

In your pasted `config.py` you had **multiple `get_config` / `C` definitions and aliases**. Delete the old ones. Keep **one** `C()`.

If you leave the old `C = get_config` alias above, you can accidentally end up calling the wrong one.

---

## 4) After refactor, restart kernel and rerun the import

Then:

```python
import dq_engine.utils.config as cfg
cfg.load_and_bind_config(PROJECT_CONFIG_PATH)
print(cfg.C("CATEGORICAL.VALID_DOMAINS", None).__class__)
```

Should print `<class 'dict'>`.

---

## Why your YAML is not the problem

Your YAML definitely includes:

* `CATEGORICAL:`

  * `VALID_DOMAINS: *EXPECTED_LEVELS`

So if `C(...)` returns `None`, that‚Äôs almost always a **binding/import issue**, not a missing key.

---

## One more ‚Äúgotcha‚Äù that bites hard

If anywhere in the notebook you did something like:

```python
def C(...): ...
```

or

```python
C = get_config
```

you might be calling the notebook‚Äôs `C`, not the module‚Äôs. That‚Äôs why I‚Äôm pushing `cfg.C(...)` explicitly.

---

If you run step (1) and paste the single line output of `cfg.__file__`, I can tell you immediately whether you‚Äôre importing the right `config.py` or a shadow copy somewhere else.

Perfect: you‚Äôre importing the *right* file from the *right* place. So the only remaining explanation for `CATEGORICAL.VALID_DOMAINS -> None` is:

**`load_and_bind_config()` is not actually binding the same config store that `C()` reads from** (or `C()` is still the ‚Äúold‚Äù version that looks at `globals().get("CONFIG")`, and that module-global `CONFIG` is never set).

Let‚Äôs fix it cleanly.

---

## What‚Äôs happening (in plain terms)

Right now, your `C()` is almost certainly doing something like:

```python
cfg = config or globals().get("CONFIG", {})
```

But `globals()` there means **globals inside `dq_engine.utils.config`**, not your notebook. Unless that module has a module-level `CONFIG = {...}`, `C()` will see `{}` and return `None`/default.

So: **your notebook‚Äôs `CONFIG = ...` does not help** unless you also set `dq_engine.utils.config.CONFIG`.

---

## The fastest fix (no refactor required)

After you call `load_and_bind_config`, do this:

```python
import dq_engine.utils.config as cfg

PROJECT_CONFIG_PATH = "/Users/b/DATA/PROJECTS/Telco/_T2/Level_3/config/project_config.yaml"

CONFIG = cfg.load_and_bind_config(PROJECT_CONFIG_PATH)

# üîß critical: bind into module global if C() uses globals().get("CONFIG")
cfg.CONFIG = CONFIG

vd = cfg.C("CATEGORICAL.VALID_DOMAINS", None)
print("VALID_DOMAINS type:", type(vd), "len:", (len(vd) if isinstance(vd, dict) else None))
```

If `vd` becomes a dict with keys, you‚Äôve confirmed the diagnosis.

üí°üí° Hiring-value note: this is why ‚Äúglobal CONFIG in notebooks‚Äù is brittle ‚Äî modules don‚Äôt automatically inherit notebook state.

---

## The correct fix (refactor `config.py` once; never think about this again)

Edit **this exact file** (you already confirmed it):

`/Users/b/DATA/PROJECTS/Telco/_T2/Level_3/src/dq_engine/utils/config.py`

Make it have **one** authoritative store `_CONFIG` and have `C()` read it.

Paste this in and delete the duplicate old `C/get_config` stuff:

```python
from __future__ import annotations

from pathlib import Path
import yaml

# module-private config store (single source of truth)
_CONFIG: dict = {}
_CONFIG_SOURCE: str | None = None

def load_and_bind_config(path: str | Path) -> dict:
    """Load YAML config and bind it to this module so C() can read it."""
    global _CONFIG, _CONFIG_SOURCE
    p = Path(path).expanduser().resolve()
    with p.open("r", encoding="utf-8") as f:
        _CONFIG = yaml.safe_load(f) or {}
    _CONFIG_SOURCE = str(p)
    return _CONFIG

def config_source() -> str | None:
    return _CONFIG_SOURCE

def C(key: str, default=None, *, required: bool = False, config: dict | None = None):
    """
    Safe config accessor using dotted keys, e.g. C("CATEGORICAL.VALID_DOMAINS").
    By default reads the module-bound config loaded via load_and_bind_config().
    """
    cfg = _CONFIG if config is None else config
    if not isinstance(cfg, dict):
        if required:
            raise TypeError("Config is not a dict")
        return default

    cur = cfg
    for part in key.split("."):
        if isinstance(cur, dict) and part in cur:
            cur = cur[part]
        else:
            if required:
                raise KeyError(f"Missing config key: {key}")
            return default
    return cur
```

### Then restart kernel and do:

```python
import dq_engine.utils.config as cfg

PROJECT_CONFIG_PATH = "/Users/b/DATA/PROJECTS/Telco/_T2/Level_3/config/project_config.yaml"
cfg.load_and_bind_config(PROJECT_CONFIG_PATH)

vd = cfg.C("CATEGORICAL.VALID_DOMAINS", None)
print(type(vd), len(vd))
print("sample keys:", list(vd.keys())[:5])
```

Expected keys: `gender`, `SeniorCitizen`, `Partner`, etc. (from your YAML‚Äôs `EXPECTED_LEVELS`).

---

## Why your current 2.4.2 still prints ‚ÄúNo configured VALID_DOMAINS‚Äù

Because **inside that run**, `C("CATEGORICAL.VALID_DOMAINS", {})` is returning `{}` (or `None`), which matches your debug.

Once `C()` reads the bound config, that message will disappear and 2.4.2 will actually iterate.

---

## Quick extra sanity check: confirm the YAML actually loads the expected keys

Run this (independent of `C()`):

```python
import yaml
from pathlib import Path

p = Path("/Users/b/DATA/PROJECTS/Telco/_T2/Level_3/config/project_config.yaml")
cfg_raw = yaml.safe_load(p.read_text())

print("Has CATEGORICAL:", "CATEGORICAL" in cfg_raw)
print("Has VALID_DOMAINS:", "VALID_DOMAINS" in cfg_raw.get("CATEGORICAL", {}))
print("VALID_DOMAINS keys:", list(cfg_raw["CATEGORICAL"]["VALID_DOMAINS"].keys())[:5])
```

If that prints keys, the YAML is 100% fine ‚Äî it‚Äôs purely the binding layer.

---

Now the fun part: once `C()` works, you can delete *all* those repetitive ‚Äúfallback to CONFIG dict‚Äù ladders in 2.4.x and just do clean one-liners like:

```python
valid_domains_242 = C("CATEGORICAL.VALID_DOMAINS", {})
rare_threshold_pct_246 = C("DATA_QUALITY.RARE_PCT_THRESHOLD", 1.0)
high_card_limit_245 = C("DATA_QUALITY.HIGH_CARD_THRESHOLD", 50)
```

‚Ä¶and your notebook becomes less of a haunted mansion.

># XXXXX

># VALID_DOMAINS type: <class 'dict'> len: 17

Boom. That‚Äôs the whole mystery: **your `C()` is now reading the real config**. üéØ
So the earlier ‚ÄúNo configured VALID_DOMAINS‚Äù message wasn‚Äôt about YAML at all ‚Äî it was because `C()` was effectively unbound (reading `{}` / `None` from the module).

Now you should do two quick things:

---

## 1) Lock in the binding so you never hit this again

### Best (recommended): keep config bound inside the module

In `dq_engine/utils/config.py`, make sure you‚Äôre using the `_CONFIG` pattern (module-private store) and **only one** `C()` definition.

Then in your notebook, do:

```python
import dq_engine.utils.config as cfg

PROJECT_CONFIG_PATH = "/Users/b/DATA/PROJECTS/Telco/_T2/Level_3/config/project_config.yaml"
cfg.load_and_bind_config(PROJECT_CONFIG_PATH)

# Use cfg.C everywhere (avoid shadowing notebook C)
C = cfg.C
```

That last line gives you convenience without the ‚Äúwhich C am I calling?‚Äù chaos.

üí°üí° Rule: **don‚Äôt set `CONFIG = ...` in the notebook and assume modules see it.** Modules are their own universe.

---

## 2) Your 2.4.2 code will now work, but fix one subtle landmine

Your `VALID_DOMAINS` in YAML is currently a mapping of:

```yaml
gender: ["Female", "Male"]
...
```

So in 2.4.2, `dom_config_242` is a **list**, not a dict with `{"values":..., "regex":...}`. Your code already supports both. Great.

What you *must* ensure in the 2.4.2 cell is that:

* `unexpected_rows_242 = []` is defined **before** the loop (you did ‚úÖ)
* `n_rows_24` is defined (you did earlier ‚úÖ)
* you **don‚Äôt** have leftover duplicated blocks (your earlier pasted version had an ‚Äúelse: for ‚Ä¶‚Äù then later another loop ‚Äî that can cause confusing behavior)

Use the clean 2.4.2 cell you posted last (the one that starts with `valid_domains_242 = C(...)` and defines `unexpected_rows_242 = []` once). That‚Äôs the right one.

---

## 3) Quick sanity tests to confirm it‚Äôs truly running

Run these immediately before 2.4.2:

```python
print("VALID_DOMAINS keys:", list(C("CATEGORICAL.VALID_DOMAINS", {}).keys()))
print("Example domain:", C("CATEGORICAL.VALID_DOMAINS.gender", None))
```

Then inside 2.4.2, right after you load domains:

```python
print("2.4.2 domains loaded:", len(valid_domains_242))
```

If you see `17`, you‚Äôre good. The ‚Äúskipping‚Äù print should vanish.

---

## Why you may still see ‚Äúno unexpected values detected‚Äù (and that‚Äôs fine)

Now that VALID_DOMAINS is loaded, there are two possibilities:

1. ‚úÖ **Everything matches** (Telco dataset is pretty clean on these domains), so you get an empty report ‚Äî that‚Äôs a legit success case.
2. You have ‚Äúnear-miss‚Äù hygiene issues (case/whitespace) ‚Äî those will show up in **2.4.3**, not 2.4.2, because 2.4.2 is exact-domain membership.

---

## One more nerdy-but-useful improvement üí°üí°

In 2.4.2, you convert values with `astype("string")`. Good. But your domain values are plain strings. Sometimes pandas `StringDtype` values compare oddly if there are hidden spaces.

Add a normalization step *only for this check*:

```python
v_str_242 = str(val).strip()
```

And when building allowed set:

```python
allowed_values_242.add(str(v).strip())
```

That makes 2.4.2 robust even if your raw data has trailing spaces.

---

At this point you‚Äôve got the config plumbing working (the hard part). Next, the real fun is deleting all the fallback ladders in 2.4.x and making everything a clean `C("...", default)` call ‚Äî that‚Äôs a big readability + ‚Äúportfolio polish‚Äù upgrade.

# /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/src/dq_engine/utils/config.py

from __future__ import annotations
from pathlib import Path
from typing import Any, Dict, Iterable, Optional

import yaml

# Bound config lives here (not notebook globals)
_BOUND_CONFIG: Dict[str, Any] = {}
_BOUND_CONFIG_PATH: Optional[str] = None


def load_config_yaml(path: str | Path) -> Dict[str, Any]:
    """Load YAML into a dict."""
    p = Path(path).expanduser().resolve()
    with p.open("r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
    if not isinstance(data, dict):
        raise ValueError(f"Config YAML root must be a mapping/dict: {p}")
    return data


def bind_config(cfg: Dict[str, Any], *, path: str | Path | None = None) -> None:
    """Bind a config dict so C() always reads from the same source."""
    global _BOUND_CONFIG, _BOUND_CONFIG_PATH
    _BOUND_CONFIG = cfg if isinstance(cfg, dict) else {}
    _BOUND_CONFIG_PATH = str(Path(path).expanduser().resolve()) if path else None


def load_and_bind_config(path: str | Path) -> Dict[str, Any]:
    """Convenience: load YAML and bind it in one step."""
    cfg = load_config_yaml(path)
    bind_config(cfg, path=path)
    return cfg


def C(
    key: str,
    default: Any = None,
    *,
    required: bool = False,
    config: Optional[Dict[str, Any]] = None,
    roots: Optional[Iterable[str]] = None,
) -> Any:
    """
    Safe access into config using dotted keys, e.g. C("RANGES.tenure.max").
    Reads from:
      - explicit `config` argument if provided
      - else bound config (_BOUND_CONFIG)

    Optional `roots` lets you try prefixes, e.g. roots=["DATA_QUALITY.", "NUMERIC_CHECKS."].
    """
    cfg = config if isinstance(config, dict) else _BOUND_CONFIG
    if not isinstance(cfg, dict) or not cfg:
        if required:
            raise KeyError(f"CONFIG not bound/empty. Missing key: {key}")
        return default

    if not isinstance(key, str) or not key.strip():
        if required:
            raise KeyError("Empty config key")
        return default

    prefixes = [""] + list(roots or [])
    for prefix in prefixes:
        cur: Any = cfg
        parts = (prefix + key).strip(".").split(".")
        ok = True
        for p in parts:
            if isinstance(cur, dict) and p in cur:
                cur = cur[p]
            else:
                ok = False
                break
        if ok:
            return cur

    if required:
        src = _BOUND_CONFIG_PATH or "(unbound)"
        raise KeyError(f"Missing CONFIG key: {key} (config source: {src})")
    return default


def config_source() -> str:
    """Debug helper: where did the bound config come from?"""
    return _BOUND_CONFIG_PATH or "(unbound)"


def get_config(key_path, default=None):
    """
    Safely gets nested keys from CONFIG (e.g., 'CATEGORICAL.VALID_DOMAINS')
    Works even if the keys are inside 'DATA_QUALITY' or other roots.
    """
    res = globals().get("CONFIG", {})

    # Optional: Automatically try common root prefixes if not found at top level
    possible_roots = ["", "DATA_QUALITY.", "NUMERIC_CHECKS."]

    for root in possible_roots:
        temp_res = res
        keys = (root + key_path).strip(".").split(".")
        try:
            for k in keys:
                temp_res = temp_res[k]
            return temp_res
        except (KeyError, TypeError):
            continue
    return default

# Alias it to 'C' so your existing code works
C = get_config

This is what I had in my config.py -- Should I still use the config.py you gave me

># 
Keep **most** of what you have ‚Äî it‚Äôs solid ‚Äî but you must do one surgical thing:

### ‚úÖ Delete (or comment out) everything from `def get_config...` down, including `C = get_config`.

Right now your file contains **two different `C()` functions**, and then you *overwrite* the good one with the old one:

* You define the **good** `C()` that reads `_BOUND_CONFIG`
* Then you define `get_config()` that reads `globals().get("CONFIG")`
* Then you do `C = get_config` which **clobbers** the good `C()`

So even though you ‚Äúbound‚Äù config correctly, you were later calling the wrong `C()` unless you happened to import it before the overwrite (kernel import order can make this feel random).

That‚Äôs why things felt haunted.

---

## What to change in your `config.py`

### Keep this whole section (it‚Äôs good):

* `_BOUND_CONFIG`, `_BOUND_CONFIG_PATH`
* `load_config_yaml`
* `bind_config`
* `load_and_bind_config`
* the **good** `C(...)` that reads `_BOUND_CONFIG`
* `config_source`

### Remove this entire block:

```python
def get_config(key_path, default=None):
    ...
    return default

C = get_config
```

That‚Äôs it.

---

## Resulting file structure (minimal, clean)

Your file should end at:

```python
def config_source() -> str:
    return _BOUND_CONFIG_PATH or "(unbound)"
```

No second `C`. No alias. No globals().

---

## Then in notebooks/scripts, use it like this

```python
import dq_engine.utils.config as cfg

cfg.load_and_bind_config(PROJECT_CONFIG_PATH)

# optional convenience alias
C = cfg.C

print(cfg.config_source())
print(type(C("CATEGORICAL.VALID_DOMAINS", {})), len(C("CATEGORICAL.VALID_DOMAINS", {})))
```

---

## üí°üí° Extra ‚Äúmake it impossible to misuse‚Äù guard (recommended)

Rename the internal config accessor to something like `_C_old` if you *really* want to keep it for reference, but don‚Äôt export it as `C`.

If you leave `C = get_config` in place, you will eventually step on the rake again.

---

### Answer to your question

You **do not** need to switch to a totally different file than what you have.
You just need to **remove the overwriting old alias** and keep the ‚Äúbound config‚Äù approach.

Now your `C("CATEGORICAL.VALID_DOMAINS")` will always come from `load_and_bind_config()`, not notebook globals, and your 2.4.x checks will behave consistently across runs.
