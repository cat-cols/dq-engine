># 2.3.7.4 | Rule Confidence Scores


```python
# 2.3.7.4 | Rule Confidence Scores
print("\n2.3.7.4 ‚è±Ô∏è Rule confidence scores")

rule_rows_2374 = []

range_path_2374  = NUMERIC_DIR / "range_violation_report.csv"
outlier_path_2374 = NUMERIC_DIR / "outlier_report_iqr_z.csv"
ts_outliers_path_2374 = globals().get("time_series_outliers_path", NUMERIC_DIR / "time_series_outliers.csv")
corr_anom_path_2374   = NUMERIC_DIR / "correlation_anomalies.csv"

try:
    hard_types_cfg_2374 = C("NUMERIC.RULES.HARD_TYPES", ["range"]) or ["range"]
except Exception:
    hard_types_cfg_2374 = ["range"]

# --- Range rules -------------------------------------------------------
if range_path_2374.exists():
    range_df_2374 = pd.read_csv(range_path_2374)
else:
    range_df_2374 = pd.DataFrame()

for _, r in range_df_2374.iterrows():
    has_range_rule = bool(r.get("has_range_rule", False))
    if not has_range_rule:
        continue

    col = r.get("column")

    n_below_raw = r.get("n_below_min", 0)
    n_above_raw = r.get("n_above_max", 0)
    n_in_raw    = r.get("n_in_range", 0)

    n_below = float(0 if pd.isna(n_below_raw) else n_below_raw)
    n_above = float(0 if pd.isna(n_above_raw) else n_above_raw)
    n_in    = float(0 if pd.isna(n_in_raw)    else n_in_raw)

    total = n_below + n_above + n_in
    if pd.isna(total) or total <= 0:
        total = 1.0

    viol_rate = (n_below + n_above) / total

    if total >= 1000:
        size_factor = 1.0
    elif total >= 100:
        size_factor = 0.8
    else:
        size_factor = 0.6

    viol_factor = max(0.2, 1.0 - viol_rate * 4.0)
    confidence = float(min(1.0, size_factor * viol_factor))

    total_display = int(round(total))

    rule_rows_2374.append(
        {
            "feature":          col,
            "rule_type":        "range",
            "rule_id":          "range_minmax",
            "confidence_score": round(confidence, 3),
            "hard_vs_soft":     "hard" if "range" in hard_types_cfg_2374 else "soft",
            "notes":            f"viol_rate={round(viol_rate,4)}, total={total_display}",
        }
    )

# --- Outlier rules (IQR/Z) ---------------------------------------------
if outlier_path_2374.exists():
    out_df_2374 = pd.read_csv(outlier_path_2374)
else:
    out_df_2374 = pd.DataFrame()

for _, r in out_df_2374.iterrows():
    col = r.get("column")
    pct_iqr = float(r.get("pct_outliers_iqr", 0) or 0)
    pct_z   = float(r.get("pct_outliers_z", 0) or 0)

    max_pct = max(pct_iqr, pct_z)
    if max_pct < 1.0:
        sev_factor = 1.0
    elif max_pct < 5.0:
        sev_factor = 0.8
    else:
        sev_factor = 0.6

    confidence = float(sev_factor)

    rule_rows_2374.append(
        {
            "feature":          col,
            "rule_type":        "outlier_iqr_z",
            "rule_id":          "outlier_iqr_z",
            "confidence_score": round(confidence, 3),
            "hard_vs_soft":     "soft",
            "notes":            f"max_pct_outliers={round(max_pct,3)}",
        }
    )

# --- Temporal time-series rules ----------------------------------------
ts_df_2374 = pd.DataFrame()
if isinstance(ts_outliers_path_2374, Path) and ts_outliers_path_2374.exists() and ts_outliers_path_2374.stat().st_size > 0:
    try:
        ts_df_2374 = pd.read_csv(ts_outliers_path_2374)
    except pd.errors.EmptyDataError:
        ts_df_2374 = pd.DataFrame()

if not ts_df_2374.empty:
    if ts_df_2374["is_outlier"].dtype != bool:
        ts_df_2374["is_outlier"] = ts_df_2374["is_outlier"].astype(bool)

    total_buckets = ts_df_2374["time_bucket"].nunique()
    if total_buckets <= 0:
        total_buckets = 1

    for feat, g in ts_df_2374.groupby("feature"):
        n_out_feat = int(g[g["is_outlier"]].shape[0])
        rate_feat  = n_out_feat / total_buckets

        if rate_feat == 0:
            conf = 0.9
        elif rate_feat < 0.2:
            conf = 0.8
        else:
            conf = 0.6

        rule_rows_2374.append(
            {
                "feature":          feat,
                "rule_type":        "temporal_ts_outlier",
                "rule_id":          "ts_zscore",
                "confidence_score": round(float(conf), 3),
                "hard_vs_soft":     "soft",
                "notes":            f"outlier_bucket_rate={round(rate_feat,4)}",
            }
        )

# --- Correlation anomaly rules -----------------------------------------
corr_df_2374 = pd.DataFrame()
if corr_anom_path_2374.exists() and corr_anom_path_2374.stat().st_size > 0:
    try:
        corr_df_2374 = pd.read_csv(corr_anom_path_2374)
    except pd.errors.EmptyDataError:
        corr_df_2374 = pd.DataFrame()

for _, r in corr_df_2374.iterrows():
    feat_i = r.get("feature_i")
    feat_j = r.get("feature_j")
    abs_delta = float(r.get("abs_delta", 0) or 0)

    if abs_delta < corr_delta_threshold_237:
        conf = 0.7
    elif abs_delta < 2 * corr_delta_threshold_237:
        conf = 0.8
    else:
        conf = 0.9

    rule_rows_2374.append(
        {
            "feature":          f"{feat_i}__{feat_j}",
            "rule_type":        "correlation",
            "rule_id":          r.get("time_window", ""),
            "confidence_score": round(float(conf), 3),
            "hard_vs_soft":     "soft",
            "notes":            f"abs_delta={round(abs_delta,4)}",
        }
    )

rule_conf_df_2374 = pd.DataFrame(rule_rows_2374)

rule_conf_path_2374 = NUMERIC_DIR / "rule_confidence_scores.csv"
tmp_2374 = rule_conf_path_2374.with_suffix(".tmp.csv")
rule_conf_df_2374.to_csv(tmp_2374, index=False)
os.replace(tmp_2374, rule_conf_path_2374)

print(f"üíæ Wrote rule confidence scores ‚Üí {rule_conf_path_2374}")
if not rule_conf_df_2374.empty:
    print("\nüìä 2.3.7.4 rule confidence scores (head):")
    display(rule_conf_df_2374.head(30))

n_rules_2374 = int(rule_conf_df_2374.shape[0])
n_hard_rules_2374 = int((rule_conf_df_2374["hard_vs_soft"] == "hard").sum()) if n_rules_2374 else 0
n_soft_rules_2374 = int((rule_conf_df_2374["hard_vs_soft"] == "soft").sum()) if n_rules_2374 else 0

status_2374 = "SKIP" if n_rules_2374 == 0 else "OK"

summary_2374 = pd.DataFrame([{
    "section":       "2.3.7.4",
    "section_name":  "Rule confidence scores",
    "check":         "Assign confidence & hardness to numeric rules",
    "level":         "info",
    "status":        status_2374,
    "n_rules":       n_rules_2374,
    "n_hard_rules":  n_hard_rules_2374,
    "n_soft_rules":  n_soft_rules_2374,
    "detail":        f"rule_confidence_scores.csv under {NUMERIC_DIR.name}",
    "timestamp":     pd.Timestamp.utcnow(),
}])

append_sec2(summary_2374, SECTION2_REPORT_PATH)
display(summary_2374)

# PART C | 2.3.8‚Äì2.3.14 üßÆ Model Readiness & Operational Hooks
print("\n2.3.8‚Äì2.3.14 üßÆ Model readiness & operational hooks")

# Assumes:
#   - df, NUMERIC_DIR, REPORTS_DIR, SECTION2_REPORT_PATH exist
#   - prior numeric artifacts already written by 2.3.x & 2.3.7.x
#   - CONFIG may exist as a dict (optional)

# ---------------------------------------------------------------------------
# Utility: safe loader for CSV ‚Üí DataFrame with a 'feature' column
# (still inline, no def)
# ---------------------------------------------------------------------------
# (We just repeat a tiny pattern; no functions)
# 2.3.8 üìö DQ rule catalog (joined with numeric profile)
print("\n2.3.8 üìö DQ rule catalog (joined with numeric profile)")

# --- 1) Load rule confidence artifact (safe) -------------------------------
rule_conf_path = NUMERIC_DIR / "rule_confidence_scores.csv"

try:
    if rule_conf_path.exists() and rule_conf_path.stat().st_size > 0:
        rule_conf_df = pd.read_csv(rule_conf_path)
    else:
        rule_conf_df = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {rule_conf_path} is empty or has no columns. Treating as no rules.")
    rule_conf_df = pd.DataFrame()

# --- 2) Load numeric profile (safe) ---------------------------------------
numeric_profile_path = NUMERIC_DIR / "numeric_profile_df.csv"

try:
    if numeric_profile_path.exists() and numeric_profile_path.stat().st_size > 0:
        numeric_profile_df_238 = pd.read_csv(numeric_profile_path)
    else:
        numeric_profile_df_238 = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {numeric_profile_path} is empty or has no columns. Skipping join.")
    numeric_profile_df_238 = pd.DataFrame()

# --- 3) Build DQ rule catalog ---------------------------------------------
if not rule_conf_df.empty and not numeric_profile_df_238.empty:
    if "column" in numeric_profile_df_238.columns:
        dq_rule_catalog_df = (
            numeric_profile_df_238
            .rename(columns={"column": "feature"})
            .merge(rule_conf_df, on="feature", how="left")
            .sort_values(["feature", "rule_type", "rule_id"])
            .reset_index(drop=True)
        )
    else:
        print("‚ö†Ô∏è numeric_profile_df_238 missing 'column' col; using rule_conf_df only.")
        dq_rule_catalog_df = rule_conf_df.copy()
else:
    dq_rule_catalog_df = rule_conf_df.copy()

dq_rule_catalog_path = NUMERIC_DIR / "dq_rule_catalog.csv"
tmp_238 = dq_rule_catalog_path.with_suffix(".tmp.csv")
dq_rule_catalog_df.to_csv(tmp_238, index=False)
os.replace(tmp_238, dq_rule_catalog_path)

print(f"üíæ Wrote DQ rule catalog ‚Üí {dq_rule_catalog_path}")

if not dq_rule_catalog_df.empty:
    print("\nüìä Data Quality Rule Catalog (head):")
    cols_preview = [
        "feature",
        "role" if "role" in dq_rule_catalog_df.columns else "feature",
        "rule_type",
        "rule_id",
        "confidence_score",
        "hard_vs_soft",
    ]
    cols_preview = [c for c in cols_preview if c in dq_rule_catalog_df.columns]
    display(dq_rule_catalog_df[cols_preview].head(30))
else:
    print("   (no rules to catalog)")

# --- 4) ‚ÄúDQ rules‚Äù tab in your report (aggregated view) -------------------
dq_rules_path = NUMERIC_DIR / "dq_rule_catalog.csv"

try:
    if dq_rules_path.exists() and dq_rules_path.stat().st_size > 0:
        dq_rules_df = pd.read_csv(dq_rules_path)
    else:
        dq_rules_df = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {dq_rules_path} is empty or has no columns. Skipping aggregation.")
    dq_rules_df = pd.DataFrame()

if (
    not dq_rules_df.empty
    and {"feature", "rule_id", "confidence_score", "hard_vs_soft"}.issubset(dq_rules_df.columns)
):
    agg_rules_df = (
        dq_rules_df
        .groupby("feature", as_index=False)
        .agg(
            n_rules=("rule_id", "nunique"),
            max_hard_conf=(
                "confidence_score",
                lambda s: s[dq_rules_df.loc[s.index, "hard_vs_soft"] == "hard"].max()
            ),
            max_soft_conf=(
                "confidence_score",
                lambda s: s[dq_rules_df.loc[s.index, "hard_vs_soft"] == "soft"].max()
            ),
    )
        )
    print("\nüìä Aggregated DQ rules per feature (head):")
    display(agg_rules_df.head(20))
else:
    print("‚ö†Ô∏è Not enough columns / data to build aggregated DQ rules view.")

# TODO: add display and append?
print("‚úÖ base catalog complete")
# 2.3.9 üßÆ Model readiness impact summary
print("\n2.3.9 üßÆ Model readiness impact summary")

numeric_profile_path_239 = NUMERIC_DIR / "numeric_profile_df.csv"
range_path_239          = NUMERIC_DIR / "range_violation_report.csv"
outlier_path_239        = NUMERIC_DIR / "outlier_report_iqr_z.csv"
rule_conf_path_239      = NUMERIC_DIR / "rule_confidence_scores.csv"
integrity_path_239      = NUMERIC_DIR / "numeric_integrity_report.csv"  # may or may not exist
model_readiness_path_239 = NUMERIC_DIR / "model_readiness_report.csv"

# 1) Load artifacts with guards (EmptyDataError-safe)

# numeric_profile_df_239
try:
    if numeric_profile_path_239.exists() and numeric_profile_path_239.stat().st_size > 0:
        numeric_profile_df_239 = pd.read_csv(numeric_profile_path_239)
    else:
        print(f"‚ö†Ô∏è {numeric_profile_path_239} missing/empty ‚Äî using empty numeric_profile_df for 2.3.9.")
        numeric_profile_df_239 = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {numeric_profile_path_239} is empty or has no columns. Using empty numeric_profile_df for 2.3.9.")
    numeric_profile_df_239 = pd.DataFrame()

# range_df_239
try:
    if range_path_239.exists() and range_path_239.stat().st_size > 0:
        range_df_239 = pd.read_csv(range_path_239)
    else:
        print(f"‚ö†Ô∏è {range_path_239} missing/empty ‚Äî no range info for 2.3.9.")
        range_df_239 = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {range_path_239} is empty or has no columns. No range info for 2.3.9.")
    range_df_239 = pd.DataFrame()

# outlier_df_239
try:
    if outlier_path_239.exists() and outlier_path_239.stat().st_size > 0:
        outlier_df_239 = pd.read_csv(outlier_path_239)
    else:
        print(f"‚ö†Ô∏è {outlier_path_239} missing/empty ‚Äî no outlier info for 2.3.9.")
        outlier_df_239 = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {outlier_path_239} is empty or has no columns. No outlier info for 2.3.9.")
    outlier_df_239 = pd.DataFrame()

# rule_conf_df_239
try:
    if rule_conf_path_239.exists() and rule_conf_path_239.stat().st_size > 0:
        rule_conf_df_239 = pd.read_csv(rule_conf_path_239)
    else:
        print(f"‚ö†Ô∏è {rule_conf_path_239} missing/empty ‚Äî no rule confidence info for 2.3.9.")
        rule_conf_df_239 = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {rule_conf_path_239} is empty or has no columns. No rule confidence info for 2.3.9.")
    rule_conf_df_239 = pd.DataFrame()

# integrity_df_239
try:
    if integrity_path_239.exists() and integrity_path_239.stat().st_size > 0:
        integrity_df_239 = pd.read_csv(integrity_path_239)
    else:
        integrity_df_239 = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {integrity_path_239} is empty or has no columns. Using empty integrity_df_239.")
    integrity_df_239 = pd.DataFrame()



else:
    print(f"‚ö†Ô∏è {rule_conf_path_239} missing ‚Äî no rule confidence info for 2.3.9.")
    # Create an empty DataFrame
    rule_conf_df_239 = pd.DataFrame()
if integrity_path_239.exists():
    integrity_df_239 = pd.read_csv(integrity_path_239)
else:
    integrity_df_239 = pd.DataFrame()

# 2) Normalize each DF to have a 'feature' column where possible
def _ensure_feature_col(df):
    if df.empty:
        return df
    cols = df.columns.tolist()
    if "feature" in cols:
        df["feature"] = df["feature"].astype("string")
    elif "column" in cols:
        df["feature"] = df["column"].astype("string")
    return df

numeric_profile_df_239 = _ensure_feature_col(numeric_profile_df_239)
range_df_239          = _ensure_feature_col(range_df_239)
outlier_df_239        = _ensure_feature_col(outlier_df_239)
rule_conf_df_239      = _ensure_feature_col(rule_conf_df_239)
integrity_df_239      = _ensure_feature_col(integrity_df_239)

# 3) Build a unified base_239 indexed by 'feature'
feature_series_list_239 = []

for df_tmp in [numeric_profile_df_239, range_df_239, outlier_df_239, rule_conf_df_239, integrity_df_239]:
    if (not df_tmp.empty) and ("feature" in df_tmp.columns):
        feature_series_list_239.append(df_tmp["feature"].astype("string"))

if feature_series_list_239:
    all_features_239 = (
        pd.concat(feature_series_list_239, ignore_index=True)
        .dropna()
        .astype("string")
        .unique()
        .tolist()
    )
    all_features_239 = sorted(all_features_239)
    base_239 = pd.DataFrame({"feature": all_features_239})
else:
    base_239 = pd.DataFrame(columns=["feature"])

# 4) Attach core profile info (role, feature_group, null_pct, etc.)
if (not numeric_profile_df_239.empty) and ("feature" in numeric_profile_df_239.columns):
    keep_cols_np_239 = [
        c for c in [
            "feature",
            "column",
            "role",
            "feature_group",
            "null_pct",
            "numeric_integrity_status",
        ] if c in numeric_profile_df_239.columns
    ]
    numeric_core_239 = numeric_profile_df_239[keep_cols_np_239].drop_duplicates(subset=["feature"])
    base_239 = base_239.merge(numeric_core_239, on="feature", how="left")

# If integrity report has extra status, prefer it
if (not integrity_df_239.empty) and ("feature" in integrity_df_239.columns):
    if "numeric_integrity_status" in integrity_df_239.columns:
        integ_core_239 = integrity_df_239[["feature", "numeric_integrity_status"]].drop_duplicates("feature")
        base_239 = base_239.merge(integ_core_239, on="feature", how="left", suffixes=("", "_from_integrity"))
        if "numeric_integrity_status_from_integrity" in base_239.columns:
            base_239["numeric_integrity_status"] = base_239["numeric_integrity_status_from_integrity"].combine_first(
                base_239.get("numeric_integrity_status")
            )
            base_239.drop(columns=["numeric_integrity_status_from_integrity"], inplace=True)
else:
    if "numeric_integrity_status" not in base_239.columns:
        base_239["numeric_integrity_status"] = None

# 5) Attach range & outlier diagnostics

# Range info
if (not range_df_239.empty) and ("feature" in range_df_239.columns):
    keep_cols_range_239 = [c for c in ["feature", "total_violation_pct", "range_status"] if c in range_df_239.columns]
    range_core_239 = range_df_239[keep_cols_range_239].drop_duplicates(subset=["feature"])
    base_239 = base_239.merge(range_core_239, on="feature", how="left")
else:
    base_239["total_violation_pct"] = None
    base_239["range_status"] = None

# Outlier info
if (not outlier_df_239.empty) and ("feature" in outlier_df_239.columns):
    for col_name in ["pct_outliers_iqr", "pct_outliers_z"]:
        if col_name not in outlier_df_239.columns:
            outlier_df_239[col_name] = 0.0
    outlier_core_239 = outlier_df_239[["feature", "pct_outliers_iqr", "pct_outliers_z"]].drop_duplicates("feature")
    base_239 = base_239.merge(outlier_core_239, on="feature", how="left")
else:
    base_239["pct_outliers_iqr"] = None
    base_239["pct_outliers_z"] = None

# 6) Aggregate rule confidence per feature
if (not rule_conf_df_239.empty) and ("feature" in rule_conf_df_239.columns):
    agg_rule_conf_239 = (
        rule_conf_df_239
        .groupby("feature", dropna=False)
        .agg(
            avg_confidence=("confidence_score", "mean"),
            n_rules=("rule_type", "count"),
            n_hard_rules=("hard_vs_soft", lambda s: (s == "hard").sum()),
            n_soft_rules=("hard_vs_soft", lambda s: (s == "soft").sum()),
        )
        .reset_index()
    )
    base_239 = base_239.merge(agg_rule_conf_239, on="feature", how="left")
else:
    base_239["avg_confidence"] = None
    base_239["n_rules"] = 0
    base_239["n_hard_rules"] = 0
    base_239["n_soft_rules"] = 0

# 7) Compute pct_rows_impacted & readiness_score
if "null_pct" in base_239.columns:
    null_pct_239 = base_239["null_pct"].fillna(0.0)
else:
    null_pct_239 = pd.Series(0.0, index=base_239.index)

range_violation_pct_239 = base_239["total_violation_pct"].fillna(0.0)
out_iqr_239 = base_239["pct_outliers_iqr"].fillna(0.0)
out_z_239 = base_239["pct_outliers_z"].fillna(0.0)

max_out_pct_239 = out_iqr_239.combine(out_z_239, func=lambda a, b: max(a, b))

pct_rows_impacted_239 = null_pct_239.combine(range_violation_pct_239, max)
pct_rows_impacted_239 = pct_rows_impacted_239.combine(max_out_pct_239, max)
base_239["pct_rows_impacted"] = pct_rows_impacted_239

avg_conf_239 = base_239["avg_confidence"].fillna(0.8)
n_hard_239 = base_239["n_hard_rules"].fillna(0)

readiness_raw_239 = (
    1.0
    - (pct_rows_impacted_239 / 100.0) * 0.7
    - (n_hard_239 > 0).astype(float) * 0.05
    - (avg_conf_239 < 0.7).astype(float) * 0.05
)
base_239["readiness_score"] = readiness_raw_239.clip(0.0, 1.0)

base_239["hard_rule_violations"] = (
    (range_violation_pct_239 > 0.0) & (n_hard_239 > 0)
).astype(bool)

# 8) Final column ordering + write artifact
model_readiness_cols = [
    col for col in [
        "feature",
        "column" if "column" in base_239.columns else None,
        "role" if "role" in base_239.columns else None,
        "feature_group" if "feature_group" in base_239.columns else None,
        "numeric_integrity_status" if "numeric_integrity_status" in base_239.columns else None,
        "pct_rows_impacted",
        "readiness_score",
        "n_rules",
        "n_hard_rules",
        "n_soft_rules",
        "avg_confidence",
        "hard_rule_violations",
    ] if col is not None
]

model_readiness_df_239 = base_239[model_readiness_cols].copy()

tmp_239 = model_readiness_path_239.with_suffix(".tmp.csv")
model_readiness_df_239.to_csv(tmp_239, index=False)
os.replace(tmp_239, model_readiness_path_239)

print(f"üíæ Wrote model readiness report ‚Üí {model_readiness_path_239}")
if not model_readiness_df_239.empty:
    print("\nüìä 2.3.9 model readiness report (head):")
    display(model_readiness_df_239.head(20))
else:
    print("   (no features found for model readiness)")

# 9) Section 2.3.9 summary row
n_features_239 = int(model_readiness_df_239.shape[0])
avg_readiness_239 = float(model_readiness_df_239["readiness_score"].mean()) if n_features_239 else None
n_low_readiness_239 = int((model_readiness_df_239["readiness_score"] < 0.6).sum()) if n_features_239 else 0

if n_features_239 == 0:
    status_239 = "SKIP"
else:
    frac_low = n_low_readiness_239 / max(1, n_features_239)
    status_239 = "OK" if frac_low <= 0.3 else "WARN"

summary_239 = pd.DataFrame([{
    "section":          "2.3.9",
    "section_name":     "Model readiness impact summary",
    "check":            "Per-feature readiness scores based on numeric quality",
    "level":            "info",
    "status":           status_239,
    "n_features":       int(n_features_239),
    "avg_readiness":    float(avg_readiness_239) if avg_readiness_239 is not None else None,
    "n_low_readiness":  int(n_low_readiness_239),
    "detail":           "model_readiness_report.csv",
    "timestamp":        pd.Timestamp.utcnow(),
}])

append_sec2(summary_239, SECTION2_REPORT_PATH)
display(summary_239)

2.3.9 üßÆ Model readiness impact summary
‚ö†Ô∏è /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/resources/reports/section2/numeric_integrity/rule_confidence_scores.csv missing ‚Äî no rule confidence info for 2.3.9.
üíæ Wrote model readiness report ‚Üí /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/resources/reports/section2/numeric_integrity/model_readiness_report.csv

üìä 2.3.9 model readiness report (head):
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_4276/1370470157.py:202: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  avg_conf_239 = base_239["avg_confidence"].fillna(0.8)

How do I implement the proper rule confidence for 2.3.9?
How do I resolve the FutureWarning: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  avg_conf_239 = base_239["avg_confidence"].fillna(0.8)
```


### 1) ‚ÄúProper rule confidence‚Äù in 2.3.9

Your 2.3.9 is not *using* rule confidence because it cannot find the file:

`.../section2/numeric_integrity/rule_confidence_scores.csv missing`

That means one of these is true.

* 2.3.7.4 wrote the file to a different directory than 2.3.9 is reading.
* 2.3.7.4 never ran in this run.
* `NUMERIC_DIR` changed between sections.

Fix it by making the path a single source of truth and asserting it exists before building 2.3.9.

Drop this at the top of 2.3.9 before you read `rule_conf_path_239`:

```python
# --- Rule confidence path must match 2.3.7.4 --------------------------------
rule_conf_path_239 = NUMERIC_DIR / "rule_confidence_scores.csv"

if not rule_conf_path_239.exists():
    print(f"‚ùå rule_confidence_scores.csv not found at: {rule_conf_path_239}")
    print("   Likely: NUMERIC_DIR differs between 2.3.7.4 and 2.3.9, or 2.3.7.4 did not run.")
    # Optional: try a fallback if you have multiple numeric dirs
    fallback = (REPORTS_DIR / "section2" / "numeric_integrity" / "rule_confidence_scores.csv")
    if fallback.exists():
        print(f"   ‚úÖ Found fallback: {fallback}")
        rule_conf_path_239 = fallback
    else:
        print(f"   ‚ö†Ô∏è No fallback found. Rule confidence will be empty.")
```

Then load it as you already do.

Also: your ‚Äúproper‚Äù rule confidence is whatever you wrote in 2.3.7.4. If you want it to influence readiness, actually use it in the readiness formula. Right now you only penalize `avg_conf < 0.7` and `n_hard_rules > 0`. That is fine. The real bug is the missing file.

Minimal improvement once the file loads: weight hard rules more than soft when aggregating.

Replace your aggregation with:

```python
if (not rule_conf_df_239.empty) and ("feature" in rule_conf_df_239.columns):
    rc = rule_conf_df_239.copy()

    rc["confidence_score"] = pd.to_numeric(rc["confidence_score"], errors="coerce")
    rc["is_hard"] = (rc["hard_vs_soft"].astype("string") == "hard")

    agg_rule_conf_239 = (
        rc.groupby("feature", dropna=False)
          .agg(
              avg_confidence=("confidence_score", "mean"),
              hard_confidence=("confidence_score", lambda s: s[rc.loc[s.index, "is_hard"]].mean()),
              n_rules=("rule_type", "count"),
              n_hard_rules=("is_hard", "sum"),
          )
          .reset_index()
    )
    base_239 = base_239.merge(agg_rule_conf_239, on="feature", how="left")
else:
    base_239["avg_confidence"] = None
    base_239["hard_confidence"] = None
    base_239["n_rules"] = 0
    base_239["n_hard_rules"] = 0
```

Then use `hard_confidence` in readiness if you want.

---

### 2) Fix the FutureWarning on `fillna`

The warning happens because `base_239["avg_confidence"]` is `object` dtype, so `fillna(0.8)` triggers deprecated silent downcasting behavior.

Fix by coercing to numeric first and using a nullable float dtype.

Replace:

```python
avg_conf_239 = base_239["avg_confidence"].fillna(0.8)
```

with:

```python
base_239["avg_confidence"] = pd.to_numeric(base_239.get("avg_confidence"), errors="coerce")
avg_conf_239 = base_239["avg_confidence"].astype("Float64").fillna(0.8)
```

Do the same for other percent columns if any are object-typed:

```python
base_239["total_violation_pct"] = pd.to_numeric(base_239.get("total_violation_pct"), errors="coerce")
base_239["pct_outliers_iqr"] = pd.to_numeric(base_239.get("pct_outliers_iqr"), errors="coerce")
base_239["pct_outliers_z"] = pd.to_numeric(base_239.get("pct_outliers_z"), errors="coerce")
base_239["null_pct"] = pd.to_numeric(base_239.get("null_pct"), errors="coerce")
```

That eliminates the warning without global options.

---

If you paste the printed paths from 2.3.7.4 (where it wrote `rule_confidence_scores.csv`) and from 2.3.9 (where it looked), I can tell you exactly which directory variable is drifting.
