># FIX: id_cols not populated

```python
# 2.1.5 | Feature Group Registration

# TODO: fix numbering issues in 2.1.5 & PART B

# 2.1.5 üß¨ Feature Group Registration | Column-level Feature Catalog
print("\n2.1.5 üß¨ Feature Group Registration | Column-level Feature Catalog")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0.0 first."
assert "CONFIG" in globals(), "‚ùå CONFIG not found. Run 2.0.0 first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."
assert "ARTIFACTS_DIR" in globals(), "‚ùå ARTIFACTS_DIR missing. Run 2.0.0 first."
assert "id_cols" in globals(), "‚ùå id_cols not found. Run 2.1.2 first."

import json  # used later for group_counts_json in diagnostics

# 1) Config + thresholds
fg_cfg = CONFIG.get("FEATURE_GROUPING", {}) or {}
low_card_threshold = int(fg_cfg.get("LOW_CARDINALITY_THRESHOLD", 20))
free_text_min_avg_len = int(fg_cfg.get("FREE_TEXT_MIN_AVG_LEN", 30))

ordinal_cfg = CONFIG.get("ORDINAL_COLUMNS", []) or []
if isinstance(ordinal_cfg, (str, bytes)):
    ordinal_cols = [ordinal_cfg]
else:
    ordinal_cols = list(ordinal_cfg)

protected_cfg = CONFIG.get("PROTECTED_COLUMNS", []) or []
if isinstance(protected_cfg, (str, bytes)):
    protected_from_config = {protected_cfg}
else:
    protected_from_config = set(protected_cfg)

# 2) Resolve target columns
# Try to locate target columns from earlier steps
raw_target_col = None
encoded_target_col = None

_target_block = CONFIG.get("TARGET", {}) or {}
_raw_from_cfg = _target_block.get("RAW_COLUMN")
_enc_from_cfg = _target_block.get("COLUMN")

if _raw_from_cfg and _raw_from_cfg in df.columns:
    raw_target_col = _raw_from_cfg
elif "raw_target_col" in globals() and isinstance(raw_target_col, str) and raw_target_col in df.columns:
    # keep previously-resolved raw_target_col if present
    pass

if _enc_from_cfg and _enc_from_cfg in df.columns:
    encoded_target_col = _enc_from_cfg
elif "encoded_target_col" in globals() and isinstance(encoded_target_col, str) and encoded_target_col in df.columns:
    # keep previously-resolved encoded_target_col if present
    pass

# 3) Load special numeric flags (from 2.1.3)
special_flags_path = SEC2_REPORTS_DIR / "special_numeric_flags.csv"
special_flag_cols = set()

if special_flags_path.exists() and special_flags_path.stat().st_size > 0:
    try:
        _special_flags_df = pd.read_csv(special_flags_path)
    except Exception:
        _special_flags_df = pd.DataFrame()
    if "column" in _special_flags_df.columns:
        special_flag_cols = set(
            _special_flags_df["column"].dropna().astype("string")
        )
else:
    _special_flags_df = pd.DataFrame(columns=["column", "role"])

# 4) Build protected-columns set
protected_cols = set()

# IDs
protected_cols.update(id_cols)

# Targets
if raw_target_col is not None:
    protected_cols.add(raw_target_col)
if encoded_target_col is not None:
    protected_cols.add(encoded_target_col)

# Special numeric flags
protected_cols.update(special_flag_cols)

# Config-driven protected list
protected_cols.update(protected_from_config)

# Ensure only columns that actually exist in df are considered protected
# Only keep those that actually exist in df
protected_cols = {c for c in protected_cols if c in df.columns}

# --- 2.1.5.5 Feature grouping logic (per-column catalog) --------------------
feature_group_rows = []

for col in df.columns:
    s = df[col]
    dtype_str = str(s.dtype)
    n_unique = int(s.nunique(dropna=True))
    is_protected = col in protected_cols

    # Base notes str we can enrich
    notes = []

    # Target / target_aux
    if encoded_target_col is not None and col == encoded_target_col:
        feature_group = "target"
        notes.append("binary target (encoded)")
    elif raw_target_col is not None and col == raw_target_col:
        feature_group = "target_aux"
        notes.append("raw target label")
    # ID / primary key
    elif col in id_cols:
        feature_group = "id"
        notes.append("ID / key candidate")
    # Explicit ordinal from config
    elif col in ordinal_cols:
        feature_group = "ordinal"
        notes.append("ordinal from CONFIG.ORDINAL_COLUMNS")
    # Special-case numeric flags from 2.1.3
    elif col in special_flag_cols:
        feature_group = "numeric_flag"
        notes.append("special numeric flag (2.1.3)")
    else:
        # Type-based rules
        if pd.api.types.is_datetime64_any_dtype(s):
            feature_group = "datetime"
            notes.append("datetime-like dtype")
        elif pd.api.types.is_bool_dtype(s):
            feature_group = "numeric_flag"
            notes.append("bool ‚Üí treated as flag")
        elif pd.api.types.is_numeric_dtype(s):
            # numeric: detect potential flag-like or discrete small-card
            if n_unique <= low_card_threshold and n_unique <= 10:
                feature_group = "numeric_flag"
                notes.append(
                    f"numeric small-card (n_unique={n_unique} ‚â§ {low_card_threshold})"
                )
            else:
                feature_group = "numeric_continuous"
                notes.append("numeric continuous / high-card")
        else:
            # object / string-like / category
            # quick heuristic for free text: high card + long strings
            try:
                avg_len = float(
                    s.dropna()
                    .astype("string")
                    .str.len()
                    .mean()
                )
            except Exception:
                avg_len = 0.0

            if n_unique <= low_card_threshold:
                feature_group = "categorical_low_card"
                notes.append(
                    f"low-card categorical (n_unique={n_unique} ‚â§ {low_card_threshold})"
                )
            else:
                if avg_len >= free_text_min_avg_len:
                    feature_group = "free_text"
                    notes.append(
                        f"free text (avg_len‚âà{avg_len:.1f} ‚â• {free_text_min_avg_len})"
                    )
                else:
                    feature_group = "categorical_high_card"
                    notes.append(
                        f"high-card categorical (n_unique={n_unique} > {low_card_threshold})"
                    )

    feature_group_rows.append(
        {
            "column": col,
            "dtype": dtype_str,
            "feature_group": feature_group,
            "n_unique": n_unique,
            "protected": bool(is_protected),
            "notes": "; ".join(notes),
        }
    )

#
feature_groups_df = pd.DataFrame(feature_group_rows)

# Just in case, ensure feature_group is not missing
feature_groups_df["feature_group"] = feature_groups_df["feature_group"].fillna("other")

# --- 2.1.5.6 Persist CSV artifact under SEC2_REPORTS_DIR --------------------
fg_csv_path = SEC2_REPORTS_DIR / "feature_groups_2_1_5.csv"
fg_tmp_csv = fg_csv_path.with_suffix(".tmp.csv")

feature_groups_df.to_csv(fg_tmp_csv, index=False)
os.replace(fg_tmp_csv, fg_csv_path)

print(f"‚úÖ 2.1.5 feature groups CSV written ‚Üí {fg_csv_path}")
display(feature_groups_df.head(30))

# FIXME: integrate into 2.1.6 --- 2.1.5.6 Persist YAML / JSON artifact under ARTIFACTS_DIR --------------
# Build group ‚Üí columns mapping (+ protected info) for YAML/JSON
group_map = {}
for grp, sub_df in feature_groups_df.groupby("feature_group"):
    group_map[str(grp)] = sorted(sub_df["column"].astype("string").tolist())

protected_list = sorted(feature_groups_df.loc[feature_groups_df["protected"], "column"].astype("string").tolist())
meta = {
    "section": "2.1.5",
    "description": "Feature group catalog at end of Section 2.1",
    "low_card_threshold": low_card_threshold,
    "free_text_min_avg_len": free_text_min_avg_len,
    "protected_columns": protected_list,
}

fg_struct = {
    "groups": group_map,
    "meta": meta,
}

# JSON
fg_json_path = ARTIFACTS_DIR / "feature_groups_2_1_5.json"
fg_tmp_json = fg_json_path.with_suffix(".tmp.json")
with open(fg_tmp_json, "w", encoding="utf-8") as f:
    json.dump(fg_struct, f, indent=2, ensure_ascii=False)
os.replace(fg_tmp_json, fg_json_path)

print(f"üíæ feature groups JSON written ‚Üí {fg_json_path}")

# -- YAML (optional)
fg_yaml_path = ARTIFACTS_DIR / "feature_groups_2_1_5.yaml"
if yaml is not None:
    fg_tmp_yaml = fg_yaml_path.with_suffix(".tmp.yaml")
    with open(fg_tmp_yaml, "w", encoding="utf-8") as f:
        yaml.safe_dump(fg_struct, f, sort_keys=False, allow_unicode=True)
    os.replace(fg_tmp_yaml, fg_yaml_path)
    print(f"üíæ feature groups YAML written ‚Üí {fg_yaml_path}")
else:
    print("‚ö†Ô∏è yaml not available; skipping YAML export for feature groups.")


# -- 2.1.5.7 Summary metrics + unified diagnostics row
group_counts = (
    feature_groups_df["feature_group"]
    .value_counts()
    .sort_index()
    .to_dict()
)

# metrics?
n_features = int(len(feature_groups_df))
n_protected = int(feature_groups_df["protected"].sum())
n_unassigned = int((feature_groups_df["feature_group"] == "other").sum())

# set status
status_215 = "OK"

# set notes
notes_215 = None
if n_unassigned > 0:
    status_215 = "WARN"
    notes_215 = f"{n_unassigned} column(s) unassigned ‚Üí feature_group='other'"

# use scalar values ([{}])
summary_215 = pd.DataFrame([{
    "section":             "2.1.5",
    "section_name":        "Feature group registration",
    "check":               "Feature group catalog (column-level)",
    "level":               "info",
    "status":              status_215,
    "n_features":          n_features,
    "n_protected":         n_protected,
    "n_unassigned":        n_unassigned,
    "group_counts_json":   json.dumps(group_counts, sort_keys=True),
    "feature_groups_csv":  fg_csv_path.name,
    "feature_groups_json": fg_json_path.name,
    "feature_groups_yaml": fg_yaml_path.name if yaml is not None else None,
    "timestamp": pd.Timestamp.utcnow(),
    "detail": (
        f"Feature groups registered for {n_features} column(s); "
        f"catalog written to {fg_csv_path.name}."),
    "notes":                notes_215,
}])

append_sec2(summary_215, SECTION2_REPORT_PATH)
display(summary_215)
```

2.1.5 üß¨ Feature Group Registration | Column-level Feature Catalog
‚úÖ 2.1.5 feature groups CSV written ‚Üí /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/resources/reports/section2/feature_groups_2_1_5.csv


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column</th>
      <th>dtype</th>
      <th>feature_group</th>
      <th>n_unique</th>
      <th>protected</th>
      <th>notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>customerID</td>
      <td>object</td>
      <td>id</td>
      <td>7043</td>
      <td>True</td>
      <td>ID / key candidate</td>
    </tr>
    <tr>
      <th>1</th>
      <td>gender</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>2</td>
      <td>False</td>
      <td>low-card categorical (n_unique=2 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SeniorCitizen</td>
      <td>int64</td>
      <td>numeric_flag</td>
      <td>2</td>
      <td>True</td>
      <td>special numeric flag (2.1.3)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Partner</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>2</td>
      <td>False</td>
      <td>low-card categorical (n_unique=2 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Dependents</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>2</td>
      <td>False</td>
      <td>low-card categorical (n_unique=2 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>5</th>
      <td>tenure</td>
      <td>int64</td>
      <td>numeric_continuous</td>
      <td>73</td>
      <td>False</td>
      <td>numeric continuous / high-card</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PhoneService</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>2</td>
      <td>False</td>
      <td>low-card categorical (n_unique=2 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>7</th>
      <td>MultipleLines</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>8</th>
      <td>InternetService</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>9</th>
      <td>OnlineSecurity</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>10</th>
      <td>OnlineBackup</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>11</th>
      <td>DeviceProtection</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>12</th>
      <td>TechSupport</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>13</th>
      <td>StreamingTV</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>14</th>
      <td>StreamingMovies</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Contract</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>3</td>
      <td>False</td>
      <td>low-card categorical (n_unique=3 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>16</th>
      <td>PaperlessBilling</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>2</td>
      <td>False</td>
      <td>low-card categorical (n_unique=2 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>17</th>
      <td>PaymentMethod</td>
      <td>object</td>
      <td>categorical_low_card</td>
      <td>4</td>
      <td>False</td>
      <td>low-card categorical (n_unique=4 ‚â§ 20)</td>
    </tr>
    <tr>
      <th>18</th>
      <td>MonthlyCharges</td>
      <td>float64</td>
      <td>numeric_continuous</td>
      <td>1585</td>
      <td>False</td>
      <td>numeric continuous / high-card</td>
    </tr>
    <tr>
      <th>19</th>
      <td>TotalCharges</td>
      <td>float64</td>
      <td>numeric_continuous</td>
      <td>6530</td>
      <td>False</td>
      <td>numeric continuous / high-card</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Churn</td>
      <td>object</td>
      <td>target_aux</td>
      <td>2</td>
      <td>True</td>
      <td>raw target label</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Churn_flag</td>
      <td>Int64</td>
      <td>target</td>
      <td>2</td>
      <td>True</td>
      <td>binary target (encoded)</td>
    </tr>
  </tbody>
</table>
</div>

># A:

Yes ‚Äî **conceptually it‚Äôs doing what ‚Äúfeature group registration‚Äù should do**: it creates a *column-level catalog*, assigns each column to a group with rules, marks ‚Äúprotected‚Äù columns, writes artifacts (CSV + JSON + optional YAML), and logs a summary row.

That said, there are a few **quiet gotchas** in *your specific code* that mean it‚Äôs **not doing exactly what you intended in a couple places**.

## What it‚Äôs doing correctly ‚úÖ

* **Groups your columns** into sensible buckets (`id`, `target`, `target_aux`, `numeric_continuous`, `numeric_flag`, `categorical_low_card`, etc.).
* **Protects** IDs + targets + special flags + config-protected columns.
* **Persists outputs**:

  * CSV ‚Üí `SEC2_REPORTS_DIR/feature_groups_2_1_5.csv` ‚úÖ
  * JSON/YAML ‚Üí `ARTIFACTS_DIR/feature_groups_2_1_5.*` ‚úÖ
* **Creates summary metrics** (counts, protected count, etc.) and appends to Section 2 report ‚úÖ

## Two real bugs / misbehaviors ‚ö†Ô∏è

### FIX 1) Your ‚Äúkeep previously resolved target col‚Äù logic can never work

You do:

```python
raw_target_col = None
...
elif "raw_target_col" in globals() and isinstance(raw_target_col, str) ...
```

But `raw_target_col` is a local variable you just set to `None`, so `isinstance(raw_target_col, str)` will always be False. Same issue for `encoded_target_col`.

**Effect:** you *only* ever pick targets from `CONFIG.TARGET.*` (or not at all). You are **not** actually ‚Äúkeeping previously-resolved‚Äù targets.

‚úÖ Fix (inline, no functions): check `globals().get("raw_target_col")` / `globals().get("encoded_target_col")`.

> EXPLANATION 2:
> What‚Äôs going on is a **scope / name collision** problem: you‚Äôre trying to ‚Äúreuse‚Äù a value that might exist in the *global notebook namespace*, but you accidentally check the **local variable** you just set to `None`.

### Why your current code can‚Äôt ‚Äúkeep previously-resolved‚Äù

You do this (simplified):

```python
raw_target_col = None

...

elif "raw_target_col" in globals() and isinstance(raw_target_col, str) and raw_target_col in df.columns:
    pass
```

* `raw_target_col = None` creates a **local variable** named `raw_target_col` (in that cell‚Äôs scope).
* That local variable is **None**, so `isinstance(raw_target_col, str)` is **always False**.
* Even if you *previously* had a global `raw_target_col = "Churn"` from an earlier cell/run, you never read it. You only check whether the *name* exists in `globals()`, but then you validate the **local** `raw_target_col` (None), not the global one.

So the ‚Äúkeep previously-resolved‚Äù branch is effectively dead code.

---

## What the fix actually means

If you want to reuse a previously computed value, you must **read it out of `globals()`** (or not overwrite it in the first place).

### Correct pattern (inline, no functions)

Use a separate variable to fetch the global value:

```python
raw_target_col = None

_target_block = CONFIG.get("TARGET", {}) or {}
_raw_from_cfg = _target_block.get("RAW_COLUMN")

if _raw_from_cfg and _raw_from_cfg in df.columns:
    raw_target_col = _raw_from_cfg
else:
    _prev_raw = globals().get("raw_target_col")
    if isinstance(_prev_raw, str) and _prev_raw in df.columns:
        raw_target_col = _prev_raw
```

Same idea for `encoded_target_col`:

```python
encoded_target_col = None
_enc_from_cfg = _target_block.get("COLUMN")

if _enc_from_cfg and _enc_from_cfg in df.columns:
    encoded_target_col = _enc_from_cfg
else:
    _prev_enc = globals().get("encoded_target_col")
    if isinstance(_prev_enc, str) and _prev_enc in df.columns:
        encoded_target_col = _prev_enc
```

### Why this works

* `_prev_raw = globals().get("raw_target_col")` actually retrieves the *previous global value* (if any).
* You validate `_prev_raw` instead of the local `raw_target_col`.
* You only adopt it if it‚Äôs a string and still a real column in `df`.

---

## The behavior you get after the fix (the intended ‚Äúfallback ladder‚Äù)

For each target variable, you now have a clean priority order:

1. **Use config** if it points to a real column in the current `df`
2. Else, **reuse previously resolved** global value if valid
3. Else, leave it `None` (and downstream grouping won‚Äôt treat anything as target)

This is useful because in notebooks:

* you sometimes rerun a later cell after changing `df`
* or you temporarily rename/re-encode targets and store the result in `raw_target_col` / `encoded_target_col`
* and you don‚Äôt want to re-edit YAML just to keep moving

---

## One extra nuance (important)

If you *don‚Äôt actually need* the ‚Äúpreviously resolved‚Äù behavior, the simplest move is to **delete the fallback entirely** and rely only on `CONFIG["TARGET"]`. That‚Äôs more deterministic.

But if you like the fallback, the `globals().get(...)` approach is the correct way to do it without functions.

üí°üí° If you paste your exact target-resolution block (both raw + encoded), I‚Äôll rewrite it cleanly in-place with this fallback ladder and with your existing naming conventions.

---
---


### FIX 2) ‚Äúnumeric small-card‚Äù rule is stricter than it looks

You label numeric as flag only when:

```python
if n_unique <= low_card_threshold and n_unique <= 10:
```

Because of the `and n_unique <= 10`, your `low_card_threshold` basically doesn‚Äôt matter above 10.

**Effect:** `low_card_threshold=20` will never let a numeric column with 11‚Äì20 unique values become `numeric_flag`. It‚Äôll become `numeric_continuous`.

That might be what you want! But your note says `‚â§ {low_card_threshold}` while the code is really `‚â§ min(low_card_threshold, 10)`.

‚úÖ Fix: decide which you want:

* If you truly want `low_card_threshold` to drive it ‚Üí remove `and n_unique <= 10`
* If you want hard cap at 10 ‚Üí update the note string to be accurate

---

## One design note (not a bug) üí°üí°

You write JSON/YAML to `ARTIFACTS_DIR`, but in your project layout you also have `SEC2_ARTIFACTS_DIR` and `SEC2_REGISTRY_DIR`. If `ARTIFACTS_DIR` is ‚Äúproject-wide,‚Äù you‚Äôll end up mixing sections.

I‚Äôd usually put:

* machine-consumed stuff ‚Üí `SEC2_ARTIFACTS_DIR` (or `SEC2_REGISTRY_DIR` if it‚Äôs ‚Äúregistry-ish‚Äù)

But if you *intended* `ARTIFACTS_DIR` to be Section 2 already, then you‚Äôre fine.

---

## Quick sanity check from your output

Your shown output looks right:

* `customerID` ‚Üí `id`, protected ‚úÖ
* `Churn` ‚Üí `target_aux`, protected ‚úÖ
* `Churn_flag` ‚Üí `target`, protected ‚úÖ
* `SeniorCitizen` ‚Üí `numeric_flag` because it‚Äôs in special flags ‚úÖ
* `tenure`, `MonthlyCharges`, `TotalCharges` ‚Üí `numeric_continuous` ‚úÖ
* the rest low-card categoricals ‚úÖ

So the classification behavior matches expectations for Telco churn.

---

If you want, paste your `CONFIG["TARGET"]` and what `id_cols` contains, and I‚Äôll tell you if any important columns are being misclassified (like `TotalCharges` sometimes being string-ish in this dataset depending on cleaning).

---

># INPUT:

```py
print(id_cols)
print(CONFIG.get("TARGET"))
print(CONFIG.get("ORDINAL_COLUMNS"))


# OUTPUT:
set()
{'COLUMN': 'Churn_flag', 'RAW_COLUMN': 'Churn', 'POSITIVE_CLASS': 'Yes', 'NEGATIVE_CLASS': 'No'}
None
```

Cool ‚Äî that output tells us a lot.

## What it means

### 1) `id_cols` is **not set up correctly**

You got:

* `id_cols = set()`

So your ‚ÄúID protection‚Äù logic isn‚Äôt doing anything right now. The only reason `customerID` is showing as `id` + `protected=True` in your feature catalog is because **you still classified it as `id` somewhere** (likely via an earlier heuristic or a previous run), *not* because `id_cols` actually contains it.

Given your guard says `Run 2.1.2 first`, your **2.1.2 step either didn‚Äôt detect IDs, didn‚Äôt run, or didn‚Äôt persist/populate `id_cols`**.

‚úÖ Immediate fix (fast): if you know your ID column:

```python
id_cols = {"customerID"}
```

üí°üí° Better fix: in **2.1.2** ensure it explicitly assigns:

* `id_cols = {...}` in memory
* and writes an artifact like `id_columns.csv` (so later steps can rehydrate even if you restart the kernel)

---

### 2) Your `TARGET` config exists and is good ‚úÖ

You have:

```python
{'COLUMN': 'Churn_flag', 'RAW_COLUMN': 'Churn', 'POSITIVE_CLASS': 'Yes', 'NEGATIVE_CLASS': 'No'}
```

So `CONFIG["TARGET"]` is fine and your target detection logic should lock onto:

* raw target: `Churn`
* encoded target: `Churn_flag`

One tiny mismatch: your code uses `POS_LABEL` / `NEG_LABEL` in comments, but your config uses `POSITIVE_CLASS` / `NEGATIVE_CLASS`. That only matters in other sections if you reference those keys.

---

### 3) `ORDINAL_COLUMNS` is not defined (and that‚Äôs fine)

You got `None`, so your code correctly turns that into an empty list:

* `ordinal_cols = []`
  No ordinal classification will happen unless you add it to the YAML.

---

## The only ‚Äúproblem‚Äù for 2.1.5 right now

Because `id_cols` is empty:

* **your ID columns will not be protected**
* and they might not even be labeled `id` unless you have separate ID heuristics

In Telco, that means `customerID` might accidentally get treated as high-card categorical later (depending on your rules elsewhere), which is *exactly* what you don‚Äôt want.

---

## What you should do next (no functions)

### A) Patch it now so the pipeline continues cleanly

Put this right before 2.1.5 (or right after 2.1.2 if you rerun that section):

```python
if not id_cols:
    if "customerID" in df.columns:
        id_cols = {"customerID"}
        print("‚ö†Ô∏è id_cols was empty; patched to {'customerID'} for this dataset.")
```

### B) Fix the root cause in 2.1.2

2.1.2 should end with something like:

* `id_cols` populated
* `SEC2_REPORTS_DIR / "id_columns.csv"` written
* and/or a JSON in `SEC2_ARTIFACTS_DIR` so later steps can reload it

---

üí°üí° If you paste your **2.1.2** code block (the part that‚Äôs supposed to populate `id_cols`), I‚Äôll point out exactly why it‚Äôs ending up as `set()` and give you an inline fix that persists the artifact too.


># X

Yep ‚Äî your **target fallback fix is now correct**, but your block has some **duplication / ordering weirdness** that you should clean up so future-you doesn‚Äôt get confused.

## What you fixed correctly ‚úÖ

These parts are now doing the right thing:

```python
if _raw_from_cfg and _raw_from_cfg in df.columns:
    raw_target_col = _raw_from_cfg
else:
    _prev_raw = globals().get("raw_target_col")
    if isinstance(_prev_raw, str) and _prev_raw in df.columns:
        raw_target_col = _prev_raw
```

and

```python
if _enc_from_cfg and _enc_from_cfg in df.columns:
    encoded_target_col = _enc_from_cfg
else:
    _prev_enc = globals().get("encoded_target_col")
    if isinstance(_prev_enc, str) and _prev_enc in df.columns:
        encoded_target_col = _prev_enc
```

That establishes the intended ladder:

1. **Use config** (deterministic, preferred)
2. Else **use previously resolved global** (convenient in notebooks)
3. Else stay `None`

## What to clean up (not logic-breaking, but messy) ‚ö†Ô∏è

Right now you have repeated lines:

* You define `_target_block`, `_raw_from_cfg`, `_enc_from_cfg` **twice**
* You set `_enc_from_cfg` **twice**
* You reassign `encoded_target_col = None` after already setting `_enc_from_cfg` once
* Comments say ‚ÄúResolve target columns‚Äù twice

This won‚Äôt usually *break* anything, but it makes it easier to introduce a bug later.

### Replace your entire ‚Äú2) Resolve target columns‚Äù section with this (inline, no functions)

```python
# 2) Resolve target columns (prefer CONFIG, fallback to previously-resolved globals)
raw_target_col = None
encoded_target_col = None

_target_block = CONFIG.get("TARGET", {}) or {}
_raw_from_cfg = _target_block.get("RAW_COLUMN")
_enc_from_cfg = _target_block.get("COLUMN")

# Raw target (e.g., "Churn")
if _raw_from_cfg and _raw_from_cfg in df.columns:
    raw_target_col = _raw_from_cfg
else:
    _prev_raw = globals().get("raw_target_col")
    if isinstance(_prev_raw, str) and _prev_raw in df.columns:
        raw_target_col = _prev_raw

# Encoded target (e.g., "Churn_flag")
if _enc_from_cfg and _enc_from_cfg in df.columns:
    encoded_target_col = _enc_from_cfg
else:
    _prev_enc = globals().get("encoded_target_col")
    if isinstance(_prev_enc, str) and _prev_enc in df.columns:
        encoded_target_col = _prev_enc

print("üéØ raw_target_col:", raw_target_col, "| encoded_target_col:", encoded_target_col)
```

That last `print` is optional but helpful‚Äîlets you confirm the resolution every run.

## One more tiny improvement üí°üí°

Right now your code uses the global fallback only if you already ran a prior cell that set `raw_target_col` / `encoded_target_col` globally. If you never set those anywhere, the fallback does nothing‚Äîwhich is fine.

But since your `CONFIG["TARGET"]` is present and correct, you‚Äôll almost always resolve from config anyway.

---

If you want, I can also point out the next likely ‚Äúlogic mismatch‚Äù in this cell: your note string for numeric flags says `‚â§ low_card_threshold` but your rule is effectively `‚â§ 10` because of the extra `and n_unique <= 10`.
