># Q: Where is the drift happening

```python
# 2.3.7.4 | Rule Confidence Scores
print("\n2.3.7.4 ‚è±Ô∏è Rule confidence scores")

rule_rows_2374 = []

range_path_2374  = NUMERIC_DIR / "range_violation_report.csv"
outlier_path_2374 = NUMERIC_DIR / "outlier_report_iqr_z.csv"
ts_outliers_path_2374 = globals().get("time_series_outliers_path", NUMERIC_DIR / "time_series_outliers.csv")
corr_anom_path_2374   = NUMERIC_DIR / "correlation_anomalies.csv"

try:
    hard_types_cfg_2374 = C("NUMERIC.RULES.HARD_TYPES", ["range"]) or ["range"]
except Exception:
    hard_types_cfg_2374 = ["range"]

# --- Range rules -------------------------------------------------------
if range_path_2374.exists():
    range_df_2374 = pd.read_csv(range_path_2374)
else:
    range_df_2374 = pd.DataFrame()

for _, r in range_df_2374.iterrows():
    has_range_rule = bool(r.get("has_range_rule", False))
    if not has_range_rule:
        continue

    col = r.get("column")

    n_below_raw = r.get("n_below_min", 0)
    n_above_raw = r.get("n_above_max", 0)
    n_in_raw    = r.get("n_in_range", 0)

    n_below = float(0 if pd.isna(n_below_raw) else n_below_raw)
    n_above = float(0 if pd.isna(n_above_raw) else n_above_raw)
    n_in    = float(0 if pd.isna(n_in_raw)    else n_in_raw)

    total = n_below + n_above + n_in
    if pd.isna(total) or total <= 0:
        total = 1.0

    viol_rate = (n_below + n_above) / total

    if total >= 1000:
        size_factor = 1.0
    elif total >= 100:
        size_factor = 0.8
    else:
        size_factor = 0.6

    viol_factor = max(0.2, 1.0 - viol_rate * 4.0)
    confidence = float(min(1.0, size_factor * viol_factor))

    total_display = int(round(total))

    rule_rows_2374.append(
        {
            "feature":          col,
            "rule_type":        "range",
            "rule_id":          "range_minmax",
            "confidence_score": round(confidence, 3),
            "hard_vs_soft":     "hard" if "range" in hard_types_cfg_2374 else "soft",
            "notes":            f"viol_rate={round(viol_rate,4)}, total={total_display}",
        }
    )

# --- Outlier rules (IQR/Z) ---------------------------------------------
if outlier_path_2374.exists():
    out_df_2374 = pd.read_csv(outlier_path_2374)
else:
    out_df_2374 = pd.DataFrame()

for _, r in out_df_2374.iterrows():
    col = r.get("column")
    pct_iqr = float(r.get("pct_outliers_iqr", 0) or 0)
    pct_z   = float(r.get("pct_outliers_z", 0) or 0)

    max_pct = max(pct_iqr, pct_z)
    if max_pct < 1.0:
        sev_factor = 1.0
    elif max_pct < 5.0:
        sev_factor = 0.8
    else:
        sev_factor = 0.6

    confidence = float(sev_factor)

    rule_rows_2374.append(
        {
            "feature":          col,
            "rule_type":        "outlier_iqr_z",
            "rule_id":          "outlier_iqr_z",
            "confidence_score": round(confidence, 3),
            "hard_vs_soft":     "soft",
            "notes":            f"max_pct_outliers={round(max_pct,3)}",
        }
    )

# --- Temporal time-series rules ----------------------------------------
ts_df_2374 = pd.DataFrame()
if isinstance(ts_outliers_path_2374, Path) and ts_outliers_path_2374.exists() and ts_outliers_path_2374.stat().st_size > 0:
    try:
        ts_df_2374 = pd.read_csv(ts_outliers_path_2374)
    except pd.errors.EmptyDataError:
        ts_df_2374 = pd.DataFrame()

if not ts_df_2374.empty:
    if ts_df_2374["is_outlier"].dtype != bool:
        ts_df_2374["is_outlier"] = ts_df_2374["is_outlier"].astype(bool)

    total_buckets = ts_df_2374["time_bucket"].nunique()
    if total_buckets <= 0:
        total_buckets = 1

    for feat, g in ts_df_2374.groupby("feature"):
        n_out_feat = int(g[g["is_outlier"]].shape[0])
        rate_feat  = n_out_feat / total_buckets

        if rate_feat == 0:
            conf = 0.9
        elif rate_feat < 0.2:
            conf = 0.8
        else:
            conf = 0.6

        rule_rows_2374.append(
            {
                "feature":          feat,
                "rule_type":        "temporal_ts_outlier",
                "rule_id":          "ts_zscore",
                "confidence_score": round(float(conf), 3),
                "hard_vs_soft":     "soft",
                "notes":            f"outlier_bucket_rate={round(rate_feat,4)}",
            }
        )

# --- Correlation anomaly rules -----------------------------------------
corr_df_2374 = pd.DataFrame()
if corr_anom_path_2374.exists() and corr_anom_path_2374.stat().st_size > 0:
    try:
        corr_df_2374 = pd.read_csv(corr_anom_path_2374)
    except pd.errors.EmptyDataError:
        corr_df_2374 = pd.DataFrame()

for _, r in corr_df_2374.iterrows():
    feat_i = r.get("feature_i")
    feat_j = r.get("feature_j")
    abs_delta = float(r.get("abs_delta", 0) or 0)

    if abs_delta < corr_delta_threshold_237:
        conf = 0.7
    elif abs_delta < 2 * corr_delta_threshold_237:
        conf = 0.8
    else:
        conf = 0.9

    rule_rows_2374.append(
        {
            "feature":          f"{feat_i}__{feat_j}",
            "rule_type":        "correlation",
            "rule_id":          r.get("time_window", ""),
            "confidence_score": round(float(conf), 3),
            "hard_vs_soft":     "soft",
            "notes":            f"abs_delta={round(abs_delta,4)}",
        }
    )

rule_conf_df_2374 = pd.DataFrame(rule_rows_2374)

rule_conf_path_2374 = NUMERIC_DIR / "rule_confidence_scores.csv"
tmp_2374 = rule_conf_path_2374.with_suffix(".tmp.csv")
rule_conf_df_2374.to_csv(tmp_2374, index=False)
os.replace(tmp_2374, rule_conf_path_2374)

print(f"üíæ Wrote rule confidence scores ‚Üí {rule_conf_path_2374}")
if not rule_conf_df_2374.empty:
    print("\nüìä 2.3.7.4 rule confidence scores (head):")
    display(rule_conf_df_2374.head(30))

n_rules_2374 = int(rule_conf_df_2374.shape[0])
n_hard_rules_2374 = int((rule_conf_df_2374["hard_vs_soft"] == "hard").sum()) if n_rules_2374 else 0
n_soft_rules_2374 = int((rule_conf_df_2374["hard_vs_soft"] == "soft").sum()) if n_rules_2374 else 0

status_2374 = "SKIP" if n_rules_2374 == 0 else "OK"

summary_2374 = pd.DataFrame([{
    "section":       "2.3.7.4",
    "section_name":  "Rule confidence scores",
    "check":         "Assign confidence & hardness to numeric rules",
    "level":         "info",
    "status":        status_2374,
    "n_rules":       n_rules_2374,
    "n_hard_rules":  n_hard_rules_2374,
    "n_soft_rules":  n_soft_rules_2374,
    "detail":        f"rule_confidence_scores.csv under {NUMERIC_DIR.name}",
    "timestamp":     pd.Timestamp.utcnow(),
}])

append_sec2(summary_2374, SECTION2_REPORT_PATH)
display(summary_2374)

#OUTPUT:
2.3.7.4 ‚è±Ô∏è Rule confidence scores
üíæ Wrote rule confidence scores ‚Üí /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/resources/reports/section2/numeric_integrity/rule_confidence_scores.csv

üìä 2.3.7.4 rule confidence scores (head):
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>rule_type</th>
      <th>rule_id</th>
      <th>confidence_score</th>
      <th>hard_vs_soft</th>
      <th>notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SeniorCitizen</td>
      <td>outlier_iqr_z</td>
      <td>outlier_iqr_z</td>
      <td>0.6</td>
      <td>soft</td>
      <td>max_pct_outliers=16.215</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Churn_flag</td>
      <td>outlier_iqr_z</td>
      <td>outlier_iqr_z</td>
      <td>1.0</td>
      <td>soft</td>
      <td>max_pct_outliers=0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>MonthlyCharges</td>
      <td>outlier_iqr_z</td>
      <td>outlier_iqr_z</td>
      <td>1.0</td>
      <td>soft</td>
      <td>max_pct_outliers=0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>TotalCharges</td>
      <td>outlier_iqr_z</td>
      <td>outlier_iqr_z</td>
      <td>1.0</td>
      <td>soft</td>
      <td>max_pct_outliers=0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>tenure</td>
      <td>outlier_iqr_z</td>
      <td>outlier_iqr_z</td>
      <td>1.0</td>
      <td>soft</td>
      <td>max_pct_outliers=0.0</td>
    </tr>
  </tbody>
</table>
</div>
üßæ Appended diagnostics ‚Üí /Users/b/DATA/PROJECTS/Telco/_T2/Level_3/resources/reports/section2/section2_report.csv
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>section</th>
      <th>section_name</th>
      <th>check</th>
      <th>level</th>
      <th>status</th>
      <th>n_rules</th>
      <th>n_hard_rules</th>
      <th>n_soft_rules</th>
      <th>detail</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.3.7.4</td>
      <td>Rule confidence scores</td>
      <td>Assign confidence &amp; hardness to numeric rules</td>
      <td>info</td>
      <td>OK</td>
      <td>5</td>
      <td>0</td>
      <td>5</td>
      <td>rule_confidence_scores.csv under numeric_integ...</td>
      <td>2025-12-26 20:22:14.211935+00:00</td>
    </tr>
  </tbody>
</table>
</div>

# PART C | 2.3.8‚Äì2.3.14 üßÆ Model Readiness & Operational Hooks
print("\n2.3.8‚Äì2.3.14 üßÆ Model readiness & operational hooks")

# Assumes:
#   - df, NUMERIC_DIR, REPORTS_DIR, SECTION2_REPORT_PATH exist
#   - prior numeric artifacts already written by 2.3.x & 2.3.7.x
#   - CONFIG may exist as a dict (optional)

# ---------------------------------------------------------------------------
# Utility: safe loader for CSV ‚Üí DataFrame with a 'feature' column
# (still inline, no def)
# ---------------------------------------------------------------------------
# (We just repeat a tiny pattern; no functions)
# 2.3.8 üìö DQ rule catalog (joined with numeric profile)
print("\n2.3.8 üìö DQ rule catalog (joined with numeric profile)")

# --- 1) Load rule confidence artifact (safe) -------------------------------
rule_conf_path = NUMERIC_DIR / "rule_confidence_scores.csv"

try:
    if rule_conf_path.exists() and rule_conf_path.stat().st_size > 0:
        rule_conf_df = pd.read_csv(rule_conf_path)
    else:
        rule_conf_df = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {rule_conf_path} is empty or has no columns. Treating as no rules.")
    rule_conf_df = pd.DataFrame()

# --- 2) Load numeric profile (safe) ---------------------------------------
numeric_profile_path = NUMERIC_DIR / "numeric_profile_df.csv"

try:
    if numeric_profile_path.exists() and numeric_profile_path.stat().st_size > 0:
        numeric_profile_df_238 = pd.read_csv(numeric_profile_path)
    else:
        numeric_profile_df_238 = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {numeric_profile_path} is empty or has no columns. Skipping join.")
    numeric_profile_df_238 = pd.DataFrame()

# --- 3) Build DQ rule catalog ---------------------------------------------
if not rule_conf_df.empty and not numeric_profile_df_238.empty:
    if "column" in numeric_profile_df_238.columns:
        dq_rule_catalog_df = (
            numeric_profile_df_238
            .rename(columns={"column": "feature"})
            .merge(rule_conf_df, on="feature", how="left")
            .sort_values(["feature", "rule_type", "rule_id"])
            .reset_index(drop=True)
        )
    else:
        print("‚ö†Ô∏è numeric_profile_df_238 missing 'column' col; using rule_conf_df only.")
        dq_rule_catalog_df = rule_conf_df.copy()
else:
    dq_rule_catalog_df = rule_conf_df.copy()

dq_rule_catalog_path = NUMERIC_DIR / "dq_rule_catalog.csv"
tmp_238 = dq_rule_catalog_path.with_suffix(".tmp.csv")
dq_rule_catalog_df.to_csv(tmp_238, index=False)
os.replace(tmp_238, dq_rule_catalog_path)

print(f"üíæ Wrote DQ rule catalog ‚Üí {dq_rule_catalog_path}")

if not dq_rule_catalog_df.empty:
    print("\nüìä Data Quality Rule Catalog (head):")
    cols_preview = [
        "feature",
        "role" if "role" in dq_rule_catalog_df.columns else "feature",
        "rule_type",
        "rule_id",
        "confidence_score",
        "hard_vs_soft",
    ]
    cols_preview = [c for c in cols_preview if c in dq_rule_catalog_df.columns]
    display(dq_rule_catalog_df[cols_preview].head(30))
else:
    print("   (no rules to catalog)")

# --- 4) ‚ÄúDQ rules‚Äù tab in your report (aggregated view) -------------------
dq_rules_path = NUMERIC_DIR / "dq_rule_catalog.csv"

try:
    if dq_rules_path.exists() and dq_rules_path.stat().st_size > 0:
        dq_rules_df = pd.read_csv(dq_rules_path)
    else:
        dq_rules_df = pd.DataFrame()
except EmptyDataError:
    print(f"‚ö†Ô∏è {dq_rules_path} is empty or has no columns. Skipping aggregation.")
    dq_rules_df = pd.DataFrame()

if (
    not dq_rules_df.empty
    and {"feature", "rule_id", "confidence_score", "hard_vs_soft"}.issubset(dq_rules_df.columns)
):
    agg_rules_df = (
        dq_rules_df
        .groupby("feature", as_index=False)
        .agg(
            n_rules=("rule_id", "nunique"),
            max_hard_conf=(
                "confidence_score",
                lambda s: s[dq_rules_df.loc[s.index, "hard_vs_soft"] == "hard"].max()
            ),
            max_soft_conf=(
                "confidence_score",
                lambda s: s[dq_rules_df.loc[s.index, "hard_vs_soft"] == "soft"].max()
            ),
    )
        )
    print("\nüìä Aggregated DQ rules per feature (head):")
    display(agg_rules_df.head(20))
else:
    print("‚ö†Ô∏è Not enough columns / data to build aggregated DQ rules view.")

# TODO: add display and append?
print("‚úÖ base catalog complete")
```

Drift is in your **feature naming key** across artifacts. You are mixing **`column`** and **`feature`** and sometimes renaming the wrong way.

### The exact bug

In 2.3.8 you do this:

```python
numeric_profile_df_238.rename(columns={"column": "feature"}).merge(rule_conf_df, on="feature", how="left")
```

That implies `numeric_profile_df_238["column"]` contains the feature names.

But in your own earlier code (2.3.9) you treat `numeric_profile_df.csv` as already having `column` as the column name and you sometimes create `feature` from it. If `numeric_profile_df.csv` already has both `column` and `feature` or if `column` is not the actual identifier, your rename can silently create a ‚Äúfeature‚Äù column that does not match `rule_conf_df["feature"]`.

Result: joins go sparse or wrong. That is the ‚Äúdrift.‚Äù

### The tell

Your rule confidence output shows `feature = MonthlyCharges, TotalCharges, tenure, ...`.
If `numeric_profile_df.csv` uses a different naming convention (case, whitespace, renamed fields, or stores the identifier under `feature` already), your join keys diverge.

### Fix pattern (minimal, inline, no functions)

Make a single canonical key called `feature` in **both** dataframes, by:

1. choosing the best available identifier column
2. normalizing it the same way

Use this before the merge:

```python
# Canonicalize rule_conf_df key
if not rule_conf_df.empty:
    rule_conf_df["feature"] = rule_conf_df["feature"].astype("string").str.strip()

# Canonicalize numeric_profile_df_238 key
if not numeric_profile_df_238.empty:
    if "feature" in numeric_profile_df_238.columns:
        numeric_profile_df_238["feature"] = numeric_profile_df_238["feature"].astype("string").str.strip()
    elif "column" in numeric_profile_df_238.columns:
        numeric_profile_df_238["feature"] = numeric_profile_df_238["column"].astype("string").str.strip()
    else:
        numeric_profile_df_238["feature"] = pd.NA
```

Then merge without renaming the whole frame:

```python
dq_rule_catalog_df = (
    numeric_profile_df_238
    .merge(rule_conf_df, on="feature", how="left")
    .sort_values(["feature", "rule_type", "rule_id"], na_position="last")
    .reset_index(drop=True)
)
```

### How to prove it in 10 seconds

Right before the merge, print set overlap:

```python
a = set(rule_conf_df["feature"].dropna().astype(str))
b = set(numeric_profile_df_238["feature"].dropna().astype(str))
print("rule_conf only:", len(a - b))
print("profile only:", len(b - a))
print("overlap:", len(a & b))
```

If overlap is low, your drift is naming, not math.

> üí°üí° Also: STOP using `rename(columns={"column":"feature"})` here.
> Create `feature` explicitly and keep `column` intact. That prevents accidental identifier swaps.
