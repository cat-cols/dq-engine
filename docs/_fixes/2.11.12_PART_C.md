
```py
# 2.11.12â€“2.11.13 | PART C/D ðŸ“Š Relationship Dashboard & Feature Readiness
print("\n2.11D ðŸ“Š Relationship Dashboard & Feature Readiness")

import os
import json
import numpy as np
import pandas as pd
from pathlib import Path
from pandas.api.types import is_numeric_dtype, is_bool_dtype
import matplotlib.pyplot as plt

# ------------------------------------------------------------------------------
# Shared: Section 2 reports dir + figures root for 2.11
# ------------------------------------------------------------------------------

if "sec2_reports_dir_210" in globals():
    section2_reports_dir_211 = sec2_reports_dir_210
elif "sec2_reports_dir" in globals():
    section2_reports_dir_211 = sec2_reports_dir
elif "REPORTS_DIR" in globals():
    section2_reports_dir_211 = (REPORTS_DIR / "section2").resolve()
elif "PROJECT_ROOT" in globals():
    section2_reports_dir_211 = (PROJECT_ROOT / "resources" / "reports" / "section2").resolve()
else:
    section2_reports_dir_211 = Path("resources/reports/section2").resolve()
section2_reports_dir_211.mkdir(parents=True, exist_ok=True)

if "FIGURES_DIR" in globals():
    interactions_fig_root_211 = (FIGURES_DIR / "2_11_interactions").resolve()
elif "PROJECT_ROOT" in globals():
    interactions_fig_root_211 = (PROJECT_ROOT / "resources" / "figures" / "2_11_interactions").resolve()
else:
    interactions_fig_root_211 = Path("resources/figures/2_11_interactions").resolve()
interactions_fig_root_211.mkdir(parents=True, exist_ok=True)

# Reuse known subdirs (may have been created in earlier 2.11B/C cells)
interaction_heatmaps_dir_2116 = (interactions_fig_root_211 / "interaction_heatmaps").resolve()
cat_num_boxplots_dir_2118 = (interactions_fig_root_211 / "cat_num_boxplots").resolve()
cat_cat_heatmaps_dir_2119 = (interactions_fig_root_211 / "cat_cat_heatmaps").resolve()

# We'll also anticipate temporal & drift plot dirs (2.11.10â€“2.11.11)
trend_plots_dir_21110 = (interactions_fig_root_211 / "trend_plots").resolve()
feature_drift_plots_dir_21111 = (interactions_fig_root_211 / "feature_drift_plots").resolve()

# Ensure they exist if used later
for _d in [
    interaction_heatmaps_dir_2116,
    cat_num_boxplots_dir_2118,
    cat_cat_heatmaps_dir_2119,
    trend_plots_dir_21110,
    feature_drift_plots_dir_21111,
]:
    _d.mkdir(parents=True, exist_ok=True)


# ==============================================================================
# 2.11.12 | Relationship Dashboard Index
# ==============================================================================

print("2.11.12 â–¶ Relationship dashboard index")

default_rel_dash_cfg_21112 = {
    "ENABLED": True,
    "OUTPUT_FILE": "feature_relationship_dashboard_index.csv",
}
rel_dash_cfg_21112 = _get_cfg_210("RELATIONSHIP_DASHBOARD", default_rel_dash_cfg_21112)

rel_dash_enabled_21112 = bool(rel_dash_cfg_21112.get("ENABLED", True))
rel_dash_output_file_21112 = str(
    rel_dash_cfg_21112.get("OUTPUT_FILE", "feature_relationship_dashboard_index.csv")
)

rel_dash_output_path_21112 = section2_reports_dir_211 / rel_dash_output_file_21112

dashboard_rows_21112 = []
n_artifacts_21112 = 0

if not rel_dash_enabled_21112:
    status_21112 = "SKIP"
    print("â„¹ï¸ RELATIONSHIP_DASHBOARD.ENABLED is False; skipping 2.11.12.")
else:
    # NOTE: We reference canonical filenames from earlier sections.
    # Even if some files were not generated (e.g., sections skipped),
    # this index still documents their intended locations.

    def _add_artifact(section_id, artifact_type, name, desc, path_obj):
        """Helper to append an artifact record."""
        nonlocal dashboard_rows_21112
        dashboard_rows_21112.append(
            {
                "section": section_id,
                "artifact_type": artifact_type,
                "artifact_name": name,
                "description": desc,
                "path": str(path_obj),
            }
        )

    # --- 2.11A: Correlation & Association Clustering -------------------------
    # 2.11.1
    _add_artifact(
        "2.11.1",
        "csv",
        "numeric_correlation_matrix.csv",
        "Long-form numeric correlation matrix (Pearson/Spearman/Kendall) with collinearity flags.",
        section2_reports_dir_211 / "numeric_correlation_matrix.csv",
    )
    _add_artifact(
        "2.11.1",
        "figure",
        "corr_heatmap.png",
        "Heatmap of numeric correlations.",
        interactions_fig_root_211 / "corr_heatmap.png",
    )

    # 2.11.2
    _add_artifact(
        "2.11.2",
        "csv",
        "correlation_clusters.csv",
        "Cluster assignments for numeric features based on correlation distance.",
        section2_reports_dir_211 / "correlation_clusters.csv",
    )
    _add_artifact(
        "2.11.2",
        "figure",
        "corr_dendrogram.png",
        "Dendrogram of correlation-based feature clustering.",
        interactions_fig_root_211 / "corr_dendrogram.png",
    )

    # 2.11.3
    _add_artifact(
        "2.11.3",
        "csv",
        "category_association_matrix.csv",
        "CramÃ©râ€™s V association matrix for categorical features.",
        section2_reports_dir_211 / "category_association_matrix.csv",
    )
    _add_artifact(
        "2.11.3",
        "csv",
        "theils_u_matrix.csv",
        "Theilâ€™s U directional predictive power matrix for categorical features.",
        section2_reports_dir_211 / "theils_u_matrix.csv",
    )

    # 2.11.4
    _add_artifact(
        "2.11.4",
        "csv",
        "chi2_association_results.csv",
        "Ï‡Â² independence test results for categorical feature pairs.",
        section2_reports_dir_211 / "chi2_association_results.csv",
    )

    # 2.11.5
    _add_artifact(
        "2.11.5",
        "figure",
        "association_heatmap.png",
        "Heatmap of categorical associations.",
        interactions_fig_root_211 / "association_heatmap.png",
    )
    _add_artifact(
        "2.11.5",
        "figure",
        "association_graph.png",
        "Graph network visualization of categorical associations.",
        interactions_fig_root_211 / "association_graph.png",
    )

    # --- 2.11B: Feature Interactions & Non-Linear Relationships -------------
    # 2.11.6
    _add_artifact(
        "2.11.6",
        "json",
        "interaction_map.json",
        "Global interaction map with key feature pairs and target-rate grids.",
        section2_reports_dir_211 / "interaction_map.json",
    )
    _add_artifact(
        "2.11.6",
        "dir",
        "interaction_heatmaps/",
        "2D heatmaps of target rate across interaction grids.",
        interaction_heatmaps_dir_2116,
    )

    # 2.11.7
    _add_artifact(
        "2.11.7",
        "csv",
        "continuous_interactions.csv",
        "ContinuousÃ—continuous interaction metrics (target-rate variance over 2D bins).",
        section2_reports_dir_211 / "continuous_interactions.csv",
    )
    _add_artifact(
        "2.11.7",
        "figure",
        "pairplots.png",
        "Scatter matrix of top numericâ€“numeric pairs colored by target.",
        interactions_fig_root_211 / "pairplots.png",
    )

    # 2.11.8
    _add_artifact(
        "2.11.8",
        "csv",
        "cat_num_interaction_summary.csv",
        "Summary of numeric behavior (mean/median) and target rate across categories.",
        section2_reports_dir_211 / "cat_num_interaction_summary.csv",
    )
    _add_artifact(
        "2.11.8",
        "dir",
        "cat_num_boxplots/",
        "Boxplots of numeric features by categories.",
        cat_num_boxplots_dir_2118,
    )

    # 2.11.9
    _add_artifact(
        "2.11.9",
        "csv",
        "cat_cat_interaction_summary.csv",
        "Cross-tab summary of categoryÃ—category segments with target rate.",
        section2_reports_dir_211 / "cat_cat_interaction_summary.csv",
    )
    _add_artifact(
        "2.11.9",
        "dir",
        "cat_cat_heatmaps/",
        "Heatmaps for categoricalÃ—categorical interactions vs target.",
        cat_cat_heatmaps_dir_2119,
    )

    # --- 2.11C: Temporal & Drift (2.11.10â€“2.11.11, anticipated) -------------
    _add_artifact(
        "2.11.10",
        "csv",
        "temporal_trend_summary.csv",
        "Time-indexed summary of churn and key metrics.",
        section2_reports_dir_211 / "temporal_trend_summary.csv",
    )
    _add_artifact(
        "2.11.10",
        "dir",
        "trend_plots/",
        "Temporal trend plots for churn and key metrics.",
        trend_plots_dir_21110,
    )

    _add_artifact(
        "2.11.11",
        "csv",
        "feature_drift_summary.csv",
        "Feature-level drift metrics (e.g., PSI/KS) across time periods.",
        section2_reports_dir_211 / "feature_drift_summary.csv",
    )
    _add_artifact(
        "2.11.11",
        "dir",
        "feature_drift_plots/",
        "Drift plots for selected predictors.",
        feature_drift_plots_dir_21111,
    )

    # --- Materialized relationship readiness file for this part --------------
    _add_artifact(
        "2.11.13",
        "csv",
        "feature_relationship_readiness.csv",
        "Per-feature relationship readiness score combining association, interactions, and drift.",
        section2_reports_dir_211 / "feature_relationship_readiness.csv",
    )

    # Build dashboard index DataFrame and write atomically
    if dashboard_rows_21112:
        rel_dash_df_21112 = pd.DataFrame(dashboard_rows_21112)
        tmp_21112 = rel_dash_output_path_21112.with_suffix(".tmp.csv")
        rel_dash_df_21112.to_csv(tmp_21112, index=False)
        os.replace(tmp_21112, rel_dash_output_path_21112)
        n_artifacts_21112 = int(rel_dash_df_21112.shape[0])
    else:
        rel_dash_df_21112 = pd.DataFrame(
            columns=["section", "artifact_type", "artifact_name", "description", "path"]
        )
        n_artifacts_21112 = 0

    status_21112 = "OK" if n_artifacts_21112 > 0 else "WARN"

# Diagnostics row for 2.11.12
sec2_chunk_21112 = pd.DataFrame(
    {
        "section": ["2.11.12"],
        "section_name": ["Relationship dashboard index"],
        "check": ["Index key correlation, interaction, temporal, and drift artifacts for navigation"],
        "level": ["info"],
        "n_artifacts": [n_artifacts_21112],
        "status": [status_21112],
        "detail": [str(rel_dash_output_path_21112)],
    }
)

if "_append_sec2" in globals() and callable(_append_sec2):
    _append_sec2(sec2_chunk_21112)
else:
    print("â„¹ï¸ _append_sec2 not available; 2.11.12 diagnostics not appended to Section 2 report.")


# ==============================================================================
# 2.11.13 | Feature Relationship Readiness Score
# ==============================================================================

print("2.11.13 â–¶ Feature relationship readiness score")

default_rel_ready_cfg_21113 = {
    "ENABLED": True,
    "WEIGHTS": {
        "ASSOCIATION_STRENGTH": 0.40,
        "INTERACTION_VALUE": 0.35,
        "TEMPORAL_STABILITY": 0.25,
    },
    "OUTPUT_FILE": "feature_relationship_readiness.csv",
}
rel_ready_cfg_21113 = _get_cfg_210("FEATURE_RELATIONSHIP_READINESS", default_rel_ready_cfg_21113)

rel_ready_enabled_21113 = bool(rel_ready_cfg_21113.get("ENABLED", True))
rel_ready_weights_raw_21113 = rel_ready_cfg_21113.get("WEIGHTS", {})
rel_ready_output_file_21113 = str(
    rel_ready_cfg_21113.get("OUTPUT_FILE", "feature_relationship_readiness.csv")
)
rel_ready_output_path_21113 = section2_reports_dir_211 / rel_ready_output_file_21113

if not rel_ready_enabled_21113:
    print("â„¹ï¸ FEATURE_RELATIONSHIP_READINESS.ENABLED is False; skipping 2.11.13 scoring.")
    status_21113 = "SKIP"
    sec2_chunk_21113 = pd.DataFrame(
        {
            "section": ["2.11.13"],
            "section_name": ["Feature relationship readiness score"],
            "check": [
                "Score features based on association strength, interaction value, and temporal stability"
            ],
            "level": ["info"],
            "n_features_scored": [0],
            "n_relationship_ready": [0],
            "n_needs_monitoring": [0],
            "status": [status_21113],
            "detail": [str(rel_ready_output_path_21113)],
        }
    )
    if "_append_sec2" in globals() and callable(_append_sec2):
        _append_sec2(sec2_chunk_21113)
    else:
        print("â„¹ï¸ _append_sec2 not available; 2.11.13 diagnostics not appended to Section 2 report.")
else:
    # ----------------------------------------------------------------------
    # Normalize weights
    # ----------------------------------------------------------------------
    raw_w = {
        "ASSOCIATION_STRENGTH": float(rel_ready_weights_raw_21113.get("ASSOCIATION_STRENGTH", 0.40)),
        "INTERACTION_VALUE": float(rel_ready_weights_raw_21113.get("INTERACTION_VALUE", 0.35)),
        "TEMPORAL_STABILITY": float(rel_ready_weights_raw_21113.get("TEMPORAL_STABILITY", 0.25)),
    }
    total_w = sum(v for v in raw_w.values() if v > 0)
    if total_w <= 0:
        active_keys = list(raw_w.keys())
        weights_21113 = {k: 1.0 / len(active_keys) for k in active_keys}
    else:
        weights_21113 = {k: (v / total_w) if v > 0 else 0.0 for k, v in raw_w.items()}

    # ----------------------------------------------------------------------
    # Association strength per feature (reuse 2.10.4â€“2.10.6 if available)
    # ----------------------------------------------------------------------
    assoc_strength_21113 = {}
    if "df_clean" not in globals():
        raise RuntimeError("âŒ df_clean not found in globals(); 2.11.13 requires the cleaned dataset.")
    for c in df_clean.columns:
        assoc_strength_21113[c] = 0.0

    # From numericâ€“numeric correlations
    if (
        "bivar_num_df_2104" in globals()
        and isinstance(bivar_num_df_2104, pd.DataFrame)
        and not bivar_num_df_2104.empty
    ):
        df_bn = bivar_num_df_2104
        for _, row in df_bn.iterrows():
            f1 = row.get("feature_1")
            f2 = row.get("feature_2")
            pearson_r = row.get("pearson_r", np.nan)
            spearman_rho = row.get("spearman_rho", np.nan)
            vals = [v for v in [pearson_r, spearman_rho] if not np.isnan(v)]
            if not vals:
                continue
            strength = float(np.max(np.abs(vals)))
            if f1 in assoc_strength_21113:
                assoc_strength_21113[f1] = max(assoc_strength_21113[f1], strength)
            if f2 in assoc_strength_21113:
                assoc_strength_21113[f2] = max(assoc_strength_21113[f2], strength)

    # From categoricalâ€“categorical associations
    if (
        "bivar_cat_df_2105" in globals()
        and isinstance(bivar_cat_df_2105, pd.DataFrame)
        and not bivar_cat_df_2105.empty
    ):
        df_bc = bivar_cat_df_2105
        for _, row in df_bc.iterrows():
            a = row.get("feature_a")
            b = row.get("feature_b")
            cv = row.get("cramers_v", np.nan)
            tu_ab = row.get("theils_u_ab", np.nan)
            tu_ba = row.get("theils_u_ba", np.nan)
            vals = [v for v in [cv, tu_ab, tu_ba] if not np.isnan(v)]
            if not vals:
                continue
            strength = float(np.max(vals))  # already 0â€“1
            if a in assoc_strength_21113:
                assoc_strength_21113[a] = max(assoc_strength_21113[a], strength)
            if b in assoc_strength_21113:
                assoc_strength_21113[b] = max(assoc_strength_21113[b], strength)

    # From categoricalâ€“numeric association labels
    if (
        "bivar_cross_df_2106" in globals()
        and isinstance(bivar_cross_df_2106, pd.DataFrame)
        and not bivar_cross_df_2106.empty
    ):
        df_bcros = bivar_cross_df_2106
        for _, row in df_bcros.iterrows():
            cat_col = row.get("categorical_feature")
            num_col = row.get("numeric_feature")
            label = str(row.get("effect_label", "Unknown"))

            if label.startswith("Strong"):
                strength = 0.9
            elif label.startswith("Moderate"):
                strength = 0.7
            elif label.startswith("Weak"):
                strength = 0.4
            elif label == "Not significant":
                strength = 0.1
            else:
                strength = 0.3

            if cat_col in assoc_strength_21113:
                assoc_strength_21113[cat_col] = max(assoc_strength_21113[cat_col], strength)
            if num_col in assoc_strength_21113:
                assoc_strength_21113[num_col] = max(assoc_strength_21113[num_col], strength)

    # clamp to [0,1]
    for k in assoc_strength_21113:
        v = assoc_strength_21113[k]
        assoc_strength_21113[k] = float(max(0.0, min(1.0, v)))

    # ----------------------------------------------------------------------
    # Interaction value per feature (from 2.11.6â€“2.11.7 if available)
    # ----------------------------------------------------------------------
    interaction_value_21113 = {c: 0.0 for c in df_clean.columns}

    # 2.11.6 interaction map
    if "interaction_map_obj_2116" in globals():
        map_obj = interaction_map_obj_2116
        if isinstance(map_obj, dict) and "pairs" in map_obj:
            for rec in map_obj["pairs"]:
                f1 = rec.get("feature_1")
                f2 = rec.get("feature_2")
                s = float(rec.get("interaction_strength", 0.0))
                s = max(0.0, min(1.0, s))
                if f1 in interaction_value_21113:
                    interaction_value_21113[f1] = max(interaction_value_21113[f1], s)
                if f2 in interaction_value_21113:
                    interaction_value_21113[f2] = max(interaction_value_21113[f2], s)

    # 2.11.7 continuous_interactions.csv â†’ cont_cont_df_2117
    if "cont_cont_df_2117" in globals() and isinstance(cont_cont_df_2117, pd.DataFrame):
        df_ci = cont_cont_df_2117
        if "interaction_strength" in df_ci.columns:
            for _, row in df_ci.iterrows():
                f1 = row.get("feature_1")
                f2 = row.get("feature_2")
                s = float(row.get("interaction_strength", 0.0))
                s = max(0.0, min(1.0, s))
                if f1 in interaction_value_21113:
                    interaction_value_21113[f1] = max(interaction_value_21113[f1], s)
                if f2 in interaction_value_21113:
                    interaction_value_21113[f2] = max(interaction_value_21113[f2], s)

    # clamp to [0,1]
    for k in interaction_value_21113:
        v = interaction_value_21113[k]
        interaction_value_21113[k] = float(max(0.0, min(1.0, v)))

    # ----------------------------------------------------------------------
    # Temporal stability per feature (from drift summary if available)
    # ----------------------------------------------------------------------
    # We treat drift_score â‰ˆ PSI-like in [0,1+]; stability ~ 1 - min(drift_score / 0.5, 1).
    temporal_stability_21113 = {c: 0.5 for c in df_clean.columns}  # neutral baseline
    drift_scores_raw_21113 = {}

    for cand_name in [
        "feature_drift_df_21111",
        "feature_drift_df",
        "feature_drift_summary_df",
    ]:
        if cand_name in globals():
            cand = globals()[cand_name]
            if isinstance(cand, pd.DataFrame) and "feature" in cand.columns:
                drift_col = None
                for col in cand.columns:
                    cl = col.lower()
                    if "psi" in cl or "drift_score" in cl or "max_psi" in cl:
                        drift_col = col
                        break
                if drift_col is not None:
                    for _, row in cand.iterrows():
                        f = str(row["feature"])
                        try:
                            drift_scores_raw_21113[f] = float(row[drift_col])
                        except Exception:
                            continue
                break  # first usable drift table wins

    for f in df_clean.columns:
        if f in drift_scores_raw_21113:
            d = drift_scores_raw_21113[f]
            if np.isnan(d):
                temporal_stability_21113[f] = 0.5
            else:
                # scale: 0 drift -> 1.0, >=0.5 psi -> 0.0
                d_norm = min(max(d, 0.0), 0.5)
                s = 1.0 - (d_norm / 0.5)
                temporal_stability_21113[f] = float(max(0.0, min(1.0, s)))
        else:
            # No drift info: slightly optimistic neutral
            temporal_stability_21113[f] = 0.6

    # ----------------------------------------------------------------------
    # Score per feature
    # ----------------------------------------------------------------------
    rows_21113 = []
    all_features_21113 = list(df_clean.columns)

    for feat in all_features_21113:
        assoc_score = assoc_strength_21113.get(feat, 0.0)
        inter_score = interaction_value_21113.get(feat, 0.0)
        temp_stab_score = temporal_stability_21113.get(feat, 0.6)

        # Combined index in [0,1]
        idx_0_1 = (
            weights_21113["ASSOCIATION_STRENGTH"] * assoc_score
            + weights_21113["INTERACTION_VALUE"] * inter_score
            + weights_21113["TEMPORAL_STABILITY"] * temp_stab_score
        )
        idx_0_1 = max(0.0, min(1.0, idx_0_1))
        idx_0_100 = float(round(idx_0_1 * 100.0, 1))

        # Banding
        if idx_0_100 >= 80.0:
            band = "Relationship_Ready"
        elif idx_0_100 >= 60.0:
            band = "Needs_Monitoring"
        else:
            band = "High_Drift_or_Weak_Relationship"

        rows_21113.append(
            {
                "feature": feat,
                "score_association_strength_0_100": round(assoc_score * 100.0, 1),
                "score_interaction_value_0_100": round(inter_score * 100.0, 1),
                "score_temporal_stability_0_100": round(temp_stab_score * 100.0, 1),
                "relationship_readiness_index_0_100": idx_0_100,
                "relationship_band": band,
            }
        )

    # ----------------------------------------------------------------------
    # Build DataFrame & write atomically
    # ----------------------------------------------------------------------
    rel_ready_df_21113 = pd.DataFrame(rows_21113).sort_values(
        "relationship_readiness_index_0_100", ascending=False
    )

    tmp_21113 = rel_ready_output_path_21113.with_suffix(".tmp.csv")
    rel_ready_df_21113.to_csv(tmp_21113, index=False)
    os.replace(tmp_21113, rel_ready_output_path_21113)

    n_features_scored_21113 = int(rel_ready_df_21113.shape[0])
    n_relationship_ready_21113 = int(
        (rel_ready_df_21113["relationship_band"] == "Relationship_Ready").sum()
    )
    n_needs_monitoring_21113 = int(
        (rel_ready_df_21113["relationship_band"] == "Needs_Monitoring").sum()
    )
    n_high_drift_21113 = int(
        (rel_ready_df_21113["relationship_band"] == "High_Drift_or_Weak_Relationship").sum()
    )

    if n_features_scored_21113 == 0:
        status_21113 = "WARN"
    else:
        # If almost everything is high-drift/weak, flag as WARN/FAIL
        frac_high = n_high_drift_21113 / max(1, n_features_scored_21113)
        if frac_high <= 0.5:
            status_21113 = "OK"
        elif frac_high <= 0.8:
            status_21113 = "WARN"
        else:
            status_21113 = "FAIL"

    # ----------------------------------------------------------------------
    # Diagnostics row for 2.11.13
    # ----------------------------------------------------------------------
    sec2_chunk_21113 = pd.DataFrame(
        {
            "section": ["2.11.13"],
            "section_name": ["Feature relationship readiness score"],
            "check": [
                "Score features based on association strength, interaction value, and temporal stability"
            ],
            "level": ["info"],
            "n_features_scored": [n_features_scored_21113],
            "n_relationship_ready": [n_relationship_ready_21113],
            "n_needs_monitoring": [n_needs_monitoring_21113],
            "status": [status_21113],
            "detail": [str(rel_ready_output_path_21113)],
        }
    )

    if "_append_sec2" in globals() and callable(_append_sec2):
        _append_sec2(sec2_chunk_21113)
    else:
        print("â„¹ï¸ _append_sec2 not available; 2.11.13 diagnostics not appended to Section 2 report.")

print("âœ… 2.11D complete â€” dashboard index and relationship readiness scores generated.")

Cell In[425], line 88
    nonlocal dashboard_rows_21112
    ^
SyntaxError: no binding for nonlocal 'dashboard_rows_21112' found
```

---
---

Nice, this oneâ€™s easy to fix. The error:

```text
SyntaxError: no binding for nonlocal 'dashboard_rows_21112' found
```

happens because `nonlocal` only works *inside another function*, not at the top level of a notebook cell. Here, `dashboard_rows_21112` is a **global** list, so you donâ€™t need `nonlocal` at all.

You only need to change the helper function in 2.11.12.

### ðŸ”§ Patch

Find this part:

```python
    def _add_artifact(section_id, artifact_type, name, desc, path_obj):
        """Helper to append an artifact record."""
        nonlocal dashboard_rows_21112
        dashboard_rows_21112.append(
            {
                "section": section_id,
                "artifact_type": artifact_type,
                "artifact_name": name,
                "description": desc,
                "path": str(path_obj),
            }
        )
```

and replace it with:

```python
    def _add_artifact(section_id, artifact_type, name, desc, path_obj):
        """Helper to append an artifact record."""
        # dashboard_rows_21112 is defined in the outer (global) scope;
        # we only mutate it (append), so no global/nonlocal is needed.
        dashboard_rows_21112.append(
            {
                "section": section_id,
                "artifact_type": artifact_type,
                "artifact_name": name,
                "description": desc,
                "path": str(path_obj),
            }
        )
```

Thatâ€™s it â€” no other changes needed. Then rerun the whole 2.11.12â€“2.11.13 cell and you should get:

```text
2.11.12 â–¶ Relationship dashboard index
2.11.13 â–¶ Feature relationship readiness score
âœ… 2.11D complete â€” dashboard index and relationship readiness scores generated.
```

> If anything else explodes after that (e.g., missing bivar_* frames or drift tables), harden those branches..
