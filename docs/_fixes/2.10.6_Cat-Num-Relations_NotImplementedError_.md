
># NotImplementedError: infer_objects is not implemented for MultiIndex. Use index.to_frame().infer_objects() instead.

```py
# 2.10.6 | Categoricalâ€“Numeric Relationships
print("2.10.6 Categoricalâ€“numeric relationships")

default_bivar_cross_cfg = {
    "ENABLED": True,
    "TESTS": ["anova", "kruskal"],
    "MUTUAL_INFORMATION": True,
    "TARGETS": [],  # optional: for MI focus on specific targets (kept generic here)
    "OUTPUT_FILE": "bivariate_cross_association.csv",
}
bivar_cross_cfg = _get_cfg_210("BIVARIATE_CROSS", default_bivar_cross_cfg)

bivar_cross_enabled_2106 = bool(bivar_cross_cfg.get("ENABLED", True))
bivar_cross_tests_2106 = list(bivar_cross_cfg.get("TESTS", ["anova", "kruskal"]))
bivar_cross_use_mi_2106 = bool(bivar_cross_cfg.get("MUTUAL_INFORMATION", True))
bivar_cross_targets_2106 = list(bivar_cross_cfg.get("TARGETS", []))
bivar_cross_output_file_2106 = str(
    bivar_cross_cfg.get("OUTPUT_FILE", "bivariate_cross_association.csv")
)

bivar_cross_matrix_path_2106 = section2_reports_dir_210 / bivar_cross_output_file_2106

bivar_cross_df_2106 = pd.DataFrame()
n_pairs_2106 = 0
n_significant_2106 = 0

# Try to import SciPy for real p-values; fall back to approximate F-like statistic otherwise
try:
    from scipy.stats import f_oneway as _f_oneway_2106, kruskal as _kruskal_2106
    _HAS_SCIPY_2106 = True
except Exception:
    _HAS_SCIPY_2106 = False

def _all_groups_constant_2106(groups) -> bool:
    """Return True if every group has zero variance (all values identical)."""
    for g in groups:
        if g.size == 0:
            continue
        if not np.allclose(g, g[0]):
            return False
    return True

def _qcut_codes_2106(s: pd.Series, q: int = 5) -> pd.Series:
    """Return quantile-binned labels as strings (for MI)."""
    try:
        bins = pd.qcut(s, q=q, duplicates="drop")
        return bins.astype("str")
    except Exception:
        # fall back to all-NaN series on failure
        return pd.Series(index=s.index, data=np.nan)

def _entropy_generic_2106(s: pd.Series) -> float:
    """Shannon entropy H(s) in bits for a discrete series."""
    # Explicitly follow pandas' suggested pattern
    result = s.value_counts(normalize=True, dropna=True)

    # Future-proof: ensure index dtype inference happens explicitly
    if hasattr(result.index, "infer_objects"):
        result.index = result.index.infer_objects()

    if result.empty:
        return np.nan

    p = result.values.astype(float)
    with np.errstate(divide="ignore", invalid="ignore"):
        return float(-(p * np.log2(p + 1e-15)).sum())

# OLD  _entropy_generic_2106
    # def _entropy_generic_2106(s: pd.Series) -> float:
    #     """Shannon entropy H(s) in bits for a discrete series."""
    #     vc = s.value_counts(normalize=True, dropna=True)

    #     # Future-proof: ensure index dtype inference happens explicitly
    #     if hasattr(vc.index, "infer_objects"):
    #         vc.index = vc.index.infer_objects()

    #     if vc.empty:
    #         return np.nan
    #     p = vc.values.astype(float)
    #     with np.errstate(divide="ignore", invalid="ignore"):
    #         return float(-(p * np.log2(p + 1e-15)).sum())

# OLD  _entropy_generic_2106
    # def _entropy_generic_2106(s: pd.Series) -> float:
    #     """Shannon entropy H(s) in bits for a discrete series."""
    #     # value_counts(normalize=True) gives probabilities directly
    #     vc = s.value_counts(normalize=True, dropna=True)
    #     if vc.empty:
    #         return np.nan
    #     p = vc.values.astype(float)
    #     with np.errstate(divide="ignore", invalid="ignore"):
    #         return float(-(p * np.log2(p + 1e-15)).sum())

def _joint_entropy_2106(x: pd.Series, y: pd.Series) -> float:
    """Joint entropy H(X,Y) in bits."""
    df_xy = pd.DataFrame({"x": x, "y": y}).dropna()
    if df_xy.empty:
        return np.nan

    result = df_xy.value_counts(normalize=True)

    if hasattr(result.index, "infer_objects"):
        result.index = result.index.infer_objects()

    if result.empty:
        return np.nan

    p = result.values.astype(float)
    with np.errstate(divide="ignore", invalid="ignore"):
        return float(-(p * np.log2(p + 1e-15)).sum())

# OLD _joint_entropy_2106
    # def _joint_entropy_2106(x: pd.Series, y: pd.Series) -> float:
    #     """Joint entropy H(X,Y) in bits."""
    #     df_xy = pd.DataFrame({"x": x, "y": y}).dropna()
    #     if df_xy.empty:
    #         return np.nan
    #     vc = df_xy.value_counts(normalize=True)
    #     if vc.empty:
    #         return np.nan
    #     p = vc.values.astype(float)
    #     with np.errstate(divide="ignore", invalid="ignore"):
    #         return float(-(p * np.log2(p + 1e-15)).sum())

def _mutual_information_2106(x: pd.Series, y: pd.Series) -> float:
    """Mutual information I(X;Y) in bits for discrete/categorical X,Y."""
    df_xy = pd.DataFrame({"x": x, "y": y}).dropna()
    if df_xy.empty:
        return np.nan
    h_x = _entropy_generic_2106(df_xy["x"])
    h_y = _entropy_generic_2106(df_xy["y"])
    h_xy = _joint_entropy_2106(df_xy["x"], df_xy["y"])
    if any(np.isnan(v) for v in (h_x, h_y, h_xy)):
        return np.nan
    mi = h_x + h_y - h_xy
    # Numerical noise can make MI slightly negative; clamp to 0
    return float(max(0.0, mi))

if bivar_cross_enabled_2106:
    # Numeric features (reuse 2.10.1 if available)
    if (
        "num_summary_df_2101" in globals()
        and isinstance(num_summary_df_2101, pd.DataFrame)
        and not num_summary_df_2101.empty
    ):
        numeric_cols_2106 = [
            c for c in num_summary_df_2101["feature"] if c in df_clean.columns
        ]
    else:
        from pandas.api.types import is_numeric_dtype, is_bool_dtype

        numeric_cols_2106 = [
            c
            for c in df_clean.columns
            if is_numeric_dtype(df_clean[c]) and not is_bool_dtype(df_clean[c])
        ]

    # Categorical features (reuse 2.10.2 if available)
    if (
        "cat_summary_df_2102" in globals()
        and isinstance(cat_summary_df_2102, pd.DataFrame)
        and not cat_summary_df_2102.empty
    ):
        categorical_cols_2106 = [
            c for c in cat_summary_df_2102["feature"] if c in df_clean.columns
        ]
    else:
        from pandas.api.types import is_numeric_dtype, is_bool_dtype

        categorical_cols_2106 = [
            c
            for c in df_clean.columns
            if (not is_numeric_dtype(df_clean[c])) or is_bool_dtype(df_clean[c])
        ]

    rows_2106 = []
    for cat_col in categorical_cols_2106:
        for num_col in numeric_cols_2106:
            s_cat = df_clean[cat_col]
            s_num = df_clean[num_col]
            valid = s_cat.notna() & s_num.notna()
            if valid.sum() < 3:
                continue

            s_cat_valid = s_cat[valid].astype("object")
            s_num_valid = s_num[valid].astype(float)

            # group arrays for tests
            groups = [
                s_num_valid[s_cat_valid == level].values
                for level in s_cat_valid.unique()
            ]
            groups = [g for g in groups if g.size > 0]

            test_method_used = None
            test_stat = np.nan
            p_value = np.nan

            # if "anova" in bivar_cross_tests_2106 and len(groups) >= 2:
            #     test_method_used = "anova"
            #     if _HAS_SCIPY_2106:
            #         try:
            #             stat, p = _f_oneway_2106(*groups)
            #             test_stat = float(stat)
            #             p_value = float(p)
            #         except Exception:
            #             test_stat = np.nan
            #             p_value = np.nan
            #     else:
            #         # simple F-like ratio as placeholder when SciPy missing
            #         grand_mean = s_num_valid.mean()
            #         ss_between = sum(
            #             g.size * (g.mean() - grand_mean) ** 2 for g in groups
            #         )
            #         ss_within = sum(((g - g.mean()) ** 2).sum() for g in groups)
            #         df_between = len(groups) - 1
            #         df_within = max(1, valid.sum() - len(groups))
            #         ms_between = ss_between / df_between if df_between > 0 else np.nan
            #         ms_within = ss_within / df_within if df_within > 0 else np.nan
            #         test_stat = (
            #             (ms_between / ms_within)
            #             if (ms_between > 0 and ms_within > 0)
            #             else np.nan
            #         )
            #         p_value = np.nan  # cannot compute exact p without SciPy

            # NEW
            if "anova" in bivar_cross_tests_2106 and len(groups) >= 2:
                test_method_used = "anova"

                # Skip ANOVA when all groups are constant to avoid ConstantInputWarning
                if _all_groups_constant_2106(groups):
                    test_stat = np.nan
                    p_value = np.nan
                elif _HAS_SCIPY_2106:
                    try:
                        stat, p = _f_oneway_2106(*groups)
                        test_stat = float(stat)
                        p_value = float(p)
                    except Exception:
                        test_stat = np.nan
                        p_value = np.nan
                else:
                    # simple F-like ratio as placeholder when SciPy missing
                    grand_mean = s_num_valid.mean()
                    ss_between = sum(
                        g.size * (g.mean() - grand_mean) ** 2 for g in groups
                    )
                    ss_within = sum(((g - g.mean()) ** 2).sum() for g in groups)
                    df_between = len(groups) - 1
                    df_within = max(1, valid.sum() - len(groups))
                    ms_between = ss_between / df_between if df_between > 0 else np.nan
                    ms_within = ss_within / df_within if df_within > 0 else np.nan
                    test_stat = (
                        (ms_between / ms_within)
                        if (ms_between > 0 and ms_within > 0)
                        else np.nan
                    )
                    p_value = np.nan  # cannot compute exact p without SciPy

            elif "kruskal" in bivar_cross_tests_2106 and len(groups) >= 2:
                test_method_used = "kruskal"
                if _HAS_SCIPY_2106:
                    try:
                        stat, p = _kruskal_2106(*groups)
                        test_stat = float(stat)
                        p_value = float(p)
                    except Exception:
                        test_stat = np.nan
                        p_value = np.nan
                else:
                    test_stat = np.nan
                    p_value = np.nan

            # Mutual information: between categorical and binned numeric
            mi_val = np.nan
            if bivar_cross_use_mi_2106:
                binned_num = _qcut_codes_2106(s_num_valid, q=5)
                mi_val = _mutual_information_2106(s_cat_valid, binned_num)

            # Effect label
            if not np.isnan(p_value):
                if p_value < 0.01:
                    effect_label = "Strong"
                elif p_value < 0.05:
                    effect_label = "Moderate"
                elif p_value < 0.1:
                    effect_label = "Weak"
                else:
                    effect_label = "Not significant"
            else:
                if not np.isnan(mi_val) and mi_val >= 0.5:
                    effect_label = "Strong (MI)"
                elif not np.isnan(mi_val) and mi_val >= 0.2:
                    effect_label = "Moderate (MI)"
                elif not np.isnan(mi_val) and mi_val > 0:
                    effect_label = "Weak (MI)"
                else:
                    effect_label = "Unknown"

            rows_2106.append(
                {
                    "categorical_feature": cat_col,
                    "numeric_feature": num_col,
                    "test_method": test_method_used,
                    "test_statistic": test_stat,
                    "p_value": p_value,
                    "mutual_information": mi_val,
                    "effect_label": effect_label,
                }
            )

    bivar_cross_df_2106 = pd.DataFrame(rows_2106)
    n_pairs_2106 = int(bivar_cross_df_2106.shape[0])
    n_significant_2106 = int(
        (
            bivar_cross_df_2106["p_value"].notna()
            & (bivar_cross_df_2106["p_value"] < 0.05)
        ).sum()
    )

    tmp_path_2106 = bivar_cross_matrix_path_2106.with_suffix(".tmp.csv")
    bivar_cross_df_2106.to_csv(tmp_path_2106, index=False)
    os.replace(tmp_path_2106, bivar_cross_matrix_path_2106)

if n_pairs_2106 == 0:
    status_2106 = "WARN"
else:
    frac_sig_2106 = n_significant_2106 / max(1, n_pairs_2106)
    if frac_sig_2106 <= 0.3:
        status_2106 = "OK"
    elif frac_sig_2106 <= 0.7:
        status_2106 = "WARN"
    else:
        status_2106 = "FAIL"

sig_rate_2106 = (
    float(n_significant_2106) / n_pairs_2106
    if n_pairs_2106 and n_pairs_2106 > 0
    else None
)

summary_2106 = pd.DataFrame([{
    "section": "2.10.6",
    "section_name": "Categoricalâ€“numeric relationships",
    "check": "Run group difference tests and mutual information for catâ€“num pairs",
    "level": "info",
    "status": status_2106,
    "n_pairs": int(n_pairs_2106),
    "n_significant": int(n_significant_2106),
    "significance_rate": sig_rate_2106,
    "detail": str(bivar_cross_matrix_path_2106),
    "timestamp": pd.Timestamp.utcnow(),
}])

append_sec2(summary_2106, SECTION2_REPORT_PATH)

display(summary_2106)

---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
Cell In[236], line 279
    277 if bivar_cross_use_mi_2106:
    278     binned_num = _qcut_codes_2106(s_num_valid, q=5)
--> 279     mi_val = _mutual_information_2106(s_cat_valid, binned_num)
    281 # Effect label
    282 if not np.isnan(p_value):

Cell In[236], line 132, in _mutual_information_2106(x, y)
    130 h_x = _entropy_generic_2106(df_xy["x"])
    131 h_y = _entropy_generic_2106(df_xy["y"])
--> 132 h_xy = _joint_entropy_2106(df_xy["x"], df_xy["y"])
    133 if any(np.isnan(v) for v in (h_x, h_y, h_xy)):
    134     return np.nan

Cell In[236], line 103, in _joint_entropy_2106(x, y)
    100 result = df_xy.value_counts(normalize=True)
    102 if hasattr(result.index, "infer_objects"):
--> 103     result.index = result.index.infer_objects()
    105 if result.empty:
    106     return np.nan

File ~/DATA/PROJECTS/Telco/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7151, in Index.infer_objects(self, copy)
   7142 """
   7143 If we have an object dtype, try to infer a non-object dtype.
   7144
   (...)   7148     Whether to make a copy in cases where no inference occurs.
   7149 """
   7150 if self._is_multi:
-> 7151     raise NotImplementedError(
   7152         "infer_objects is not implemented for MultiIndex. "
   7153         "Use index.to_frame().infer_objects() instead."
   7154     )
   7155 if self.dtype != object:
   7156     return self.copy() if copy else self

NotImplementedError: infer_objects is not implemented for MultiIndex. Use index.to_frame().infer_objects() instead.
```

># SOLUTION:
Ah, niceâ€”now weâ€™ve hit the *other* edge case: `infer_objects` on a **MultiIndex**. That `NotImplementedError` is coming from this line in `_joint_entropy_2106`:

```python
if hasattr(result.index, "infer_objects"):
    result.index = result.index.infer_objects()
```

But `df_xy.value_counts()` returns a **MultiIndex** (one level for `x`, one for `y`), and pandas explicitly says: â€œ`infer_objects` is not implemented for MultiIndex.â€

Letâ€™s fix both things cleanly:

* Get rid of the FutureWarning **and**
* Avoid MultiIndex infer issues

by **casting to string before `value_counts`** and not calling `infer_objects` at all.

---

## Minimal, robust fixes

### 1. Replace `_entropy_generic_2106` with string-cast version

```python
def _entropy_generic_2106(s: pd.Series) -> float:
    """Shannon entropy H(s) in bits for a discrete series."""
    # Cast to string to avoid object-dtype deprecation noise
    s_str = s.astype("string")
    result = s_str.value_counts(normalize=True, dropna=True)

    if result.empty:
        return np.nan

    p = result.values.astype(float)
    with np.errstate(divide="ignore", invalid="ignore"):
        return float(-(p * np.log2(p + 1e-15)).sum())
```

### 2. Replace `_joint_entropy_2106` similarly

```python
def _joint_entropy_2106(x: pd.Series, y: pd.Series) -> float:
    """Joint entropy H(X,Y) in bits for discrete/categorical X,Y."""
    df_xy = pd.DataFrame({"x": x, "y": y}).dropna()
    if df_xy.empty:
        return np.nan

    # Cast both to string to stabilize dtypes and avoid object warnings
    df_xy = df_xy.astype({"x": "string", "y": "string"})
    result = df_xy.value_counts(normalize=True)

    if result.empty:
        return np.nan

    p = result.values.astype(float)
    with np.errstate(divide="ignore", invalid="ignore"):
        return float(-(p * np.log2(p + 1e-15)).sum())
```

Key points:

* No `infer_objects` calls: avoids the MultiIndex `NotImplementedError`.
* Casting to `"string"` means youâ€™re off the deprecation code path, so the **FutureWarning disappears**.
* Entropy/MI math is unchanged in spirit: weâ€™re just stabilizing the dtype going into `value_counts`.

---

ðŸ’¡ðŸ’¡ **After patching:**

1. Re-run the cell that defines these functions.
2. Re-run your 2.10.6 cell.
3. If you still see warnings, a quick kernel restart + rerun Section 2 bootstrap + rerun 2.10.6 will ensure the old versions arenâ€™t hanging around.

You should end up with:

* No FutureWarnings,
* No SciPy constant-input warnings,
* A clean `bivariate_cross_association.csv` + Section 2 row.

