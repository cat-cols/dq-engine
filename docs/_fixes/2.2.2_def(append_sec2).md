> Should I refactor this cell to use append_sec2 :
```py
# 2.2.2 ‚öôÔ∏è Coercion Attempt & Logging (numeric + datetime)
print("\n2.2.2 ‚öôÔ∏è Coercion attempt & logging")

# Reload artifacts in case this cell runs standalone after 2.2.1
type_summary_path = TYPE_DET_DIR / "type_detection_summary.csv"
if not type_summary_path.exists():
    raise FileNotFoundError("‚ùå type_detection_summary.csv missing. Run 2.2.1 first.")

type_det_df = pd.read_csv(type_summary_path)

type_map_path = TYPE_DET_DIR / "column_type_map.json"
if not type_map_path.exists():
    raise FileNotFoundError("‚ùå column_type_map.json missing. Run 2.2.1 first.")

with open(type_map_path, "r", encoding="utf-8") as f:
    column_type_map = json.load(f)

# Config knobs for coercion behaviour
try:
    numeric_threshold = float(C("TYPE_DETECTION.NUMERIC_THRESHOLD", 0.95))
except Exception:
    numeric_threshold = 0.95

try:
    coercion_min_success_numeric = float(C("TYPE_DETECTION.COERCION_MIN_SUCCESS_NUMERIC", 0.90))
except Exception:
    coercion_min_success_numeric = 0.90

try:
    coercion_min_success_datetime = float(C("TYPE_DETECTION.COERCION_MIN_SUCCESS_DATETIME", 0.85))
except Exception:
    coercion_min_success_datetime = 0.85

try:
    coercion_target_numeric = C("TYPE_DETECTION.COERCION_TARGET_NUMERIC", "float64")
except Exception:
    coercion_target_numeric = "float64"

try:
    APPLY_COERCION = bool(C("TYPE_DETECTION.APPLY_COERCION", False))
except Exception:
    APPLY_COERCION = False

try:
    id_cols = set(C("ID_COLUMNS", []) or [])
except Exception:
    id_cols = set()

try:
    target_name = C("TARGET.COLUMN")
except Exception:
    target_name = None

coercion_rows = []

# split candidates by semantic_type
numeric_candidates   = type_det_df[type_det_df["semantic_type"] == "numeric_like_string"]["column"].tolist()
datetime_candidates  = type_det_df[type_det_df["semantic_type"] == "datetime_like_string"]["column"].tolist()

for col in df.columns:
    s = df[col]
    pre_dtype = str(s.dtype)
    pre_non_null = int(s.notna().sum())

    if col in id_cols or col == target_name:
        coercion_rows.append(
            {
                "column": col,
                "target_kind": None,
                "semantic_type": column_type_map.get(col, {}).get("semantic_type"),
                "reason": "id_or_target",
                "attempted": False,
                "ok": True,
                "pre_dtype": pre_dtype,
                "post_dtype": pre_dtype,
                "pre_non_null": pre_non_null,
                "post_non_null": pre_non_null,
                "new_nulls": 0,
                "success_ratio": 1.0,
                "applied": False,
                "sample_fail_values": None,
                "error": None,
            }
        )
        continue

    semantic_type = column_type_map.get(col, {}).get("semantic_type")

    # --- numeric-like coercion ------------------------------------------------
    if (semantic_type == "numeric_like_string") and (col in numeric_candidates):
        if pre_non_null == 0:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "numeric",
                    "semantic_type": semantic_type,
                    "reason": "all_null_or_empty",
                    "attempted": False,
                    "ok": True,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": 0,
                    "success_ratio": 1.0,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": None,
                }
            )
            continue

        try:
            s_num = pd.to_numeric(s, errors="coerce")
            post_non_null = int(s_num.notna().sum())
            new_nulls_mask = (s.notna()) & (s_num.isna())
            new_nulls = int(new_nulls_mask.sum())
            success_ratio = float(post_non_null) / pre_non_null if pre_non_null else 1.0
            ok = success_ratio >= coercion_min_success_numeric

            # sample of fail values
            fail_vals = (
                s[new_nulls_mask]
                .astype("string")
                .dropna()
                .unique()
                .tolist()
            )
            fail_vals = fail_vals[:10]  # cap

            applied = False
            post_dtype = pre_dtype
            err_msg = None

            if APPLY_COERCION and ok:
                try:
                    df[col] = s_num.astype(coercion_target_numeric)
                    post_dtype = str(df[col].dtype)
                    applied = True
                except Exception as e:
                    ok = False
                    err_msg = f"astype_failed: {e}"
                    df[col] = s  # revert best-effort

            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "numeric",
                    "semantic_type": semantic_type,
                    "reason": "numeric_like_string",
                    "attempted": True,
                    "ok": ok,
                    "pre_dtype": pre_dtype,
                    "post_dtype": post_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": int(df[col].notna().sum()) if applied else pre_non_null,
                    "new_nulls": new_nulls,
                    "success_ratio": round(success_ratio, 4),
                    "applied": applied,
                    "sample_fail_values": json.dumps(fail_vals),
                    "error": err_msg,
                }
            )
        except Exception as e:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "numeric",
                    "semantic_type": semantic_type,
                    "reason": "coercion_exception",
                    "attempted": True,
                    "ok": False,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": None,
                    "success_ratio": None,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": str(e),
                }
            )
        continue

    # --- datetime-like coercion ----------------------------------------------
    if (semantic_type == "datetime_like_string") and (col in datetime_candidates):
        if pre_non_null == 0:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "datetime",
                    "semantic_type": semantic_type,
                    "reason": "all_null_or_empty",
                    "attempted": False,
                    "ok": True,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": 0,
                    "success_ratio": 1.0,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": None,
                }
            )
            continue

        try:
            s_dt = pd.to_datetime(s, errors="coerce", infer_datetime_format=True)
            post_non_null = int(s_dt.notna().sum())
            new_nulls_mask = (s.notna()) & (s_dt.isna())
            new_nulls = int(new_nulls_mask.sum())
            success_ratio = float(post_non_null) / pre_non_null if pre_non_null else 1.0
            ok = success_ratio >= coercion_min_success_datetime

            # sample of fail values
            fail_vals = (
                s[new_nulls_mask]
                .astype("string")
                .dropna()
                .unique()
                .tolist()
            )
            fail_vals = fail_vals[:10]

            applied = False
            post_dtype = pre_dtype
            err_msg = None

            if APPLY_COERCION and ok:
                try:
                    df[col] = s_dt
                    post_dtype = str(df[col].dtype)
                    applied = True
                except Exception as e:
                    ok = False
                    err_msg = f"datetime_assign_failed: {e}"
                    df[col] = s  # revert

            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "datetime",
                    "semantic_type": semantic_type,
                    "reason": "datetime_like_string",
                    "attempted": True,
                    "ok": ok,
                    "pre_dtype": pre_dtype,
                    "post_dtype": post_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": int(df[col].notna().sum()) if applied else pre_non_null,
                    "new_nulls": new_nulls,
                    "success_ratio": round(success_ratio, 4),
                    "applied": applied,
                    "sample_fail_values": json.dumps(fail_vals),
                    "error": err_msg,
                }
            )
        except Exception as e:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "datetime",
                    "semantic_type": semantic_type,
                    "reason": "coercion_exception",
                    "attempted": True,
                    "ok": False,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": None,
                    "success_ratio": None,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": str(e),
                }
            )
        continue

    # not a coercion candidate
    coercion_rows.append(
        {
            "column": col,
            "target_kind": None,
            "semantic_type": semantic_type,
            "reason": "not_coercion_candidate",
            "attempted": False,
            "ok": True,
            "pre_dtype": pre_dtype,
            "post_dtype": pre_dtype,
            "pre_non_null": pre_non_null,
            "post_non_null": pre_non_null,
            "new_nulls": 0,
            "success_ratio": 1.0,
            "applied": False,
            "sample_fail_values": None,
            "error": None,
        }
    )

coercion_df = pd.DataFrame(coercion_rows)

coercion_log_path = TYPE_DET_DIR / "coercion_log.csv"
tmp_coercion = coercion_log_path.with_suffix(".tmp.csv")
coercion_df.to_csv(tmp_coercion, index=False)
os.replace(tmp_coercion, coercion_log_path)

print(f"üíæ Wrote coercion log ‚Üí {coercion_log_path}")

print("\nüìä 2.2.2 coercion summary (head):")
display(
    coercion_df[
        [
            "column",
            "target_kind",
            "reason",
            "attempted",
            "ok",
            "pre_dtype",
            "post_dtype",
            "success_ratio",
            "applied",
        ]
    ].head(20)
)

n_attempted = int(coercion_df["attempted"].sum())
n_failed   = int((coercion_df["attempted"] & ~coercion_df["ok"]).sum())
n_applied  = int(coercion_df["applied"].sum())

status_222 = "OK" if n_failed == 0 else "WARN"

summary_222 = {
    "section":          "2.2.2",
    "section_name":     "Coercion attempt & logging",
    "check":            "Coerce numeric/datetime-like strings with audit log",
    "level":            "info",
    "status":           status_222,
    "n_columns":        n_cols,
    "n_attempted":      n_attempted,
    "n_applied":        n_applied,
    "n_failed":         n_failed,
    "apply_coercion":   APPLY_COERCION,
    "timestamp":        pd.Timestamp.utcnow(),
    "detail":           "Coercion log ‚Üí coercion_log.csv; df mutated only when APPLY_COERCION=True & success is high",
}

if "append_sec2" in globals():
    append_sec2(pd.DataFrame([summary_222]))
else:
    path = SECTION2_REPORT_PATH
    tmp_path = path.with_suffix(path.suffix + ".tmp")
    chunk = pd.DataFrame([summary_222])
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        if path.exists():
            ex = pd.read_csv(path)
            allc = pd.Index(ex.columns).union(chunk.columns)
            out = pd.concat(
                [ex.reindex(columns=allc), chunk.reindex(columns=allc)],
                ignore_index=True,
            )
        else:
            out = chunk
        out.to_csv(tmp_path, index=False)
        os.replace(tmp_path, path)
        print(f"üßæ Appended 2.2.2 summary ‚Üí {path}")
    except Exception as e:
        if tmp_path.exists():
            try:
                tmp_path.unlink()
            except Exception:
                pass
        print(f"‚ö†Ô∏è Could not append 2.2.2 summary: {e}")


print("‚úÖ 2.2.2 complete.")

Should I refactor this cell to:

# 2.2.2 ‚öôÔ∏è Coercion Attempt & Logging (numeric + datetime)
print("\n2.2.2 ‚öôÔ∏è Coercion attempt & logging")

# Reload artifacts in case this cell runs standalone after 2.2.1
type_summary_path = TYPE_DET_DIR / "type_detection_summary.csv"
if not type_summary_path.exists():
    raise FileNotFoundError("‚ùå type_detection_summary.csv missing. Run 2.2.1 first.")

type_det_df = pd.read_csv(type_summary_path)

type_map_path = TYPE_DET_DIR / "column_type_map.json"
if not type_map_path.exists():
    raise FileNotFoundError("‚ùå column_type_map.json missing. Run 2.2.1 first.")

with open(type_map_path, "r", encoding="utf-8") as f:
    column_type_map = json.load(f)

# Config knobs for coercion behaviour
try:
    numeric_threshold = float(C("TYPE_DETECTION.NUMERIC_THRESHOLD", 0.95))
except Exception:
    numeric_threshold = 0.95

try:
    coercion_min_success_numeric = float(C("TYPE_DETECTION.COERCION_MIN_SUCCESS_NUMERIC", 0.90))
except Exception:
    coercion_min_success_numeric = 0.90

try:
    coercion_min_success_datetime = float(C("TYPE_DETECTION.COERCION_MIN_SUCCESS_DATETIME", 0.85))
except Exception:
    coercion_min_success_datetime = 0.85

try:
    coercion_target_numeric = C("TYPE_DETECTION.COERCION_TARGET_NUMERIC", "float64")
except Exception:
    coercion_target_numeric = "float64"

try:
    APPLY_COERCION = bool(C("TYPE_DETECTION.APPLY_COERCION", False))
except Exception:
    APPLY_COERCION = False

try:
    id_cols = set(C("ID_COLUMNS", []) or [])
except Exception:
    id_cols = set()

try:
    target_name = C("TARGET.COLUMN")
except Exception:
    target_name = None

coercion_rows = []

# split candidates by semantic_type
numeric_candidates   = type_det_df[type_det_df["semantic_type"] == "numeric_like_string"]["column"].tolist()
datetime_candidates  = type_det_df[type_det_df["semantic_type"] == "datetime_like_string"]["column"].tolist()

for col in df.columns:
    s = df[col]
    pre_dtype = str(s.dtype)
    pre_non_null = int(s.notna().sum())

    if col in id_cols or col == target_name:
        coercion_rows.append(
            {
                "column": col,
                "target_kind": None,
                "semantic_type": column_type_map.get(col, {}).get("semantic_type"),
                "reason": "id_or_target",
                "attempted": False,
                "ok": True,
                "pre_dtype": pre_dtype,
                "post_dtype": pre_dtype,
                "pre_non_null": pre_non_null,
                "post_non_null": pre_non_null,
                "new_nulls": 0,
                "success_ratio": 1.0,
                "applied": False,
                "sample_fail_values": None,
                "error": None,
            }
        )
        continue

    semantic_type = column_type_map.get(col, {}).get("semantic_type")

    # --- numeric-like coercion ------------------------------------------------
    if (semantic_type == "numeric_like_string") and (col in numeric_candidates):
        if pre_non_null == 0:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "numeric",
                    "semantic_type": semantic_type,
                    "reason": "all_null_or_empty",
                    "attempted": False,
                    "ok": True,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": 0,
                    "success_ratio": 1.0,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": None,
                }
            )
            continue

        try:
            s_num = pd.to_numeric(s, errors="coerce")
            post_non_null = int(s_num.notna().sum())
            new_nulls_mask = (s.notna()) & (s_num.isna())
            new_nulls = int(new_nulls_mask.sum())
            success_ratio = float(post_non_null) / pre_non_null if pre_non_null else 1.0
            ok = success_ratio >= coercion_min_success_numeric

            # sample of fail values
            fail_vals = (
                s[new_nulls_mask]
                .astype("string")
                .dropna()
                .unique()
                .tolist()
            )
            fail_vals = fail_vals[:10]  # cap

            applied = False
            post_dtype = pre_dtype
            err_msg = None

            if APPLY_COERCION and ok:
                try:
                    df[col] = s_num.astype(coercion_target_numeric)
                    post_dtype = str(df[col].dtype)
                    applied = True
                except Exception as e:
                    ok = False
                    err_msg = f"astype_failed: {e}"
                    df[col] = s  # revert best-effort

            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "numeric",
                    "semantic_type": semantic_type,
                    "reason": "numeric_like_string",
                    "attempted": True,
                    "ok": ok,
                    "pre_dtype": pre_dtype,
                    "post_dtype": post_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": int(df[col].notna().sum()) if applied else pre_non_null,
                    "new_nulls": new_nulls,
                    "success_ratio": round(success_ratio, 4),
                    "applied": applied,
                    "sample_fail_values": json.dumps(fail_vals),
                    "error": err_msg,
                }
            )
        except Exception as e:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "numeric",
                    "semantic_type": semantic_type,
                    "reason": "coercion_exception",
                    "attempted": True,
                    "ok": False,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": None,
                    "success_ratio": None,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": str(e),
                }
            )
        continue

    # --- datetime-like coercion ----------------------------------------------
    if (semantic_type == "datetime_like_string") and (col in datetime_candidates):
        if pre_non_null == 0:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "datetime",
                    "semantic_type": semantic_type,
                    "reason": "all_null_or_empty",
                    "attempted": False,
                    "ok": True,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": 0,
                    "success_ratio": 1.0,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": None,
                }
            )
            continue

        try:
            s_dt = pd.to_datetime(s, errors="coerce", infer_datetime_format=True)
            post_non_null = int(s_dt.notna().sum())
            new_nulls_mask = (s.notna()) & (s_dt.isna())
            new_nulls = int(new_nulls_mask.sum())
            success_ratio = float(post_non_null) / pre_non_null if pre_non_null else 1.0
            ok = success_ratio >= coercion_min_success_datetime

            # sample of fail values
            fail_vals = (
                s[new_nulls_mask]
                .astype("string")
                .dropna()
                .unique()
                .tolist()
            )
            fail_vals = fail_vals[:10]

            applied = False
            post_dtype = pre_dtype
            err_msg = None

            if APPLY_COERCION and ok:
                try:
                    df[col] = s_dt
                    post_dtype = str(df[col].dtype)
                    applied = True
                except Exception as e:
                    ok = False
                    err_msg = f"datetime_assign_failed: {e}"
                    df[col] = s  # revert

            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "datetime",
                    "semantic_type": semantic_type,
                    "reason": "datetime_like_string",
                    "attempted": True,
                    "ok": ok,
                    "pre_dtype": pre_dtype,
                    "post_dtype": post_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": int(df[col].notna().sum()) if applied else pre_non_null,
                    "new_nulls": new_nulls,
                    "success_ratio": round(success_ratio, 4),
                    "applied": applied,
                    "sample_fail_values": json.dumps(fail_vals),
                    "error": err_msg,
                }
            )
        except Exception as e:
            coercion_rows.append(
                {
                    "column": col,
                    "target_kind": "datetime",
                    "semantic_type": semantic_type,
                    "reason": "coercion_exception",
                    "attempted": True,
                    "ok": False,
                    "pre_dtype": pre_dtype,
                    "post_dtype": pre_dtype,
                    "pre_non_null": pre_non_null,
                    "post_non_null": pre_non_null,
                    "new_nulls": None,
                    "success_ratio": None,
                    "applied": False,
                    "sample_fail_values": None,
                    "error": str(e),
                }
            )
        continue

    # not a coercion candidate
    coercion_rows.append(
        {
            "column": col,
            "target_kind": None,
            "semantic_type": semantic_type,
            "reason": "not_coercion_candidate",
            "attempted": False,
            "ok": True,
            "pre_dtype": pre_dtype,
            "post_dtype": pre_dtype,
            "pre_non_null": pre_non_null,
            "post_non_null": pre_non_null,
            "new_nulls": 0,
            "success_ratio": 1.0,
            "applied": False,
            "sample_fail_values": None,
            "error": None,
        }
    )

coercion_df = pd.DataFrame(coercion_rows)

coercion_log_path = TYPE_DET_DIR / "coercion_log.csv"
tmp_coercion = coercion_log_path.with_suffix(".tmp.csv")
coercion_df.to_csv(tmp_coercion, index=False)
os.replace(tmp_coercion, coercion_log_path)

print(f"üíæ Wrote coercion log ‚Üí {coercion_log_path}")

print("\nüìä 2.2.2 coercion summary (head):")
display(
    coercion_df[
        [
            "column",
            "target_kind",
            "reason",
            "attempted",
            "ok",
            "pre_dtype",
            "post_dtype",
            "success_ratio",
            "applied",
        ]
    ].head(20)
)

n_attempted = int(coercion_df["attempted"].sum())
n_failed   = int((coercion_df["attempted"] & ~coercion_df["ok"]).sum())
n_applied  = int(coercion_df["applied"].sum())

status_222 = "OK" if n_failed == 0 else "WARN"

summary_222 = {
    "section":          "2.2.2",
    "section_name":     "Coercion attempt & logging",
    "check":            "Coerce numeric/datetime-like strings with audit log",
    "level":            "info",
    "status":           status_222,
    "n_columns":        n_cols,
    "n_attempted":      n_attempted,
    "n_applied":        n_applied,
    "n_failed":         n_failed,
    "apply_coercion":   APPLY_COERCION,
    "timestamp":        pd.Timestamp.utcnow(),
    "detail":           "Coercion log ‚Üí coercion_log.csv; df mutated only when APPLY_COERCION=True & success is high",
}

append_sec2(summary_222, SEC2_REPORTS_PATH)

print("‚úÖ 2.2.2 complete.")
```

---

># SOLUTION:
Short answer: **yes, refactor it ‚Äì but with a couple of important fixes.**

Your *idea* (always use `append_sec2` and drop the inline fallback) is good. The details in your proposed refactor just need a tweak.

---

## 1. What you have now (bottom of the cell)

```python
if "append_sec2" in globals():
    append_sec2(pd.DataFrame([summary_222]))
else:
    path = SECTION2_REPORT_PATH
    tmp_path = path.with_suffix(path.suffix + ".tmp")
    chunk = pd.DataFrame([summary_222])
    ...
```

This is:

* Defensive (works even if `append_sec2` wasn‚Äôt run)
* But noisy + duplicated logic across cells

Now that you‚Äôve got a proper `append_sec2` helper, it‚Äôs cleaner to:

> Make 2.x cells *assume* Section 2 bootstrap ran, and fail loudly if not.

So this cell should just say: ‚ÄúI expect `append_sec2` and `SECTION2_REPORT_PATH` to exist, and if they don‚Äôt, that‚Äôs your ordering problem.‚Äù

---

## 2. Issues in your proposed refactor

Your suggested bottom:

```python
summary_222 = {
    ...
}

append_sec2(summary_222, SEC2_REPORTS_PATH)
```

Two problems:

1. `append_sec2` expects a **DataFrame**, not a dict
2. Your path variable elsewhere is `SECTION2_REPORT_PATH`, not `SEC2_REPORTS_PATH` (typo / naming mismatch)

So that line will throw at runtime.

---

## 3. A good refactor for the bottom of 2.2.2

Here‚Äôs how I‚Äôd rewrite just the tail of the cell:

```python
n_attempted = int(coercion_df["attempted"].sum())
n_failed   = int((coercion_df["attempted"] & ~coercion_df["ok"]).sum())
n_applied  = int(coercion_df["applied"].sum())

# be a bit safer: define n_cols locally
n_cols = df.shape[1]

status_222 = "OK" if n_failed == 0 else "WARN"

summary_222 = {
    "section":          "2.2.2",
    "section_name":     "Coercion attempt & logging",
    "check":            "Coerce numeric/datetime-like strings with audit log",
    "level":            "info",
    "status":           status_222,
    "n_columns":        n_cols,
    "n_attempted":      n_attempted,
    "n_applied":        n_applied,
    "n_failed":         n_failed,
    "apply_coercion":   APPLY_COERCION,
    "timestamp":        pd.Timestamp.utcnow(),
    "detail":           "Coercion log ‚Üí coercion_log.csv; df mutated only when APPLY_COERCION=True & success is high",
}

# Guards: enforce correct run order instead of silent fallback
assert "append_sec2" in globals(), "‚ùå append_sec2 not found. Run Section 2.0.x bootstrap first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH not found. Run 2.0.1 first."

# Wrap summary_222 into a 1-row DataFrame, as append_sec2 expects
append_sec2(pd.DataFrame([summary_222]), SECTION2_REPORT_PATH)

print("‚úÖ 2.2.2 complete.")
```

That gives you:

* No duplicated appending logic
* A single, consistent call to `append_sec2`
* Clear assertion messages if someone runs 2.2.2 out of order
* Correct argument types + correct path variable name

---

## 4. Pattern going forward

For any 2.x section that writes a diagnostics summary:

1. Build `summary_xxx` dict
2. Wrap it in `pd.DataFrame([summary_xxx])`
3. Call:

   ```python
   assert "append_sec2" in globals()
   assert "SECTION2_REPORT_PATH" in globals()
   append_sec2(pd.DataFrame([summary_xxx]), SECTION2_REPORT_PATH)
   ```

Since you‚Äôve already taught `append_sec2` to update `SECTION2_APPEND_SECTIONS` internally, you don‚Äôt need any per-section bookkeeping either.

So: yes, refactor the cell ‚Äî just fix the call to `append_sec2` as above and you‚Äôre golden.
