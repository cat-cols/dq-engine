# 2.3.4 | Enhanced Numeric Metrics (CV, MAD, Entropy, etc.)
print("\n2.3.4 üìä Enhanced numeric metrics (CV, MAD, entropy, zero/negative %, etc.)")

try:
    n_bins_entropy = int(C("NUMERIC.METRICS.N_BINS", 10))
except Exception:
    n_bins_entropy = 10

try:
    zero_inflated_threshold_pct = float(C("NUMERIC.METRICS.ZERO_INFLATED_PCT", 50.0))
except Exception:
    zero_inflated_threshold_pct = 50.0

try:
    cv_high_threshold = float(C("NUMERIC.METRICS.CV_HIGH_THRESHOLD", 1.0))
except Exception:
    cv_high_threshold = 1.0

try:
    cv_low_threshold = float(C("NUMERIC.METRICS.CV_LOW_THRESHOLD", 0.1))
except Exception:
    cv_low_threshold = 0.1

enhanced_rows = []

for col in numeric_cols:
    s = df[col]
    s_num = pd.to_numeric(s, errors="coerce").dropna()
    n_valid = int(s_num.shape[0])

    if n_valid == 0:
        enhanced_rows.append(
            {
                "column":          col,
                "mean":            float("nan"),
                "std":             float("nan"),
                "median":          float("nan"),
                "mad":             float("nan"),
                "cv":              float("nan"),
                "pct_zero":        0.0,
                "pct_negative":    0.0,
                "pct_positive":    0.0,
                "entropy_binned":  float("nan"),
                "distribution_shape": "empty",
            }
        )
        continue

    mean_val = float(s_num.mean())
    std_val = float(s_num.std(ddof=1))
    median_val = float(s_num.median())
    mad_val = float((s_num - median_val).abs().median())

    if mean_val != 0:
        cv_val = float(std_val / abs(mean_val))
    else:
        cv_val = float("nan")

    n_zero = int((s_num == 0).sum())
    n_neg = int((s_num < 0).sum())
    n_pos = int((s_num > 0).sum())

    pct_zero = float(round((n_zero / n_valid) * 100.0, 3))
    pct_negative = float(round((n_neg / n_valid) * 100.0, 3))
    pct_positive = float(round((n_pos / n_valid) * 100.0, 3))

    entropy_val = float("nan")
    if n_bins_entropy > 0 and n_valid > 0:
        try:
            binned = pd.cut(s_num, bins=n_bins_entropy, duplicates="drop")
            counts = binned.value_counts(normalize=True)
            p = counts.to_numpy()
            p = p[p > 0]
            if p.size > 0:
                entropy_val = float(-(p * np.log(p)).sum())
        except Exception:
            entropy_val = float("nan")

    # Simple distribution shape tags
    if pct_zero >= zero_inflated_threshold_pct:
        distribution_shape = "zero_inflated"
    elif (not np.isnan(cv_val)) and (cv_val >= cv_high_threshold):
        distribution_shape = "high_var"
    elif (not np.isnan(cv_val)) and (cv_val <= cv_low_threshold):
        distribution_shape = "low_var"
    else:
        distribution_shape = "moderate_var"

    enhanced_rows.append(
        {
            "column":          col,
            "mean":            mean_val,
            "std":             std_val,
            "median":          median_val,
            "mad":             mad_val,
            "cv":              cv_val,
            "pct_zero":        pct_zero,
            "pct_negative":    pct_negative,
            "pct_positive":    pct_positive,
            "entropy_binned":  entropy_val,
            "distribution_shape": distribution_shape,
        }
    )

numeric_metrics_df = (
    pd.DataFrame(enhanced_rows)
    .sort_values(["distribution_shape", "column"])
    .reset_index(drop=True)
)

numeric_metrics_path = NUMERIC_DIR / "numeric_metrics_enhanced.csv"
tmp_234 = numeric_metrics_path.with_suffix(".tmp.csv")
numeric_metrics_df.to_csv(tmp_234, index=False)
os.replace(tmp_234, numeric_metrics_path)
print(f"üíæ Wrote enhanced numeric metrics ‚Üí {numeric_metrics_path}")

print("\nüìä 2.3.4 enhanced metrics (head):")
if not numeric_metrics_df.empty:
    display(
        numeric_metrics_df[
            [
                "column",
                "mean",
                "std",
                "median",
                "mad",
                "cv",
                "pct_zero",
                "pct_negative",
                "pct_positive",
                "distribution_shape",
            ]
        ].head(20)
    )
else:
    print("   (no numeric columns)")

n_zero_inflated_234 = int((numeric_metrics_df["pct_zero"] > zero_inflated_threshold_pct).sum())
n_high_cv_234 = int((numeric_metrics_df["cv"] > cv_high_threshold).sum())

status_234 = "OK"
if (n_zero_inflated_234 > 0) or (n_high_cv_234 > 0):
    status_234 = "WARN"

summary_234 = {
    "section":          "2.3.4",
    "section_name":     "Enhanced numeric metrics",
    "check":            "CV, MAD, entropy, zero/negative %, etc.",
    "level":            "info",
    "status":           status_234,
    "n_numeric":        int(len(numeric_cols)),
    "n_zero_inflated":  int(n_zero_inflated_234),
    "n_high_cv":        int(n_high_cv_234),
    "detail":           "numeric_metrics_enhanced.csv",
    "timestamp":        pd.Timestamp.utcnow(),
}

if "append_sec2" in globals():
    append_sec2(pd.DataFrame([summary_234]))
else:
    path = SECTION2_REPORT_PATH
    tmp = path.with_suffix(path.suffix + ".tmp")
    chunk = pd.DataFrame([summary_234])
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        if path.exists():
            ex = pd.read_csv(path)
            allc = pd.Index(ex.columns).union(chunk.columns)
            out = pd.concat([ex.reindex(columns=allc), chunk.reindex(columns=allc)], ignore_index=True)
        else:
            out = chunk
        out.to_csv(tmp, index=False)
        os.replace(tmp, path)
        print(f"üßæ Appended 2.3.4 summary ‚Üí {path}")
    except Exception as e:
        if tmp.exists():
            try:
                tmp.unlink()
            except Exception:
                pass
        print(f"‚ö†Ô∏è Could not append 2.3.4 summary: {e}")

print("‚úÖ 2.3.4 complete.")

2.3.4 üìä Enhanced numeric metrics (CV, MAD, entropy, zero/negative %, etc.)
üíæ Wrote enhanced numeric metrics ‚Üí /Users/b/DATA/PROJECTS/Telco/Level_3/resources/reports/section2/numeric/numeric_metrics_enhanced.csv

üìä 2.3.4 enhanced metrics (head):
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column</th>
      <th>mean</th>
      <th>std</th>
      <th>median</th>
      <th>mad</th>
      <th>cv</th>
      <th>pct_zero</th>
      <th>pct_negative</th>
      <th>pct_positive</th>
      <th>distribution_shape</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>expected_total_for_zero_tenure</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>empty</td>
    </tr>
    <tr>
      <th>1</th>
      <td>MonthlyCharges</td>
      <td>64.749689</td>
      <td>30.062810</td>
      <td>70.350</td>
      <td>24.050000</td>
      <td>0.464293</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>100.000</td>
      <td>moderate_var</td>
    </tr>
    <tr>
      <th>2</th>
      <td>TotalCharges</td>
      <td>2279.361600</td>
      <td>2258.540338</td>
      <td>1397.475</td>
      <td>1221.275000</td>
      <td>0.990865</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>100.000</td>
      <td>moderate_var</td>
    </tr>
    <tr>
      <th>3</th>
      <td>expected_total_from_payment_profile</td>
      <td>2278.746746</td>
      <td>2262.274846</td>
      <td>1393.600</td>
      <td>1220.700000</td>
      <td>0.992772</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>100.000</td>
      <td>moderate_var</td>
    </tr>
    <tr>
      <th>4</th>
      <td>expected_total_from_tenure_monthly</td>
      <td>2278.746746</td>
      <td>2262.274846</td>
      <td>1393.600</td>
      <td>1220.700000</td>
      <td>0.992772</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>100.000</td>
      <td>moderate_var</td>
    </tr>
    <tr>
      <th>5</th>
      <td>expected_total_senior</td>
      <td>2810.125722</td>
      <td>2357.113714</td>
      <td>2245.350</td>
      <td>1796.150000</td>
      <td>0.838793</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>100.000</td>
      <td>moderate_var</td>
    </tr>
    <tr>
      <th>6</th>
      <td>tenure</td>
      <td>32.372710</td>
      <td>24.557454</td>
      <td>29.000</td>
      <td>22.000000</td>
      <td>0.758585</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>100.000</td>
      <td>moderate_var</td>
    </tr>
    <tr>
      <th>7</th>
      <td>total_charges_per_month</td>
      <td>66.849411</td>
      <td>60.629040</td>
      <td>70.450</td>
      <td>23.893396</td>
      <td>0.906950</td>
      <td>0.000</td>
      <td>0.0</td>
      <td>100.000</td>
      <td>moderate_var</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Churn_flag</td>
      <td>0.265370</td>
      <td>0.441561</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>1.663947</td>
      <td>73.463</td>
      <td>0.0</td>
      <td>26.537</td>
      <td>zero_inflated</td>
    </tr>
    <tr>
      <th>9</th>
      <td>SeniorCitizen</td>
      <td>0.162147</td>
      <td>0.368612</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>2.273320</td>
      <td>83.785</td>
      <td>0.0</td>
      <td>16.215</td>
      <td>zero_inflated</td>
    </tr>
    <tr>
      <th>10</th>
      <td>expected_min_total_from_contract</td>
      <td>28.217687</td>
      <td>38.416285</td>
      <td>0.000</td>
      <td>0.000000</td>
      <td>1.361426</td>
      <td>55.019</td>
      <td>0.0</td>
      <td>44.981</td>
      <td>zero_inflated</td>
    </tr>
  </tbody>
</table>
</div>

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[433], line 159
    145 summary_234 = {
    146     "section":          "2.3.4",
    147     "section_name":     "Enhanced numeric metrics",
   (...)    155     "timestamp":        pd.Timestamp.utcnow(),
    156 }
    158 if "append_sec2" in globals():
--> 159     append_sec2(pd.DataFrame([summary_234]))
    160 else:
    161     path = SECTION2_REPORT_PATH

TypeError: append_sec2() missing 1 required positional argument: 'report_path'

---
># SOLUTION
---

Nice catch ‚Äî this error is *exactly* what you'd expect after ‚Äúpromoting‚Äù `append_sec2` into a proper library function.

---

## üîß What‚Äôs going wrong

Your `append_sec2` in `utils/reporting.py` is defined as:

```python
def append_sec2(
    chunk: pd.DataFrame,
    report_path: str | Path,
) -> Path:
    ...
```

So when your cell does:

```python
if "append_sec2" in globals():
    append_sec2(pd.DataFrame([summary_234]))
```

Python quite reasonably complains:

> `TypeError: append_sec2() missing 1 required positional argument: 'report_path'`

Because you‚Äôre only passing the `chunk` (the DataFrame), but not the `report_path`.

---

## ‚úÖ The ‚Äúproper‚Äù pattern going forward

1. **Define a single unified Section 2 report path once** in your notebook.
2. **Always call `append_sec2(chunk, SECTION2_REPORT_PATH)`**.

### 1Ô∏è‚É£ Define the unified report path once

Near the top of your Section 2 notebook (where you set `section2_reports_dir_210`), add:

```python
from pathlib import Path
from telco_churn.utils.reporting import append_sec2, log_section_completion

# Where the unified Section 2 diagnostics live
SECTION2_REPORT_PATH = section2_reports_dir_210 / "section2_unified_report.csv"
```

(Adjust `section2_reports_dir_210` if you named it slightly differently.)

---

### 2Ô∏è‚É£ Fix 2.3.4 to use `append_sec2` correctly

At the bottom of your 2.3.4 cell, replace the conditional block with a simple, explicit call:

```python
summary_234 = {
    "section":          "2.3.4",
    "section_name":     "Enhanced numeric metrics",
    "check":            "CV, MAD, entropy, zero/negative %, etc.",
    "level":            "info",
    "status":           status_234,
    "n_numeric":        int(len(numeric_cols)),
    "n_zero_inflated":  int(n_zero_inflated_234),
    "n_high_cv":        int(n_high_cv_234),
    "detail":           "numeric_metrics_enhanced.csv",
    "timestamp":        pd.Timestamp.utcnow(),
}

# üîÅ Old block (remove this):
# if "append_sec2" in globals():
#     append_sec2(pd.DataFrame([summary_234]))
# else:
#     ... manual CSV logic ...

# ‚úÖ New, ‚Äúproper‚Äù call:
append_sec2(pd.DataFrame([summary_234]), SECTION2_REPORT_PATH)

print("‚úÖ 2.3.4 complete.")
```

That‚Äôs it. No need for the big fallback block anymore, because:

* `append_sec2` *is* the fallback logic (atomic write, merging, etc.).
* You control its import at the top of the notebook.

---

## üßµ If you still want a tiny shorthand

If you like the `_append_sec2(chunk)` ergonomic style inside cells, you can define a **thin wrapper** once:

```python
from telco_churn.utils.reporting import append_sec2

def _append_sec2(chunk: pd.DataFrame) -> None:
    append_sec2(chunk, SECTION2_REPORT_PATH)
```

Then your cell becomes:

```python
_append_sec2(pd.DataFrame([summary_234]))
```

But under the hood, everything still goes through the ‚Äúproper‚Äù `append_sec2`.

---

## üß† TL;DR

* Yes: **it is more proper to use `append_sec2`** as your canonical writer.
* The error is just because its signature is now `(chunk, report_path)`.
* Fix by:

  * defining `SECTION2_REPORT_PATH` once, and
  * updating calls to `append_sec2(chunk, SECTION2_REPORT_PATH)` (or using a wrapper).

If you paste your other Section 2 cells that still call `_append_sec2`, I can do a quick ‚Äúglobal refactor sketch‚Äù for all of them so everything lines up with `append_sec2`.

---

>
>
># Q: would it be most proper to add report path to my append_sec2 function?

Short answer: **no ‚Äî what you have now (append_sec2 *taking* a report_path) is actually the ‚Äúmost proper‚Äù design.**

Let me untangle the options:

---

## 1. Library function: keep `report_path` as a parameter ‚úÖ

Your current signature:

```python
def append_sec2(
    chunk: pd.DataFrame,
    report_path: str | Path,
) -> Path:
    ...
```

is exactly what a **good library function** should look like:

* It‚Äôs **pure and explicit**: ‚Äúgiven this chunk and this path, append it.‚Äù
* It doesn‚Äôt depend on notebook globals.
* You can reuse it in:

  * Section 2 notebooks
  * Future pipelines
  * Unit tests

That is *better* engineering than hard-coding or implicitly grabbing a path.

---

## 2. Nice ergonomics in the notebook: add a tiny wrapper üßµ

Where you *do* want convenience is inside your notebook cells.
That‚Äôs where a thin wrapper is perfect:

```python
from telco_churn.utils.reporting import append_sec2

SECTION2_REPORT_PATH = section2_reports_dir_210 / "section2_unified_report.csv"

def _append_sec2(chunk: pd.DataFrame) -> None:
    append_sec2(chunk, SECTION2_REPORT_PATH)
```

Then all your cells can just do:

```python
_append_sec2(sec2_chunk_2101)
```

You get:

* **Proper** library design (append_sec2 is generic + explicit),
* **Pleasant** notebook usage (no need to repeat the path everywhere).

---

## 3. What *not* to do (and why)

If you changed `append_sec2` to *internally* assume a global path like:

```python
def append_sec2(chunk: pd.DataFrame) -> Path:
    path = SECTION2_REPORT_PATH  # from globals()
    ...
```

That would be:

* tightly coupled to one environment / notebook,
* harder to reuse in other projects,
* more brittle (breaks if SECTION2_REPORT_PATH isn‚Äôt defined).

So from a DataOps / analytics-engineering perspective, **keeping `report_path` as an argument is the more professional design.**

---

### TL;DR

* **Most proper:** keep `append_sec2(chunk, report_path)` as-is in `reporting.py`.
* In your notebook, define `SECTION2_REPORT_PATH` once and a wrapper `_append_sec2(chunk)` for convenience.
* Don‚Äôt bake the path into `append_sec2` itself.
