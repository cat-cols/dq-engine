Yep ‚Äî this is a **clean 2.1.7A audit**, and the output you showed proves it‚Äôs working. The crash is simply because you‚Äôre calling a helper you haven‚Äôt imported/defined in this notebook/kernel:

> `NameError: name 'log_section_completion' is not defined`

Here‚Äôs the step-by-step fix (and a couple quick upgrades to make the dtype matching more correct for pandas).

---

## 1) Fix the crash (minimal, safest)

### Option 1 (recommended): guard the call (no new imports required)

Replace:

```python
log_section_completion(
    "2.1.7A",
    status_217A,
    checked=n_checked_217A,
    mismatched=n_mismatched_217A,
)
```

with:

```python
if "log_section_completion" in globals() and callable(globals()["log_section_completion"]):
    log_section_completion(
        "2.1.7A",
        status_217A,
        checked=n_checked_217A,
        mismatched=n_mismatched_217A,
    )
else:
    print("‚ÑπÔ∏è log_section_completion not available; skipping section completion log.")
```

‚úÖ Result: your cell will run everywhere, including ‚Äúfresh kernel‚Äù runs.

---

### Option 2: import it (only if you actually have it in src)

At the top of Section 2 where you import helpers (your Part 8), add:

```python
from telco_churn.utils.reporting import log_section_completion
```

‚Ä¶but only do this if that function actually exists there.

---

## 2) Your dtype mismatches are ‚Äúfalse mismatches‚Äù right now

Example from your report:

* expected: `"string"`
* actual: `"object"`
  That‚Äôs not ‚Äúwrong‚Äù ‚Äî it‚Äôs just pandas representation. Same with:
* expected: `"Int64"` (nullable integer)
* actual: `"int64"` (numpy int)

### Fix: normalize dtype names before comparing

Add this small mapper **inside your 2.1.7 cell** (no new function needed if you don‚Äôt want one):

```python
_dtype_alias = {
    "string": "string",
    "string[python]": "string",
    "object": "string",          # treat object as string-ish for your schema
    "int64": "Int64",            # treat numpy ints as compatible with nullable Int64
    "int32": "Int64",
    "float64": "float64",
    "bool": "boolean",
    "boolean": "boolean",
    "datetime64[ns]": "datetime64[ns]",
}

def _norm_dtype(x):
    if x is None:
        return None
    s = str(x)
    return _dtype_alias.get(s, s)
```

Then change:

```python
matches_expected = (actual_dtype == expected_str) if actual_dtype is not None else False
```

to:

```python
matches_expected = (_norm_dtype(actual_dtype) == _norm_dtype(expected_str)) if actual_dtype is not None else False
```

‚úÖ Result: your audit will stop flagging ‚Äúobject vs string‚Äù as failures if you want them treated as equivalent.

> üí°üí° If you *do* want to enforce pandas `string` dtype specifically (not object), then don‚Äôt alias `object -> string`. Keep it strict.

---

## 3) Fix the ‚Äúempty expected schema‚Äù branch (minor cleanup)

You currently do:

```python
expected_dtypes_cfg = CONFIG.get("SCHEMA_EXPECTED_DTYPES")
if expected_dtypes_cfg is None:
    expected_dtypes = {}
elif isinstance(expected_dtypes_cfg, dict):
    expected_dtypes = dict(expected_dtypes_cfg)
else:
    expected_dtypes = {}
```

That‚Äôs fine, but make the intent explicit and log when skipped:

```python
expected_dtypes_cfg = CONFIG.get("SCHEMA_EXPECTED_DTYPES") or {}
expected_dtypes = dict(expected_dtypes_cfg) if isinstance(expected_dtypes_cfg, dict) else {}

if not expected_dtypes:
    print("‚ÑπÔ∏è CONFIG.SCHEMA_EXPECTED_DTYPES missing/empty ‚Üí dtype audit will SKIP.")
```

---

## 4) One more bug waiting to happen: atomic write directory safety

Before writing:

```python
dtype_baseline_df.to_csv(tmp, index=False)
os.replace(tmp, dtype_baseline_path)
```

Add:

```python
dtype_baseline_path.parent.mkdir(parents=True, exist_ok=True)
dtype_enforcement_path.parent.mkdir(parents=True, exist_ok=True)
```

You‚Äôre already using `SEC2_REPORTS_DIR`, but this makes the cell resilient if that ever shifts.

---

## 5) Your output shows the real ‚Äúpolicy decision‚Äù you need

Right now your schema expects a lot of `"string"` but pandas reads as `"object"`.

So decide **one** of these:

### Policy A (pragmatic)

* Treat `object` as acceptable for ‚Äústring-like‚Äù
* Only warn if something is truly off (e.g., numeric where string expected)

### Policy B (strict engineering)

* Require actual dtype == pandas `string` (and later add a 2.1.7B coercion step)

Given you labeled this **audit-only**, Policy A is usually what you want.

---

## Drop-in patch for your exact crash (copy/paste)

Put this right where you call `log_section_completion`:

```python
# --- Optional logging helper (guard) ---
if "log_section_completion" in globals() and callable(globals()["log_section_completion"]):
    log_section_completion(
        "2.1.7A",
        status_217A,
        checked=n_checked_217A,
        mismatched=n_mismatched_217A,
    )
else:
    print("‚ÑπÔ∏è log_section_completion not available; skipping section completion log.")
```

That alone fixes the exception immediately.

---

If you want, I can also show you a **2.1.7B ‚Äúenforcement/coercion step‚Äù** that:

* only attempts coercion on mismatches,
* records `n_coercion_fail` and sample failing values,
* writes a separate ‚Äúdtype_changes_applied.csv‚Äù,
* and never silently changes `df` unless a `CONFIG.FLAGS.ENFORCE_DTYPES = true` toggle is on.


---
---

># FIX 2

Yes ‚Äî it **is skipping**, but **not silently**: your guard prints

> `‚ÑπÔ∏è log_section_completion not available; skipping section completion log.`

So you‚Äôre good: it won‚Äôt crash, and you still append to the unified report via `append_sec2()`.

That said, if you want this ‚Äútask completion log‚Äù to be **real** (and not just a print), you have two clean patterns:

---

# Pattern 1 (recommended): Always complete the task, optionally use helper if present

You already have the right idea. Make it explicit by defining a *single fallback path* that writes a small JSON/CSV ‚Äúcompletion log‚Äù artifact when the helper doesn‚Äôt exist.

## Drop-in block (copy/paste) for the end of 2.1.7A

Put this **right after** you build `sec2_chunk_217A` (before/after `append_sec2` is fine):

```python
# --- Completion logging: use helper if available, else write a lightweight artifact ---
completion_payload = {
    "section": "2.1.7A",
    "status": status_217A,
    "checked": int(n_checked_217A),
    "mismatched": int(n_mismatched_217A),
    "timestamp_utc": datetime.now(timezone.utc).isoformat(timespec="seconds").replace("+00:00", "Z"),
    "detail": f"Baseline: {dtype_baseline_path.name}; Enforcement: {dtype_enforcement_path.name}",
}

if "log_section_completion" in globals() and callable(globals()["log_section_completion"]):
    log_section_completion(
        "2.1.7A",
        status_217A,
        checked=n_checked_217A,
        mismatched=n_mismatched_217A,
    )
else:
    # Fallback: write a simple completion JSON (atomic)
    completion_dir = (SEC2_ARTIFACTS_DIR / "completion").resolve()
    completion_dir.mkdir(parents=True, exist_ok=True)

    completion_path = (completion_dir / "section_2_1_7A_completion.json").resolve()
    tmp = completion_path.with_suffix(".tmp.json")
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(completion_payload, f, indent=2)
    os.replace(tmp, completion_path)

    print(f"‚ÑπÔ∏è log_section_completion not available; wrote fallback completion ‚Üí {completion_path}")
```

‚úÖ Result:

* With helper: uses it
* Without helper: still produces a durable ‚Äúcompletion log‚Äù artifact (so the task is *actually completed*)

---

# Pattern 2: Implement `log_section_completion` once (simple, reusable)

If you want the function ‚Äúactivated,‚Äù create it in your `src/` so every notebook can import it.

## A solid minimal implementation

Create: `telco_churn/utils/reporting.py` (or wherever your `append_sec2` lives) and add:

```python
from __future__ import annotations
from pathlib import Path
from datetime import datetime, timezone
import json
import os

def log_section_completion(
    section: str,
    status: str,
    *,
    checked: int | None = None,
    mismatched: int | None = None,
    notes: str | None = None,
    out_dir: str | Path | None = None,
) -> Path:
    """
    Write a small JSON completion record for a section.
    - Always safe to call.
    - Atomic write.
    """
    out_dir = Path(out_dir) if out_dir is not None else Path.cwd()
    out_dir.mkdir(parents=True, exist_ok=True)

    payload = {
        "section": str(section),
        "status": str(status),
        "checked": int(checked) if checked is not None else None,
        "mismatched": int(mismatched) if mismatched is not None else None,
        "notes": notes,
        "timestamp_utc": datetime.now(timezone.utc)
            .isoformat(timespec="seconds")
            .replace("+00:00", "Z"),
    }

    path = (out_dir / f"section_{section.replace('.', '_')}_completion.json").resolve()
    tmp = path.with_suffix(".tmp.json")
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(payload, f, indent=2)
    os.replace(tmp, path)
    return path
```

Then in your notebook (Part 8 import area), do:

```python
from telco_churn.utils.reporting import append_sec2, log_section_completion
```

And call it like this:

```python
completion_path = log_section_completion(
    "2.1.7A",
    status_217A,
    checked=n_checked_217A,
    mismatched=n_mismatched_217A,
    out_dir=(SEC2_ARTIFACTS_DIR / "completion"),
)
print("‚úÖ completion log ‚Üí", completion_path)
```

‚úÖ Result: now it‚Äôs ‚Äúactivated‚Äù and consistent everywhere.

---

# Two quick fixes in your current 2.1.7 code (important)

### 1) You call `dtype_enforcement_path.parent.mkdir(...)` before `dtype_enforcement_path` exists

Right now you do:

```python
dtype_baseline_path = ...
...
dtype_baseline_path.parent.mkdir(...)
dtype_enforcement_path.parent.mkdir(...)  # <-- dtype_enforcement_path not defined yet
```

Fix by defining both paths first:

```python
dtype_baseline_path = SEC2_REPORTS_DIR / "dtype_baseline_report.csv"
dtype_enforcement_path = SEC2_REPORTS_DIR / "dtype_enforcement_report.csv"

dtype_baseline_path.parent.mkdir(parents=True, exist_ok=True)
dtype_enforcement_path.parent.mkdir(parents=True, exist_ok=True)
```

### 2) You define `_dtype_alias` and `_norm_dtype` inside the loop

It works, but it‚Äôs wasteful and noisy. Move them **above** the loop.

---

# What you should do next

If you want the cleanest architecture:

* **Use Pattern 1** inside the notebook **today** (guaranteed no imports required).
* Later, when you‚Äôre ready, implement Pattern 2 in `src/` and import it everywhere.

If you want, paste your current `telco_churn/utils/reporting.py` (or the file where `append_sec2` lives), and I‚Äôll show you exactly where to insert `log_section_completion` so it matches your existing style + registry conventions.
