# PART B | 2.5.7-2.5.9 ðŸ” Cross-Domain Consistency (Num â†” Cat Bridging)
print("PART B | 2.5.7-2.5.9 ðŸ” Cross-Domain Consistency (Num â†” Cat Bridging)")

# ðŸ§© Cross-Logic / Cross-Domain Layer
# Assumes:
#Â  Â - df is loaded
#Â  Â - pandas as pd, os, Path imported
#Â  Â - CONFIG and/or C() available
#Â  Â - SECTION2_REPORT_PATH and Section 2 summary pattern (like 2.5.6)
#Â  Â - pandas as pd, np, os, Path imported
#Â  Â - PROJECT_ROOT and/or REPORTS_DIR resolved by 2.0.x

n_rows_25B = int(df.shape[0])

# 2.5.7 | Categoricalâ€“Numeric Alignment Audit
print("\n2.5.7 ðŸ” Categoricalâ€“numeric alignment audit")

# 1) Pull CATNUM_ALIGNMENT.RULES from config
catnum_rules_257 = None

catnum_rules_257 = (globals().get("C") or CONFIG).get("CATNUM_ALIGNMENT", {}).get("RULES", {})

if "C" in globals() and callable(C):
Â  Â  try:
Â  Â  Â  Â  catnum_rules_257 = C("CATNUM_ALIGNMENT.RULES", None)
Â  Â  except Exception:
Â  Â  Â  Â  catnum_rules_257 = None

if catnum_rules_257 is None and "CONFIG" in globals():
Â  Â  cfg_257 = CONFIG
Â  Â  for _k_257 in "CATNUM_ALIGNMENT.RULES".split("."):
Â  Â  Â  Â  if isinstance(cfg_257, dict) and _k_257 in cfg_257:
Â  Â  Â  Â  Â  Â  cfg_257 = cfg_257[_k_257]
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  cfg_257 = None
Â  Â  Â  Â  Â  Â  break
Â  Â  if cfg_257 is not None:
Â  Â  Â  Â  catnum_rules_257 = cfg_257

alignment_rows_257 = []
n_rules_evaluated_257 = 0
n_rules_with_violations_257 = 0

if isinstance(catnum_rules_257, dict) and len(catnum_rules_257) > 0:
Â  Â  print(f"Â  Â ðŸ”§ CATNUM_ALIGNMENT.RULES found: {len(catnum_rules_257)} rule(s).")
Â  Â  for rule_id_257, rule_cfg_257 in catnum_rules_257.items():
Â  Â  Â  Â  if not isinstance(rule_cfg_257, dict):
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  rule_id_257 = str(rule_id_257)
Â  Â  Â  Â  group_col_257 = str(rule_cfg_257.get("group_col", "") or "").strip()
Â  Â  Â  Â  numeric_col_257 = str(rule_cfg_257.get("numeric_col", "") or "").strip()
Â  Â  Â  Â  expectation_257 = str(rule_cfg_257.get("expectation", "") or "").strip()
Â  Â  Â  Â  group_order_257 = rule_cfg_257.get("group_order", None)

Â  Â  Â  Â  if not group_col_257 or not numeric_col_257:
Â  Â  Â  Â  Â  Â  alignment_rows_257.append(
Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_id": rule_id_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_col": group_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_value": "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "numeric_col": numeric_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "mean_value": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "median_value": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "count": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "expected_relation": expectation_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_flag": False,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_gap": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_severity": "info",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "notes": "Missing group_col or numeric_col in rule config",
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  if group_col_257 not in df.columns or numeric_col_257 not in df.columns:
Â  Â  Â  Â  Â  Â  alignment_rows_257.append(
Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_id": rule_id_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_col": group_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_value": "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "numeric_col": numeric_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "mean_value": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "median_value": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "count": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "expected_relation": expectation_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_flag": False,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_gap": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_severity": "info",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "notes": "group_col or numeric_col not found in df; rule skipped",
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  # We consider this rule evaluated
Â  Â  Â  Â  n_rules_evaluated_257 += 1

Â  Â  Â  Â  # 2) Build grouped numeric stats
Â  Â  Â  Â  sub_257 = df[[group_col_257, numeric_col_257]].copy()
Â  Â  Â  Â  sub_257[numeric_col_257] = pd.to_numeric(sub_257[numeric_col_257], errors="coerce")
Â  Â  Â  Â  sub_257 = sub_257.dropna(subset=[group_col_257, numeric_col_257])

Â  Â  Â  Â  if sub_257.empty:
Â  Â  Â  Â  Â  Â  alignment_rows_257.append(
Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_id": rule_id_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_col": group_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_value": "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "numeric_col": numeric_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "mean_value": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "median_value": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "count": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "expected_relation": expectation_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_flag": False,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_gap": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_severity": "info",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "notes": "No valid rows (after NA filtering) to evaluate",
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  grp_257 = (
Â  Â  Â  Â  Â  Â  sub_257.groupby(group_col_257)[numeric_col_257]
Â  Â  Â  Â  Â  Â  .agg(["mean", "median", "count", "std", "min", "max"])
Â  Â  Â  Â  Â  Â  .reset_index()
Â  Â  Â  Â  Â  Â  .rename(columns={group_col_257: "group_value"})
Â  Â  Â  Â  )

Â  Â  Â  Â  if group_order_257 and isinstance(group_order_257, (list, tuple)):
Â  Â  Â  Â  Â  Â  grp_257["__order_key_257"] = grp_257["group_value"].apply(
Â  Â  Â  Â  Â  Â  Â  Â  lambda x: group_order_257.index(x) if x in group_order_257 else len(group_order_257)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  grp_257 = grp_257.sort_values("__order_key_257").drop(columns=["__order_key_257"])
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  grp_257 = grp_257.sort_values("group_value")

Â  Â  Â  Â  grp_257["violation_flag"] = False
Â  Â  Â  Â  grp_257["violation_gap"] = 0.0

Â  Â  Â  Â  # 3) Apply expectation logic (only monotonic expectations supported here)
Â  Â  Â  Â  if expectation_257 in ("monotonic_increasing", "monotonic_decreasing") and len(grp_257) > 1:
Â  Â  Â  Â  Â  Â  means_257 = grp_257["mean"].tolist()
Â  Â  Â  Â  Â  Â  idxs_257 = grp_257.index.tolist()

Â  Â  Â  Â  Â  Â  total_violations_rule_257 = 0
Â  Â  Â  Â  Â  Â  for i_257 in range(1, len(means_257)):
Â  Â  Â  Â  Â  Â  Â  Â  prev_mean_257 = means_257[i_257 - 1]
Â  Â  Â  Â  Â  Â  Â  Â  curr_mean_257 = means_257[i_257]
Â  Â  Â  Â  Â  Â  Â  Â  if pd.isna(prev_mean_257) or pd.isna(curr_mean_257):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  Â  Â  if expectation_257 == "monotonic_increasing" and curr_mean_257 < prev_mean_257:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gap_257 = float(prev_mean_257 - curr_mean_257)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  grp_257.loc[idxs_257[i_257], "violation_flag"] = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  grp_257.loc[idxs_257[i_257], "violation_gap"] = gap_257
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  total_violations_rule_257 += 1
Â  Â  Â  Â  Â  Â  Â  Â  elif expectation_257 == "monotonic_decreasing" and curr_mean_257 > prev_mean_257:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gap_257 = float(curr_mean_257 - prev_mean_257)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  grp_257.loc[idxs_257[i_257], "violation_flag"] = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  grp_257.loc[idxs_257[i_257], "violation_gap"] = gap_257
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  total_violations_rule_257 += 1
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  total_violations_rule_257 = int(grp_257["violation_flag"].sum())

Â  Â  Â  Â  # 4) Determine rule-level severity
Â  Â  Â  Â  if len(grp_257) == 0:
Â  Â  Â  Â  Â  Â  rule_severity_257 = "info"
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  if total_violations_rule_257 == 0:
Â  Â  Â  Â  Â  Â  Â  Â  rule_severity_257 = "ok"
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  frac_viol_257 = float(total_violations_rule_257) / float(len(grp_257))
Â  Â  Â  Â  Â  Â  Â  Â  if frac_viol_257 <= 0.25:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rule_severity_257 = "warn"
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rule_severity_257 = "fail"
Â  Â  Â  Â  Â  Â  Â  Â  n_rules_with_violations_257 += 1

Â  Â  Â  Â  # 5) Append per-group rows
Â  Â  Â  Â  for idx_row_257, row_257 in grp_257.iterrows():
Â  Â  Â  Â  Â  Â  alignment_rows_257.append(
Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_id": rule_id_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_col": group_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_value": row_257["group_value"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "numeric_col": numeric_col_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "mean_value": float(row_257["mean"]) if pd.notna(row_257["mean"]) else float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "median_value": float(row_257["median"]) if pd.notna(row_257["median"]) else float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "count": int(row_257["count"]),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "expected_relation": expectation_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_flag": bool(row_257["violation_flag"]),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "violation_gap": float(row_257["violation_gap"]),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "rule_severity": rule_severity_257,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "notes": "",
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
else:
Â  Â  print("Â  Â â„¹ï¸ No CATNUM_ALIGNMENT.RULES config found; 2.5.7 will record INFO status with no rule checks.")

alignment_df_257 = pd.DataFrame(alignment_rows_257)
alignment_path_257 = sec25_reports_dir / "catnum_alignment_report.csv"
alignment_tmp_257 = alignment_path_257.with_suffix(".tmp.csv")

if not alignment_df_257.empty:
Â  Â  try:
Â  Â  Â  Â  alignment_df_257.to_csv(alignment_tmp_257, index=False)
Â  Â  Â  Â  os.replace(alignment_tmp_257, alignment_path_257)
Â  Â  except Exception:
Â  Â  Â  Â  if alignment_tmp_257.exists():
Â  Â  Â  Â  Â  Â  alignment_tmp_257.unlink()

status_257 = "INFO"
if isinstance(catnum_rules_257, dict) and len(catnum_rules_257) > 0:
Â  Â  if n_rules_with_violations_257 == 0:
Â  Â  Â  Â  status_257 = "OK"
Â  Â  else:
Â  Â  Â  Â  status_257 = "WARN"

print(f"ðŸ’¾ 2.5.7 catnum_alignment_report.csv â†’ {alignment_path_257}")
print(f"Â  Â Rules evaluated: {n_rules_evaluated_257} | with violations: {n_rules_with_violations_257}")
if not alignment_df_257.empty:
Â  Â  print("Â  Â ðŸ“‹ Alignment preview (top 10):")
Â  Â  display(
Â  Â  Â  Â  alignment_df_257.loc[
Â  Â  Â  Â  Â  Â  :, ["rule_id", "group_col", "group_value", "numeric_col",
Â  Â  Â  Â  Â  Â  Â  Â  "mean_value", "count", "expected_relation",
Â  Â  Â  Â  Â  Â  Â  Â  "violation_flag", "violation_gap", "rule_severity"]
Â  Â  Â  Â  ].head(10)
Â  Â  )

#
summary_257 = pd.DataFrame([{
Â  Â  "section": "2.5.7",
Â  Â  "section_name": "Categoricalâ€“numeric alignment audit",
Â  Â  "check": "Validate numeric patterns within categories against configured expectations",
Â  Â  "level": "info",
Â  Â  "status": status_257,
Â  Â  "n_rules_evaluated": int(n_rules_evaluated_257),
Â  Â  "n_rules_with_violations": int(n_rules_with_violations_257),
Â  Â  "detail": "catnum_alignment_report.csv",
Â  Â  "timestamp": pd.Timestamp.utcnow(),
Â  Â  "notes": f"Evaluated {n_rules_evaluated_257} rules; {n_rules_with_violations_257} had violations"
}])
append_sec2(summary_257, SECTION2_REPORT_PATH)

display(summary_257)

# 2.5.8 | One-Hot Sum Integrity (Encoding Cross-Check)
print("\n2.5.8 ðŸ” One-hot sum integrity (encoding cross-check)")

# TODO:
# 3V2) Derive summary metrics
# n_groups_configured_258 = len(onehot_cfg_258) if isinstance(onehot_cfg_258, dict) else 0
# n_groups_valid_cfg_258 = int(n_groups_checked_258)

# if not onehot_df_258.empty:
#Â  Â  Â # "evaluated" = at least one column existed in df, so n_rows > 0
#Â  Â  Â n_groups_evaluated_258 = int((onehot_df_258["n_rows"] > 0).sum())
# else:
#Â  Â  Â n_groups_evaluated_258 = 0

# 1) Pull ONEHOT.GROUPS from config
onehot_cfg_258 = None

if "C" in globals() and callable(C):
Â  Â  try:
Â  Â  Â  Â  onehot_cfg_258 = C("ONEHOT.GROUPS", None)
Â  Â  except Exception:
Â  Â  Â  Â  onehot_cfg_258 = None

if onehot_cfg_258 is None and "CONFIG" in globals():
Â  Â  _cfg_258 = CONFIG
Â  Â  for _k_258 in "ONEHOT.GROUPS".split("."):
Â  Â  Â  Â  if isinstance(_cfg_258, dict) and _k_258 in _cfg_258:
Â  Â  Â  Â  Â  Â  _cfg_258 = _cfg_258[_k_258]
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  _cfg_258 = None
Â  Â  Â  Â  Â  Â  break
Â  Â  if _cfg_258 is not None:
Â  Â  Â  Â  onehot_cfg_258 = _cfg_258

onehot_rows_258 = []
n_groups_checked_258 = 0
n_groups_with_violations_258 = 0

if isinstance(onehot_cfg_258, dict) and len(onehot_cfg_258) > 0:
Â  Â  print(f"Â  Â ðŸ”§ ONEHOT.GROUPS found: {len(onehot_cfg_258)} group(s).")
Â  Â  for _gid_258, _gcfg_258 in onehot_cfg_258.items():
Â  Â  Â  Â  if not isinstance(_gcfg_258, dict):
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  group_id_258 = str(_gid_258)
Â  Â  Â  Â  cols_258 = _gcfg_258.get("columns", [])
Â  Â  Â  Â  mode_258 = str(_gcfg_258.get("mode", "mutually_exclusive") or "mutually_exclusive").strip()

Â  Â  Â  Â  if not isinstance(cols_258, (list, tuple)) or len(cols_258) == 0:
Â  Â  Â  Â  Â  Â  onehot_rows_258.append(
Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_id": group_id_258,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "mode": mode_258,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "columns": "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_rows": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_all_zero": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_single": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_multi": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "pct_all_zero": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "pct_multi": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_severity": "info",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "notes": "No columns configured for group",
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  missing_cols_258 = [c for c in cols_258 if c not in df.columns]
Â  Â  Â  Â  present_cols_258 = [c for c in cols_258 if c in df.columns]

Â  Â  Â  Â  if not present_cols_258:
Â  Â  Â  Â  Â  Â  onehot_rows_258.append(
Â  Â  Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_id": group_id_258,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "mode": mode_258,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "columns": ", ".join(cols_258),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_rows": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_all_zero": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_single": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "n_multi": 0,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "pct_all_zero": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "pct_multi": float("nan"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "group_severity": "info",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "notes": f"All configured columns missing from df: {', '.join(missing_cols_258)}",
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  n_groups_checked_258 += 1

Â  Â  Â  Â  _flags_258 = df[present_cols_258].copy()
Â  Â  Â  Â  for _c_258 in present_cols_258:
Â  Â  Â  Â  Â  Â  _flags_258[_c_258] = pd.to_numeric(_flags_258[_c_258], errors="coerce").fillna(0.0)

Â  Â  Â  Â  row_sum_258 = _flags_258.sum(axis=1)

Â  Â  Â  Â  n_rows_grp_258 = int(len(row_sum_258))
Â  Â  Â  Â  n_all_zero_258 = int((row_sum_258 == 0).sum())
Â  Â  Â  Â  n_single_258 = int((row_sum_258 == 1).sum())
Â  Â  Â  Â  n_multi_258 = int((row_sum_258 > 1).sum())

Â  Â  Â  Â  pct_all_zero_258 = float(n_all_zero_258) / float(n_rows_grp_258) if n_rows_grp_258 > 0 else float("nan")
Â  Â  Â  Â  pct_multi_258 = float(n_multi_258) / float(n_rows_grp_258) if n_rows_grp_258 > 0 else float("nan")

Â  Â  Â  Â  # Severity based on mode
Â  Â  Â  Â  if n_rows_grp_258 == 0:
Â  Â  Â  Â  Â  Â  group_severity_258 = "info"
Â  Â  Â  Â  Â  Â  notes_258 = "No rows to evaluate"
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  if mode_258 == "mutually_exclusive":
Â  Â  Â  Â  Â  Â  Â  Â  if n_multi_258 == 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  group_severity_258 = "ok"
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pct_multi_258 <= 0.01 and n_multi_258 <= 10:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  group_severity_258 = "warn"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  group_severity_258 = "fail"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  n_groups_with_violations_258 += 1
Â  Â  Â  Â  Â  Â  Â  Â  notes_258 = ""
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # "one_or_more" or other modes: watch all-zero pattern
Â  Â  Â  Â  Â  Â  Â  Â  if n_all_zero_258 == 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  group_severity_258 = "ok"
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pct_all_zero_258 <= 0.1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  group_severity_258 = "warn"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  group_severity_258 = "fail"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  n_groups_with_violations_258 += 1
Â  Â  Â  Â  Â  Â  Â  Â  notes_258 = ""

Â  Â  Â  Â  if missing_cols_258:
Â  Â  Â  Â  Â  Â  if notes_258:
Â  Â  Â  Â  Â  Â  Â  Â  notes_258 = notes_258 + "; "
Â  Â  Â  Â  Â  Â  notes_258 = notes_258 + f"Missing columns: {', '.join(missing_cols_258)}"

Â  Â  Â  Â  onehot_rows_258.append(
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  "group_id": group_id_258,
Â  Â  Â  Â  Â  Â  Â  Â  "mode": mode_258,
Â  Â  Â  Â  Â  Â  Â  Â  "columns": ", ".join(cols_258),
Â  Â  Â  Â  Â  Â  Â  Â  "n_rows": int(n_rows_grp_258),
Â  Â  Â  Â  Â  Â  Â  Â  "n_all_zero": int(n_all_zero_258),
Â  Â  Â  Â  Â  Â  Â  Â  "n_single": int(n_single_258),
Â  Â  Â  Â  Â  Â  Â  Â  "n_multi": int(n_multi_258),
Â  Â  Â  Â  Â  Â  Â  Â  "pct_all_zero": float(pct_all_zero_258),
Â  Â  Â  Â  Â  Â  Â  Â  "pct_multi": float(pct_multi_258),
Â  Â  Â  Â  Â  Â  Â  Â  "group_severity": group_severity_258,
Â  Â  Â  Â  Â  Â  Â  Â  "notes": notes_258,
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  )
else:
Â  Â  print("Â  Â â„¹ï¸ No ONEHOT.GROUPS config found; 2.5.8 will record INFO status with no group checks.")

onehot_df_258 = pd.DataFrame(onehot_rows_258)
onehot_path_258 = sec25_reports_dir / "onehot_integrity_report.csv"
onehot_tmp_258 = onehot_path_258.with_suffix(".tmp.csv")

# 2) Persist report
if not onehot_df_258.empty:
Â  Â  try:
Â  Â  Â  Â  onehot_df_258.to_csv(onehot_tmp_258, index=False)
Â  Â  Â  Â  os.replace(onehot_tmp_258, onehot_path_258)
Â  Â  except Exception:
Â  Â  Â  Â  if onehot_tmp_258.exists():
Â  Â  Â  Â  Â  Â  onehot_tmp_258.unlink()

# 3V1)
n_groups_configured_258 = len(onehot_cfg_258) if isinstance(onehot_cfg_258, dict) else 0

if not onehot_df_258.empty:
Â  Â  # "valid config" = has a non-empty columns string
Â  Â  n_groups_valid_cfg_258 = int(onehot_df_258["columns"].str.len().gt(0).sum())
Â  Â  # "evaluated" = at least one row (i.e., at least one column existed in df)
Â  Â  n_groups_evaluated_258 = int((onehot_df_258["n_rows"] > 0).sum())
else:
Â  Â  n_groups_valid_cfg_258 = 0
Â  Â  n_groups_evaluated_258 = 0

status_258 = "INFO"
if n_groups_configured_258 > 0:
Â  Â  # If we actually evaluated any rows, interpret violations as WARN
Â  Â  if n_groups_evaluated_258 > 0:
Â  Â  Â  Â  status_258 = "OK" if n_groups_with_violations_258 == 0 else "WARN"
Â  Â  else:
Â  Â  Â  Â  status_258 = "INFO"Â  # config-only run, no row-wise checks performed

summary_258 = pd.DataFrame([{
Â  Â  "section": "2.5.8",
Â  Â  "section_name": "One-hot sum integrity (encoding cross-check)",
Â  Â  "check": "Validate mutually exclusive and grouped dummy columns via row-wise sums",
Â  Â  "level": "info",
Â  Â  "status": status_258,
Â  Â  "n_groups_configured": int(n_groups_configured_258),
Â  Â  "n_groups_valid_config": int(n_groups_valid_cfg_258),
Â  Â  "n_groups_evaluated": int(n_groups_evaluated_258),
Â  Â  "n_groups_with_violations": int(n_groups_with_violations_258),
Â  Â  "detail": "onehot_integrity_report.csv",
Â  Â  "timestamp": pd.Timestamp.utcnow(),
}])

append_sec2(summary_258, SECTION2_REPORT_PATH)
display(summary_258)

# 4) Console UX
print(f"ðŸ’¾ 2.5.8 onehot_integrity_report.csv â†’ {onehot_path_258}")
print(f"Â  Â Groups configured: {n_groups_configured_258}")
print(f"Â  Â Groups with valid column config: {n_groups_valid_cfg_258}")
print(f"Â  Â Groups evaluated (cols present in df): {n_groups_evaluated_258}")
print(f"Â  Â Groups with violations: {n_groups_with_violations_258}")

if n_groups_configured_258 == 0:
Â  Â  print("Â  Â â„¹ï¸ No ONEHOT.GROUPS config found; 2.5.8 recorded INFO status only.")
elif n_groups_evaluated_258 == 0:
Â  Â  print("Â  Â â„¹ï¸ All configured groups had missing columns in df; "
Â  Â  Â  Â  Â  "this run recorded config only (no row-wise integrity checks).")

if not onehot_df_258.empty:
Â  Â  # Show problematic groups first if any, otherwise just a small sample
Â  Â  problem_mask_258 = onehot_df_258["group_severity"].isin(["warn", "fail"])
Â  Â  if problem_mask_258.any():
Â  Â  Â  Â  print("Â  Â ðŸ”Ž Preview of groups with issues (warn/fail):")
Â  Â  Â  Â  preview_258 = onehot_df_258.loc[
Â  Â  Â  Â  Â  Â  problem_mask_258,
Â  Â  Â  Â  Â  Â  [
Â  Â  Â  Â  Â  Â  Â  Â  "group_id", "mode", "n_rows", "n_all_zero", "n_single", "n_multi",
Â  Â  Â  Â  Â  Â  Â  Â  "pct_all_zero", "pct_multi", "group_severity", "notes",
Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  ].head(10)
Â  Â  else:
Â  Â  Â  Â  print("Â  Â ðŸ“‹ One-hot integrity preview (top 10):")
Â  Â  Â  Â  preview_258 = onehot_df_258.loc[
Â  Â  Â  Â  Â  Â  :,
Â  Â  Â  Â  Â  Â  [
Â  Â  Â  Â  Â  Â  Â  Â  "group_id", "mode", "n_rows", "n_all_zero", "n_single", "n_multi",
Â  Â  Â  Â  Â  Â  Â  Â  "pct_all_zero", "pct_multi", "group_severity", "notes",
Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  ].head(10)

Â  Â  display(preview_258)

# 2.5.9 ðŸ§¾ Reporting: reconciliation helper stats + ledger row
print("\n2.5.9 ðŸ§¾ Reporting: reconciliation helper stats + ledger row")

helpers_259 = [
Â  Â  "expected_total_from_tenure_monthly",
Â  Â  "expected_total_for_zero_tenure",
Â  Â  "expected_min_total_from_contract",
Â  Â  "expected_total_senior",
Â  Â  "expected_total_from_payment_profile",
]

created_259 = [c for c in helpers_259 if c in df.columns]
missing_259 = [c for c in helpers_259 if c not in df.columns]

# Per-helper stats artifact (min/max/mean + basic coverage)
stats_rows_259 = []

for c in helpers_259:
Â  Â  if c not in df.columns:
Â  Â  Â  Â  stats_rows_259.append({
Â  Â  Â  Â  Â  Â  "helper": c,
Â  Â  Â  Â  Â  Â  "present": False,
Â  Â  Â  Â  Â  Â  "n_total_rows": int(len(df)),
Â  Â  Â  Â  Â  Â  "n_nonnull": 0,
Â  Â  Â  Â  Â  Â  "pct_nonnull": 0.0,
Â  Â  Â  Â  Â  Â  "min": None,
Â  Â  Â  Â  Â  Â  "max": None,
Â  Â  Â  Â  Â  Â  "mean": None,
Â  Â  Â  Â  Â  Â  "note": "missing_helper_column",
Â  Â  Â  Â  })
Â  Â  Â  Â  continue

Â  Â  s = pd.to_numeric(df[c], errors="coerce")

Â  Â  n_total = int(len(s))
Â  Â  n_nonnull = int(s.notna().sum())
Â  Â  pct_nonnull = float(n_nonnull) / float(n_total) if n_total > 0 else float("nan")

Â  Â  # compute stats safely
Â  Â  _min = float(s.min()) if n_nonnull > 0 else None
Â  Â  _max = float(s.max()) if n_nonnull > 0 else None
Â  Â  _mean = float(s.mean()) if n_nonnull > 0 else None

Â  Â  stats_rows_259.append({
Â  Â  Â  Â  "helper": c,
Â  Â  Â  Â  "present": True,
Â  Â  Â  Â  "n_total_rows": n_total,
Â  Â  Â  Â  "n_nonnull": n_nonnull,
Â  Â  Â  Â  "pct_nonnull": pct_nonnull,
Â  Â  Â  Â  "min": _min,
Â  Â  Â  Â  "max": _max,
Â  Â  Â  Â  "mean": _mean,
Â  Â  Â  Â  "note": None,
Â  Â  })

recon_helpers_report_259 = pd.DataFrame(
Â  Â  stats_rows_259,
Â  Â  columns=["helper", "present", "n_total_rows", "n_nonnull", "pct_nonnull", "min", "max", "mean", "note"]
)

# Write artifact (atomic)
recon_report_path_259 = (sec25_reports_dir / "reconciliation_helpers_2_5_9_report.csv").resolve()
tmp_259 = recon_report_path_259.with_suffix(".tmp.csv")
recon_helpers_report_259.to_csv(tmp_259, index=False)
os.replace(tmp_259, recon_report_path_259)

print(f"ðŸ’¾ 2.5.9 helper stats report â†’ {recon_report_path_259}")
display(recon_helpers_report_259)

# Keep append_sec2 as ledger only (no full payload)
coverage_259 = {}
for c in created_259:
Â  Â  try:
Â  Â  Â  Â  coverage_259[c] = int(pd.to_numeric(df[c], errors="coerce").notna().sum())
Â  Â  except Exception:
Â  Â  Â  Â  coverage_259[c] = None

status_259 = "OK" if len(missing_259) == 0 else "WARN"
level_259 = "info" if status_259 == "OK" else "warn"

summary_259 = pd.DataFrame([{
Â  Â  "section": "2.5.9",
Â  Â  "section_name": "Reconciliation helper columns",
Â  Â  "check": "Create helper columns + write helper stats artifact (min/max/mean)",
Â  Â  "level": level_259,
Â  Â  "status": status_259,
Â  Â  "n_helpers_expected": int(len(helpers_259)),
Â  Â  "n_helpers_created": int(len(created_259)),
Â  Â  "helpers_created_json": json.dumps(created_259),
Â  Â  "helpers_missing_json": json.dumps(missing_259),
Â  Â  "coverage_nonnull_json": json.dumps(coverage_259, sort_keys=True),
Â  Â  "artifact": recon_report_path_259.name,
Â  Â  "timestamp": pd.Timestamp.utcnow(),
Â  Â  "detail": f"Helper stats written: {recon_report_path_259.name}",
Â  Â  "notes": None if status_259 == "OK" else "Some helper columns were skipped due to missing input columns.",
}])

append_sec2(summary_259, SECTION2_REPORT_PATH)
display(summary_259)

---------------------------------------------------------------------------
AttributeErrorÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Traceback (most recent call last)
Cell In[28], line 21
Â  Â  Â 18 # 1) Pull CATNUM_ALIGNMENT.RULES from config
Â  Â  Â 19 catnum_rules_257 = None
---> 21 catnum_rules_257 = (globals().get("C") or CONFIG).get("CATNUM_ALIGNMENT", {}).get("RULES", {})
Â  Â  Â 23 if "C" in globals() and callable(C):
Â  Â  Â 24Â  Â  Â try:

AttributeError: 'function' object has no attribute 'get'
 
Should this be written better

Yes, it definitely should. The error confirms that `C` is a function, and your current code is trying to treat it like a dictionary. Furthermore, you have **redundant fallback logic**â€”you're attempting to parse the config three different times in slightly different ways, which makes the code harder to maintain.

### The Refined Logic

We can collapse those 20+ lines of config-fetching into a single, clean block that prioritizes the helper function `C` but falls back to a nested `CONFIG.get()` approach.

**Replace lines 18 through 43 with this:**

```python
# 1) Pull CATNUM_ALIGNMENT.RULES from config
catnum_rules_257 = None

# Logic: Try helper function first; if it fails or isn't there, traverse CONFIG dict
if "C" in globals() and callable(C):
    try:
        catnum_rules_257 = C("CATNUM_ALIGNMENT.RULES", None)
    except Exception:
        pass

if catnum_rules_257 is None and "CONFIG" in globals():
    # Safe traversal of the dictionary
    catnum_rules_257 = CONFIG.get("CATNUM_ALIGNMENT", {}).get("RULES", {})

```

---

### Why this is "Written Better"

1. **Eliminates the AttributeError:** It checks if `C` is callable and uses it as a function, rather than trying to call `.get()` on it.
2. **Scannability:** Instead of three separate `if catnum_rules_257 is None` blocks, it uses a logical waterfall.
3. **Intellectual Honesty:** The original code had a manual loop (`for _k_257 in "CATNUM_ALIGNMENT.RULES".split(".")`) to find nested keys. While robust, it's overkill if you can simply use `.get("CATNUM", {}).get("RULES", {})`, which is standard Python practice.

### Visualizing the Bridge

This section (2.5.7) is critical because it acts as a "Logical Bridge" between your numeric values and categorical labels.

### Next Step for You

Once you fix the config block for **2.5.7**, you should also apply the same "Safe Fetch" pattern to **2.5.8** (the `ONEHOT.GROUPS` fetch). It currently contains similar logic that might be prone to the same confusion between functions and dictionaries.

**Would you like me to provide the clean version of the One-Hot config fetch as well?**

To keep your code clean and consistent, here is the refined "Safe Fetch" pattern for **2.5.8**. This replaces the redundant and potentially buggy logic in the One-Hot section while avoiding the `AttributeError`.

### Refined 2.5.8 Config Block

Replace the logic under `# 1) Pull ONEHOT.GROUPS from config` with this:

```python
# 1) Pull ONEHOT.GROUPS from config
onehot_cfg_258 = None

# Priority 1: Helper function C()
if "C" in globals() and callable(C):
    try:
        onehot_cfg_258 = C("ONEHOT.GROUPS", None)
    except Exception:
        pass

# Priority 2: Direct CONFIG dictionary access
if onehot_cfg_258 is None and "CONFIG" in globals():
    onehot_cfg_258 = CONFIG.get("ONEHOT", {}).get("GROUPS", {})

onehot_rows_258 = []
n_groups_checked_258 = 0
n_groups_with_violations_258 = 0

```

---

### Why this pattern is superior for Cross-Domain checks

This "Bridging" section is where you catch encoding bugs. For example, in **One-Hot Sum Integrity**, we are essentially verifying the **Law of Exclusivity**.

By calculating the row-wise sum of dummy variables:

1. **Sum = 1:** The encoding is perfect (Mutually Exclusive).
2. **Sum > 1:** Data leakage or overlapping categories (e.g., a customer is marked as both "Contract: Annual" and "Contract: Month-to-Month").
3. **Sum = 0:** An "Other" category or missing data (The "None of the Above" problem).

### Summary of the "Better" Code

| Feature | Old Version | Refined Version |
| --- | --- | --- |
| **Error Handling** | Crashed if `C` was a function. | Detects `callable(C)` and handles it correctly. |
| **Readability** | High nesting and manual string splitting. | Flat logic using `.get()` chaining. |
| **Consistency** | 2.5.7 and 2.5.8 used different patterns. | Both use the same "Waterfall" priority pattern. |

---

### Next Step

With these config blocks fixed, your script should run end-to-end without `AttributeErrors`.

**Would you like me to generate a "Final Audit" summary block that aggregates the statuses of 2.5.7, 2.5.8, and 2.5.9 into a single executive view?**