># Q: How should I fix the UserWarning and anything else that needs a fix

```python
# 2.2.1 üß¨ Auto-Detect Data Types (Column Type Map)
print("\n2.2.1 üß¨ Auto-detect data types")

# Basic guards
assert "df" in globals(), "‚ùå df is not defined. Run Section 1 & 2.1 first."
assert "REPORTS_DIR" in globals(), "‚ùå REPORTS_DIR missing."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing (2.0.1)."

#
SEC2_REPORTS_DIR   = REPORTS_DIR   / "section2"
SEC2_ARTIFACTS_DIR = ARTIFACTS_DIR / "section2"
SEC2_REPORTS_DIR.mkdir(parents=True, exist_ok=True)
SEC2_ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)

#
TYPE_DET_DIR = SEC2_REPORTS_DIR / "type_detection"
TYPE_DET_DIR.mkdir(parents=True, exist_ok=True)

n_rows, n_cols = df.shape
run_ts = datetime.now(timezone.utc).isoformat(timespec="seconds")

# --- Config-backed knobs with safe fallbacks
try:
    id_cols = set(C("ID_COLUMNS", []) or [])
except Exception:
    id_cols = set()

try:
    target_name = C("TARGET.COLUMN")
except Exception:
    target_name = None

try:
    numeric_pattern = C("TYPE_DETECTION.NUMERIC_REGEX", r'^[\+\-]?\d+(\.\d+)?$')
except Exception:
    numeric_pattern = r'^[\+\-]?\d+(\.\d+)?$'

try:
    numeric_threshold = float(C("TYPE_DETECTION.NUMERIC_THRESHOLD", 0.95))
except Exception:
    numeric_threshold = 0.95

try:
    bool_true_cfg = C("TYPE_DETECTION.BOOLEAN_TRUE_VALUES", ["true","t","yes","y","1"])
except Exception:
    bool_true_cfg = ["true","t","yes","y","1"]

try:
    bool_false_cfg = C("TYPE_DETECTION.BOOLEAN_FALSE_VALUES", ["false","f","no","n","0"])
except Exception:
    bool_false_cfg = ["false","f","no","n","0"]

bool_true_vals  = set(str(v).strip().lower() for v in bool_true_cfg)
bool_false_vals = set(str(v).strip().lower() for v in bool_false_cfg)

try:
    boolean_threshold = float(C("TYPE_DETECTION.BOOLEAN_THRESHOLD", 0.95))
except Exception:
    boolean_threshold = 0.95

try:
    datetime_sample_size = int(C("TYPE_DETECTION.DATETIME_SAMPLE_SIZE", 500))
except Exception:
    datetime_sample_size = 500

try:
    datetime_threshold = float(C("TYPE_DETECTION.DATETIME_THRESHOLD", 0.8))
except Exception:
    datetime_threshold = 0.8

# Try to incorporate structural info from 2.1.7 if available
feature_roles_map = {}
feature_group_map = {}
if "feature_roles_df" in globals():
    for _, r in feature_roles_df.iterrows():
        col_ = r["column"]
        feature_roles_map[col_] = str(r.get("role", ""))
        feature_group_map[col_] = str(r.get("feature_group", ""))

# Protected columns snapshot (optional)
if "protected_columns" in globals():
    protected_cols = set(protected_columns)
else:
    protected_cols = set()

rows_221 = []

for col in df.columns:
    s = df[col]
    dtype_str = str(s.dtype)
    dtype_lower = dtype_str.lower()

    # --- base type group from pandas dtype -----------------------------------
    if ("int" in dtype_lower) or ("float" in dtype_lower) or ("complex" in dtype_lower):
        type_group_base = "numeric"
    elif "bool" in dtype_lower:
        type_group_base = "boolean"
    elif ("datetime" in dtype_lower) or ("date" in dtype_lower):
        type_group_base = "datetime"
    elif "category" in dtype_lower:
        type_group_base = "categorical"
    else:
        type_group_base = "string_like"

    non_null = int(s.notna().sum())
    nulls    = int(s.isna().sum())
    null_pct = round((nulls / n_rows) * 100.0, 3) if n_rows else 0.0
    n_unique = int(s.nunique(dropna=True))

    # sample values for human inspection
    sample_values = (
        s.dropna()
         .astype("string")
         .head(5)
         .tolist()
    )

    pct_numeric_like   = 0.0
    pct_boolean_like   = 0.0
    pct_datetime_like  = 0.0
    numeric_like_flag  = False
    boolean_like_flag  = False
    datetime_like_flag = False

    if type_group_base == "string_like":
        s_str = s.astype("string").str.strip()
        non_empty_mask = (s_str != "")
        non_empty_count = int(non_empty_mask.sum())

        if non_empty_count > 0:
            # numeric-like
            is_numeric_like = s_str.str.match(numeric_pattern, na=False)
            pct_numeric_like = float((is_numeric_like & non_empty_mask).sum()) / non_empty_count
            numeric_like_flag = pct_numeric_like >= numeric_threshold

            # boolean-like
            norm = s_str[non_empty_mask].str.lower()
            valid_bool = norm.isin(bool_true_vals | bool_false_vals)
            pct_boolean_like = float(valid_bool.sum()) / non_empty_count
            boolean_like_flag = pct_boolean_like >= boolean_threshold

            # datetime-like (sampled)
            sample_dt = s_str[non_empty_mask].dropna().head(datetime_sample_size)
            if not sample_dt.empty:
                parsed = pd.to_datetime(sample_dt, errors="coerce")
                pct_datetime_like = float(parsed.notna().sum()) / len(sample_dt)
                datetime_like_flag = pct_datetime_like >= datetime_threshold

    # --- inferred type group + semantic type ---------------------------------
    type_group_inferred = type_group_base
    if type_group_base == "string_like":
        # precedence: boolean -> numeric -> datetime -> categorical
        if boolean_like_flag:
            type_group_inferred = "boolean"
        elif numeric_like_flag:
            type_group_inferred = "numeric"
        elif datetime_like_flag:
            type_group_inferred = "datetime"
        else:
            type_group_inferred = "categorical"

    # semantic_type for downstream coercion & semantics
    if type_group_base == "string_like" and numeric_like_flag and type_group_inferred == "numeric":
        semantic_type = "numeric_like_string"
    elif type_group_base == "string_like" and datetime_like_flag and type_group_inferred == "datetime":
        semantic_type = "datetime_like_string"
    elif type_group_base == "string_like" and boolean_like_flag and type_group_inferred == "boolean":
        semantic_type = "boolean_like_string"
    else:
        semantic_type = type_group_inferred

    is_id_col     = col in id_cols
    is_target_col = (col == target_name)

    role_val = feature_roles_map.get(col, "")
    feature_group_val = feature_group_map.get(col, "")
    is_protected = col in protected_cols

    rows_221.append(
        {
            "column":               col,
            "pandas_dtype":         dtype_str,
            "type_group_base":      type_group_base,
            "type_group_inferred":  type_group_inferred,
            "semantic_type":        semantic_type,
            "non_null":             non_null,
            "nulls":                nulls,
            "null_pct":             null_pct,
            "n_unique":             n_unique,
            "pct_numeric_like":     round(pct_numeric_like, 4),
            "numeric_like_flag":    numeric_like_flag,
            "pct_boolean_like":     round(pct_boolean_like, 4),
            "boolean_like_flag":    boolean_like_flag,
            "pct_datetime_like":    round(pct_datetime_like, 4),
            "datetime_like_flag":   datetime_like_flag,
            "sample_values":        json.dumps(sample_values),
            "is_id":                is_id_col,
            "is_target":            is_target_col,
            "role":                 role_val,
            "feature_group":        feature_group_val,
            "is_protected":         is_protected,
            "run_ts":               run_ts,
            "n_rows":               n_rows,
            "n_cols":               n_cols,
        }
    )

type_det_df = (
    pd.DataFrame(rows_221)
    .sort_values(["type_group_inferred", "column"])
    .reset_index(drop=True)
)

print("\nüìä 2.2.1 type detection summary (head):")
display(
    type_det_df[
        [
            "column",
            "pandas_dtype",
            "type_group_base",
            "type_group_inferred",
            "semantic_type",
            "n_unique",
            "null_pct",
            "pct_numeric_like",
            "pct_boolean_like",
            "pct_datetime_like",
        ]
    ].head(20)
)

# Write CSV summary
type_summary_path = TYPE_DET_DIR / "type_detection_summary.csv"
tmp_csv = type_summary_path.with_suffix(".tmp.csv")
type_det_df.to_csv(tmp_csv, index=False)
os.replace(tmp_csv, type_summary_path)
print(f"üíæ Wrote type detection summary ‚Üí {type_summary_path}")

# Write JSON column type map
column_type_map = {}
for _, r in type_det_df.iterrows():
    col = r["column"]
    column_type_map[col] = {
        "raw_dtype":         r["pandas_dtype"],
        "type_group":        r["type_group_inferred"],
        "semantic_type":     r["semantic_type"],
        "role":              r.get("role", ""),
        "feature_group":     r.get("feature_group", ""),
        "is_protected":      bool(r.get("is_protected", False)),
        "is_id":             bool(r.get("is_id", False)),
        "is_target":         bool(r.get("is_target", False)),
        "hints": {
            "n_unique":          int(r["n_unique"]),
            "null_pct":          float(r["null_pct"]),
            "pct_numeric_like":  float(r["pct_numeric_like"]),
            "pct_boolean_like":  float(r["pct_boolean_like"]),
            "pct_datetime_like": float(r["pct_datetime_like"]),
        },
    }

type_map_path = TYPE_DET_DIR / "column_type_map.json"
with open(type_map_path, "w", encoding="utf-8") as f:
    json.dump(column_type_map, f, indent=2)

print(f"üíæ Wrote column type map ‚Üí {type_map_path}")

# Append unified diagnostics row (2.2.1)
summary_221 = {
    "section":            "2.2.1",
    "section_name":       "Auto-detect data types",
    "check":              "Column type detection summary & type map artifact",
    "level":              "info",
    "status":             "OK",
    "n_columns":          n_cols,
    "n_numeric":          int((type_det_df["type_group_inferred"] == "numeric").sum()),
    "n_categorical":      int((type_det_df["type_group_inferred"] == "categorical").sum()),
    "n_boolean":          int((type_det_df["type_group_inferred"] == "boolean").sum()),
    "n_datetime":         int((type_det_df["type_group_inferred"] == "datetime").sum()),
    "timestamp":          pd.Timestamp.utcnow(),
    "detail":             "Type map ‚Üí column_type_map.json; summary ‚Üí type_detection_summary.csv",
}

if "_append_sec2" in globals():
    _append_sec2(pd.DataFrame([summary_221]))
else:
    path = SECTION2_REPORT_PATH
    tmp_path = path.with_suffix(path.suffix + ".tmp")
    chunk = pd.DataFrame([summary_221])
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        if path.exists():
            ex = pd.read_csv(path)
            allc = pd.Index(ex.columns).union(chunk.columns)
            out = pd.concat(
                [ex.reindex(columns=allc), chunk.reindex(columns=allc)],
                ignore_index=True,
            )
        else:
            out = chunk
        out.to_csv(tmp_path, index=False)
        os.replace(tmp_path, path)
        print(f"üßæ Appended 2.2.1 summary ‚Üí {path}")
    except Exception as e:
        if tmp_path.exists():
            try:
                tmp_path.unlink()
            except Exception:
                pass
        print(f"‚ö†Ô∏è Could not append 2.2.1 summary: {e}")

print("‚úÖ 2.2.1 complete.")

2.2.1 üß¨ Auto-detect data types
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")

üìä 2.2.1 type detection summary (head):
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")
/var/folders/dn/wtcqyjbd1hn63s40771sdddm0000gn/T/ipykernel_54139/1154222938.py:145: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.
  parsed = pd.to_datetime(sample_dt, errors="coerce")

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column</th>
      <th>pandas_dtype</th>
      <th>type_group_base</th>
      <th>type_group_inferred</th>
      <th>semantic_type</th>
      <th>n_unique</th>
      <th>null_pct</th>
      <th>pct_numeric_like</th>
      <th>pct_boolean_like</th>
      <th>pct_datetime_like</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Churn</td>
      <td>object</td>
      <td>string_like</td>
      <td>boolean</td>
      <td>boolean_like_string</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Dependents</td>
      <td>object</td>
      <td>string_like</td>
      <td>boolean</td>
      <td>boolean_like_string</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>PaperlessBilling</td>
      <td>object</td>
      <td>string_like</td>
      <td>boolean</td>
      <td>boolean_like_string</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Partner</td>
      <td>object</td>
      <td>string_like</td>
      <td>boolean</td>
      <td>boolean_like_string</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>PhoneService</td>
      <td>object</td>
      <td>string_like</td>
      <td>boolean</td>
      <td>boolean_like_string</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Contract</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>DeviceProtection</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.7833</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>InternetService</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.2167</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>MultipleLines</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.9032</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>OnlineBackup</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.7833</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>OnlineSecurity</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.7833</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>PaymentMethod</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>4</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>StreamingMovies</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.7833</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>StreamingTV</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.7833</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>14</th>
      <td>TechSupport</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>3</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.7833</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>15</th>
      <td>customerID</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>7043</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>16</th>
      <td>gender</td>
      <td>object</td>
      <td>string_like</td>
      <td>categorical</td>
      <td>categorical</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Churn_flag</td>
      <td>Int64</td>
      <td>numeric</td>
      <td>numeric</td>
      <td>numeric</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>18</th>
      <td>MonthlyCharges</td>
      <td>float64</td>
      <td>numeric</td>
      <td>numeric</td>
      <td>numeric</td>
      <td>1585</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>SeniorCitizen</td>
      <td>int64</td>
      <td>numeric</td>
      <td>numeric</td>
      <td>numeric</td>
      <td>2</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>

üíæ Wrote type detection summary ‚Üí /Users/b/DATA/PROJECTS/Telco/Level_3/resources/reports/section2/type_detection/type_detection_summary.csv
üíæ Wrote column type map ‚Üí /Users/b/DATA/PROJECTS/Telco/Level_3/resources/reports/section2/type_detection/column_type_map.json
üßæ Appended 2.2.1 summary ‚Üí /Users/b/DATA/PROJECTS/Telco/Level_3/resources/reports/section2/section2_data_quality_20251209_181006.csv
‚úÖ 2.2.1 complete.
```

---
---

Nice, 2.2.1 is doing exactly what we wanted ‚Äì it‚Äôs just being a bit noisy about datetimes.

### Why you‚Äôre seeing the `UserWarning`

The warning:

> Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.

comes from this block:

```python
# datetime-like (sampled)
sample_dt = s_str[non_empty_mask].dropna().head(datetime_sample_size)
if not sample_dt.empty:
    parsed = pd.to_datetime(sample_dt, errors="coerce")
    pct_datetime_like = float(parsed.notna().sum()) / len(sample_dt)
    datetime_like_flag = pct_datetime_like >= datetime_threshold
```

You‚Äôre asking pandas to **infer** datetime format from arbitrary strings. It tries, can‚Äôt find a clear format, and warns you that it‚Äôs falling back to the slower `dateutil` parser.

For Telco, you don‚Äôt actually *have* datetime columns, so this is just noise.

---

## üîß Fix 1 ‚Äî Add a configurable `DATETIME_FORMAT` + silence the warning

### Step 1: add a datetime format knob (optional, nice to have)

In `project_config.yaml` you can (optionally) add:

```yaml
TYPE_DETECTION:
  DATETIME_FORMAT: null          # or e.g. "%Y-%m-%d" if you know it later
  DATETIME_ENABLED: true
```

Not required, but gives you a place to plug in a format later.

### Step 2: grab that config in your cell

Near your other `try/except` config pulls (after `datetime_threshold` is fine), add:

```python
try:
    datetime_enabled = bool(C("TYPE_DETECTION.DATETIME_ENABLED", True))
except Exception:
    datetime_enabled = True

try:
    datetime_format = C("TYPE_DETECTION.DATETIME_FORMAT", None)
except Exception:
    datetime_format = None
```

And at the very top of the cell (with imports), make sure you have:

```python
import warnings
```

if it‚Äôs not already imported in this notebook.

### Step 3: replace the datetime-like block

Find this block:

```python
# datetime-like (sampled)
sample_dt = s_str[non_empty_mask].dropna().head(datetime_sample_size)
if not sample_dt.empty:
    parsed = pd.to_datetime(sample_dt, errors="coerce")
    pct_datetime_like = float(parsed.notna().sum()) / len(sample_dt)
    datetime_like_flag = pct_datetime_like >= datetime_threshold
```

Replace it with:

```python
# datetime-like (sampled)
sample_dt = s_str[non_empty_mask].dropna().head(datetime_sample_size)
if datetime_enabled and not sample_dt.empty:
    with warnings.catch_warnings():
        # Silence "Could not infer format" noise for generic detection
        warnings.filterwarnings(
            "ignore",
            message="Could not infer format.*",
            category=UserWarning,
        )

        parsed = pd.to_datetime(
            sample_dt,
            errors="coerce",
            format=datetime_format,   # None by default; or set in CONFIG
        )

    pct_datetime_like = float(parsed.notna().sum()) / len(sample_dt)
    datetime_like_flag = pct_datetime_like >= datetime_threshold
```

That does three things:

1. Lets you **disable** datetime detection entirely via `DATETIME_ENABLED: false`.
2. Lets you plug a **specific format** later if you have one (no more guesswork).
3. Silences the noisy UserWarning when we‚Äôre just probing types.

---

## ‚úÖ Anything else that *needs* a fix?

From the output you pasted, the rest looks healthy:

* `Churn`, `Dependents`, `Partner`, etc. are correctly flagged as `boolean_like_string`.
* `Contract`, `InternetService`, etc. are `categorical`.
* `Churn_flag`, `MonthlyCharges`, `SeniorCitizen` are `numeric`.
* The CSV + JSON artifacts are being written and appended to the Section 2 log fine.

So the only **must-fix** here is that datetime warning block. Everything else is doing what we designed it to do.

If you‚Äôd like, next I can show you how to wire **2.2.x** to actually use `semantic_type` to propose `astype` / `pd.to_datetime` / `astype("category")` casts in a 2.2.2 ‚Äúcoercion plan‚Äù step.
