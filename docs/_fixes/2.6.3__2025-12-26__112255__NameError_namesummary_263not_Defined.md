name 'summary_263' is not defined

```python
# 2.6.3 ðŸ•³ï¸ Missing Value Treatment
print("2.6.3 ðŸ•³ï¸ Missing Value Treatment")

max_null_frac_263 = missing_cfg_263.get("MAX_NULL_FRACTION_TO_IMPUTE", 0.4)
strats_263        = missing_cfg_263.get("STRATEGIES", {}) or {}

num_strat_263 = strats_263.get("NUMERIC", {}) or {}
cat_strat_263 = strats_263.get("CATEGORICAL", {}) or {}
dt_strat_263  = strats_263.get("DATETIME", {}) or {}

num_default_263 = num_strat_263.get("default", "median")
num_overrides_263 = num_strat_263.get("overrides", {}) or {}

cat_default_263 = cat_strat_263.get("default", "mode")
cat_overrides_263 = cat_strat_263.get("overrides", {}) or {}

dt_default_263 = dt_strat_263.get("default", "ffill")
dt_overrides_263 = dt_strat_263.get("overrides", {}) or {}

missing_logs_263 = []

missing_profile_263 = df_clean.isna().sum().to_frame("n_missing")
missing_profile_263["pct_missing"] = (
    missing_profile_263["n_missing"] / float(df_clean.shape[0])
)

# deprecated loop: causes weird behavioir
# for col in df_clean.columns:

# Missing value treatment
for col in list(df_clean.columns):
    n_missing   = int(missing_profile_263.loc[col, "n_missing"])
    pct_missing = float(missing_profile_263.loc[col, "pct_missing"])
    dtype_str   = str(df_clean[col].dtype)
    strategy    = None
    impute_value_str = None
    n_imputed   = 0
    high_missing_flag = pct_missing > max_null_frac_263

    # Decide domain type
    if pd.api.types.is_numeric_dtype(df_clean[col]):
        domain_type = "numeric"
        strategy = num_overrides_263.get(col, num_default_263)
    elif pd.api.types.is_datetime64_any_dtype(df_clean[col]):
        domain_type = "datetime"
        strategy = dt_overrides_263.get(col, dt_default_263)
    else:
        domain_type = "categorical"
        strategy = cat_overrides_263.get(col, cat_default_263)

    # High-missing guard
    if high_missing_flag and strategy not in ("drop_column", "drop_rows_if_missing"):
        strategy_to_apply = "skip_high_missing"
    else:
        strategy_to_apply = strategy

    if n_missing == 0 or strategy_to_apply is None:
        missing_logs_263.append(
            {
                "column": col,
                "dtype": dtype_str,
                "n_missing_before": n_missing,
                "pct_missing_before": pct_missing,
                "strategy": strategy_to_apply or "none",
                "impute_value": None,
                "n_imputed": 0,
                "high_missing_flag": high_missing_flag,
            }
        )
        continue

    # Apply strategy
    if domain_type == "numeric":
        if strategy_to_apply == "median":
            val = df_clean[col].median()
            df_clean[col] = df_clean[col].fillna(val)
            n_imputed = n_missing
            impute_value_str = float(val) if pd.notna(val) else None
        elif strategy_to_apply == "mean":
            val = df_clean[col].mean()
            df_clean[col] = df_clean[col].fillna(val)
            n_imputed = n_missing
            impute_value_str = float(val) if pd.notna(val) else None
        elif strategy_to_apply == "zero":
            df_clean[col] = df_clean[col].fillna(0)
            n_imputed = n_missing
            impute_value_str = 0
        elif strategy_to_apply == "drop_column":
            df_clean.drop(columns=[col], inplace=True)
            impute_value_str = "column_dropped"
        elif strategy_to_apply == "skip_high_missing":
            impute_value_str = "skipped_due_to_high_missing"
        else:
            impute_value_str = f"unsupported_numeric_strategy:{strategy_to_apply}"

    elif domain_type == "categorical":
        if strategy_to_apply == "mode":
            val = df_clean[col].mode(dropna=True)
            val = val.iloc[0] if not val.empty else None
            df_clean[col] = df_clean[col].fillna(val)
            n_imputed = n_missing
            impute_value_str = str(val) if val is not None else None
        elif strategy_to_apply and strategy_to_apply.startswith("new_level:"):
            label = strategy_to_apply.split(":", 1)[1] or "Unknown"
            df_clean[col] = df_clean[col].fillna(label)
            n_imputed = n_missing
            impute_value_str = label
        elif strategy_to_apply == "drop_rows_if_missing":
            before_rows = int(df_clean.shape[0])
            df_clean = df_clean.loc[~df_clean[col].isna()].copy()
            after_rows = int(df_clean.shape[0])
            impute_value_str = f"rows_dropped:{before_rows - after_rows}"
        elif strategy_to_apply == "skip_high_missing":
            impute_value_str = "skipped_due_to_high_missing"
        else:
            impute_value_str = f"unsupported_categorical_strategy:{strategy_to_apply}"

    else:  # datetime
        if strategy_to_apply in ("ffill", "bfill"):
            missing_before = int(df_clean[col].isna().sum())
            if strategy_to_apply == "ffill":
                df_clean[col] = df_clean[col].fillna(method="ffill")
            else:
                df_clean[col] = df_clean[col].fillna(method="bfill")
            missing_after = int(df_clean[col].isna().sum())
            n_imputed = max(0, missing_before - missing_after)
            impute_value_str = strategy_to_apply
        elif strategy_to_apply == "drop_rows_if_missing":
            before_rows = int(df_clean.shape[0])
            df_clean = df_clean.loc[~df_clean[col].isna()].copy()
            after_rows = int(df_clean.shape[0])
            impute_value_str = f"rows_dropped:{before_rows - after_rows}"
        elif strategy_to_apply == "skip_high_missing":
            impute_value_str = "skipped_due_to_high_missing"
        else:
            impute_value_str = f"unsupported_datetime_strategy:{strategy_to_apply}"

    missing_logs_263.append(
        {
            "column": col,
            "dtype": dtype_str,
            "n_missing_before": n_missing,
            "pct_missing_before": pct_missing,
            "strategy": strategy_to_apply,
            "impute_value": impute_value_str,
            "n_imputed": int(n_imputed),
            "high_missing_flag": high_missing_flag,
        }
    )

missing_log_df_263 = pd.DataFrame(missing_logs_263)
missing_log_path_263 = sec2_reports_dir_26 / "missing_value_imputations.csv"

tmp_missing_log_path_263 = missing_log_path_263.with_suffix(".tmp.csv")
missing_log_df_263.to_csv(tmp_missing_log_path_263, index=False)
os.replace(tmp_missing_log_path_263, missing_log_path_263)

n_cols_imputed_263 = int((missing_log_df_263["n_imputed"] > 0).sum())
n_high_missing_cols_263 = int(
    (missing_log_df_263["high_missing_flag"] == True).sum()
)

status_263 = "OK"
if n_high_missing_cols_263 > 0:
    status_263 = "WARN"

if section2_summary_path_26.exists():
    section2_summary_df_26 = pd.read_csv(section2_summary_path_26)
    section2_summary_df_26 = pd.concat([section2_summary_df_26, summary_263], ignore_index=True)
else:
    section2_summary_df_26 = summary_263

tmp_summary_path_26 = section2_summary_path_26.with_suffix(".tmp.csv")
section2_summary_df_26.to_csv(tmp_summary_path_26, index=False)
os.replace(tmp_summary_path_26, section2_summary_path_26)

cleaning_actions_261.append(
    {
        "step": "2.6.3",
        "description": "Missing value treatment",
        "n_columns_imputed": n_cols_imputed_263,
        "n_high_missing_columns": n_high_missing_cols_263,
    }
)

if VERBOSE_26 and not missing_log_df_263.empty:
    print("   ðŸ“‹ Missing-value strategies (top 20):")
    cols_263_preview = [
        "column", "dtype", "n_missing_before",
        "pct_missing_before", "strategy",
        "impute_value", "n_imputed", "high_missing_flag"
    ]
    cols_263_preview = [c for c in cols_263_preview if c in missing_log_df_263.columns]
    if display is not None:
        display(missing_log_df_263[cols_263_preview].head(20))
    else:
        print(missing_log_df_263[cols_263_preview].head(10))

    _touched_263 = missing_log_df_263[missing_log_df_263["n_imputed"] > 0]
    if not _touched_263.empty:
        print("   ðŸ”Ž Columns with imputation applied (top 20):")
        if display is not None:
            display(_touched_263[cols_263_preview].head(10))
        else:
            print(_touched_263[cols_263_preview].head(20))

summary_263 = pd.DataFrame([{
    "section": "2.6.3",
    "section_name": "Missing value treatment",
    "check": "Apply configured imputation strategies per column type",
    "level": "info",
    "status": status_263,
    "n_columns_imputed": int(n_cols_imputed_263),
    "n_high_missing_columns": int(n_high_missing_cols_263),
    "detail": getattr(missing_log_path_263, "name", None),
    "timestamp": pd.Timestamp.utcnow(),
}])
append_sec2(summary_263, SECTION2_REPORT_PATH)

display(summary_263)
display(section2_summary_df_26)

---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Cell In[139], line 169
    167 if section2_summary_path_26.exists():
    168     section2_summary_df_26 = pd.read_csv(section2_summary_path_26)
--> 169     section2_summary_df_26 = pd.concat([section2_summary_df_26, summary_263], ignore_index=True)
    170 else:
    171     section2_summary_df_26 = summary_263

NameError: name 'summary_263' is not defined

---
---

You build `summary_263` **after** you try to use it in the `section2_summary_df_26` concat block. So it is undefined at that point.

Two clean fixes.

## Fix A (minimal change): move `summary_263` creation up

Create `summary_263` immediately after you compute `status_263`, before you touch `section2_summary_df_26`.

```python
# ... after status_263 is computed

summary_263 = pd.DataFrame([{
    "section": "2.6.3",
    "section_name": "Missing value treatment",
    "check": "Apply configured imputation strategies per column type",
    "level": "info",
    "status": status_263,
    "n_columns_imputed": int(n_cols_imputed_263),
    "n_high_missing_columns": int(n_high_missing_cols_263),
    "detail": getattr(missing_log_path_263, "name", None),
    "timestamp": pd.Timestamp.utcnow(),
}])

# now this works
if section2_summary_path_26.exists():
    section2_summary_df_26 = pd.read_csv(section2_summary_path_26, low_memory=False)
    section2_summary_df_26 = pd.concat([section2_summary_df_26, summary_263], ignore_index=True)
else:
    section2_summary_df_26 = summary_263.copy()

tmp_summary_path_26 = section2_summary_path_26.with_suffix(".tmp.csv")
section2_summary_df_26.to_csv(tmp_summary_path_26, index=False)
os.replace(tmp_summary_path_26, section2_summary_path_26)
```

Then keep:

```python
append_sec2(summary_263, SECTION2_REPORT_PATH)
display(summary_263)
display(section2_summary_df_26)
```

## Fix B (better): stop writing `section2_summary_df_26` at all

You already have the unified `SECTION2_REPORT_PATH` via `append_sec2`. The extra `section2_summary_df_26` file is redundant and is where bugs like this come from.

Delete the whole block that reads/writes `section2_summary_path_26` and keep only:

```python
summary_263 = pd.DataFrame([{
    "section": "2.6.3",
    "section_name": "Missing value treatment",
    "check": "Apply configured imputation strategies per column type",
    "level": "info",
    "status": status_263,
    "n_columns_imputed": int(n_cols_imputed_263),
    "n_high_missing_columns": int(n_high_missing_cols_263),
    "detail": getattr(missing_log_path_263, "name", None),
    "timestamp": pd.Timestamp.utcnow(),
}])

append_sec2(summary_263, SECTION2_REPORT_PATH)
display(summary_263)
```

ðŸ’¡ðŸ’¡ If you keep `section2_summary_df_26`, load it with `low_memory=False` like above to reduce the mixed-type warning churn.
