> Why is the status=SKIP?
> What do I have to consider in order to fix this?
> Could the outputs of this cell be tighter? It seems 5 different outputs could be reduced

```py
# PART A | 2.1.1-2.1.5 üéØ Target Variable Creation & Validation | def(reporting) no C
# ALT TITLE: üéØ Target, ID, Flags & Structural Checks
print("\n2.1.1-2.1.? üéØ Target variable creation & validation")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0.0 first."
assert "CONFIG" in globals(), "‚ùå CONFIG not found. Run 2.0.0 first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."

# Resolve config-driven target settings with sensible fallbacks (NO C())
target_block = CONFIG.get("TARGET", {}) or {}

raw_target_col     = target_block.get("RAW_COLUMN", "Churn")
encoded_target_col = target_block.get("COLUMN", "Churn_flag")
pos_label          = target_block.get("POSITIVE_CLASS", "Yes")
neg_label          = target_block.get("NEGATIVE_CLASS", "No")

if raw_target_col not in df.columns:
    raise KeyError(f"‚ùå TARGET.RAW_COLUMN '{raw_target_col}' not found in df.columns")

# Normalize raw target values
raw_series = df[raw_target_col].astype("string")

norm = raw_series.str.strip().str.casefold()
pos_norm = str(pos_label).strip().casefold()
neg_norm = str(neg_label).strip().casefold()

allowed_norm_values = {pos_norm, neg_norm}

# Identify invalid / unexpected labels
is_non_null = norm.notna()
is_allowed  = norm.isin(list(allowed_norm_values))
invalid_mask = is_non_null & (~is_allowed)

n_total      = len(norm)
n_null       = int(norm.isna().sum())
n_valid      = int((is_non_null & is_allowed).sum())
n_invalid    = int(invalid_mask.sum())
pct_invalid  = (n_invalid / n_total * 100.0) if n_total else 0.0

invalid_sample_values = (
    norm[invalid_mask].dropna().value_counts().head(10).index.tolist()
)

# Build a small integrity report DataFrame
target_integrity_rows = [
    {"metric": "total_rows",      "value": n_total},
    {"metric": "n_null",          "value": n_null},
    {"metric": "n_valid",         "value": n_valid},
    {"metric": "n_invalid",       "value": n_invalid},
    {"metric": "pct_invalid",     "value": round(pct_invalid, 4)},
    {"metric": "raw_target_col",  "value": raw_target_col},
    {"metric": "encoded_target",  "value": encoded_target_col},
    {"metric": "pos_label",       "value": str(pos_label)},
    {"metric": "neg_label",       "value": str(neg_label)},
    {"metric": "invalid_samples", "value": ", ".join(map(str, invalid_sample_values))},
]

target_integrity_df = pd.DataFrame(target_integrity_rows)

target_integrity_path = SEC2_REPORTS_DIR / "target_integrity_report.csv"
target_integrity_df.to_csv(target_integrity_path, index=False)

print(f"‚úÖ 2.1.1 target integrity report written ‚Üí {target_integrity_path}")
display(target_integrity_df)

# Create binary Churn_flag (only for valid labels)
flag_map = {
    pos_norm: 1,
    neg_norm: 0,
}

encoded = norm.map(flag_map)
# nullable Int64, so invalid values stay as <NA>
df[encoded_target_col] = encoded.astype("Int64")

# Build churn_flag summary
summary = (
    df[encoded_target_col]
    .value_counts(dropna=False)
    .rename_axis("Churn_flag")
    .reset_index(name="count")
)

summary["percent"] = (summary["count"] / n_total * 100.0).round(4)

churn_flag_summary_path = SEC2_REPORTS_DIR / "churn_flag_summary.csv"
summary.to_csv(churn_flag_summary_path, index=False)

print(f"‚úÖ 2.1.1 churn flag summary written ‚Üí {churn_flag_summary_path}")
display(summary)

# Append unified 2.1.1 diagnostics into SECTION2_REPORT_PATH (INLINE)

imbalance_ratio = None
n_pos = None
n_neg = None
try:
    n_pos = int(summary.loc[summary["Churn_flag"] == 1, "count"].sum())
    n_neg = int(summary.loc[summary["Churn_flag"] == 0, "count"].sum())
    if n_neg > 0:
        imbalance_ratio = n_pos / n_neg
except Exception:
    imbalance_ratio = None

sec2_chunk_211 = pd.DataFrame(
    {
        "section":          ["2.1.1"],
        "section_name":     ["Target variable creation & validation"],
        "check":            ["Create Churn_flag and validate raw target labels"],
        "level":            ["info" if n_invalid == 0 else "warning"],
        "raw_target_col":   [raw_target_col],
        "encoded_target":   [encoded_target_col],
        "n_rows":           [n_total],
        "n_null_raw":       [n_null],
        "n_invalid_raw":    [n_invalid],
        "pct_invalid_raw":  [round(pct_invalid, 4)],
        "n_pos":            [n_pos],
        "n_neg":            [n_neg],
        "imbalance_ratio":  [imbalance_ratio],
        "status":           ["OK" if n_invalid == 0 else "WARN"],
        "detail":           [
            f"Target '{raw_target_col}' normalized to '{encoded_target_col}' "
            f"with {n_invalid} invalid labels; integrity report: "
            f"{target_integrity_path.name}, summary: {churn_flag_summary_path.name}"
        ],
        "timestamp":        [pd.Timestamp.now()],
    }
)

display(sec2_chunk_211)
append_sec2(sec2_chunk_211, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.1")

# 2.1.2 ü™™ ID & Key Field Verification | def(reporting) no C()
print("\n2.1.2 ü™™ ID & Key Field Verification")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0.0 first."
assert "CONFIG" in globals(), "‚ùå CONFIG not found. Run 2.0.0 first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."

# Resolve ID columns from CONFIG with sensible fallback
id_cols_cfg = CONFIG.get("ID_COLUMNS", []) or ["customerID"]
if isinstance(id_cols_cfg, (str, bytes)):
    id_cols = [id_cols_cfg]
else:
    id_cols = list(id_cols_cfg)

# Build ID integrity table
id_rows = []
for col in id_cols:
    exists = col in df.columns
    if exists:
        s = df[col]
        non_null = int(s.notna().sum())
        n_nulls = int(s.isna().sum())
        n_dupes = int(df.duplicated(subset=[col]).sum())
        n_unique = int(s.nunique(dropna=True))
        unique_ok = bool(n_unique == non_null)
    else:
        non_null = 0
        n_nulls = np.nan if "np" in globals() else None
        n_dupes = np.nan if "np" in globals() else None
        unique_ok = False

    id_rows.append(
        {
            "id_column":   col,
            "exists":      bool(exists),
            "non_null":    non_null,
            "nulls":       n_nulls,
            "duplicates":  n_dupes,
            "unique_ok":   bool(unique_ok),
        }
    )

id_integrity_df = pd.DataFrame(id_rows)

# Write id_integrity_report.csv atomically
id_integrity_path = SEC2_REPORTS_DIR / "id_integrity_report.csv"
tmp_id_path = id_integrity_path.with_suffix(".tmp.csv")

id_integrity_df.to_csv(tmp_id_path, index=False)
os.replace(tmp_id_path, id_integrity_path)

print(f"‚úÖ 2.1.2 ID integrity report written ‚Üí {id_integrity_path}")
display(id_integrity_df)

# Build unified diagnostics chunk for 2.1.2
n_ids = len(id_cols)
n_non_unique = int((~id_integrity_df["unique_ok"]).sum()) if not id_integrity_df.empty else 0
status = "OK" if n_non_unique == 0 else "WARN"

sec2_chunk_212 = pd.DataFrame(
    {
        "section":        ["2.1.2"],
        "section_name":   ["ID & key field verification"],
        "check":          ["ID & key field verification"],
        "level":          ["info"],
        "status":         [status],
        "n_ids":          [n_ids],
        "n_non_unique":   [n_non_unique],
        "timestamp":      [pd.Timestamp.now()],
        "detail":         [
            f"ID integrity report written to {id_integrity_path.name}; "
            f"{n_non_unique} non-unique or invalid ID columns."
        ],
    }
)

display(sec2_chunk_212)

append_sec2(sec2_chunk_212, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.2")
# 2.1.3 üßÆ Special-Case Numeric Flag Registration (e.g., SeniorCitizen)
print("\n2.1.3 üßÆ Special-Case Numeric Flag Registration")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0.0 first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."

# Detect special-case numeric flags (currently: SeniorCitizen)
special_numeric_map = {}

if "SeniorCitizen" in df.columns:
    # Keep original numeric but declare semantics (int-coded categorical flag)
    special_numeric_map["SeniorCitizen"] = "categorical_int"

# Build DataFrame of special numeric flags
if special_numeric_map:
    special_flags_df = pd.DataFrame(
        [{"column": k, "role": v} for k, v in special_numeric_map.items()]
    )
else:
    special_flags_df = pd.DataFrame(columns=["column", "role"])

# Write special_numeric_flags.csv atomically
special_flags_path = SEC2_REPORTS_DIR / "special_numeric_flags.csv"
tmp_flags_path = special_flags_path.with_suffix(".tmp.csv")

special_flags_df.to_csv(tmp_flags_path, index=False)
os.replace(tmp_flags_path, special_flags_path)

print(f"‚úÖ 2.1.3 special numeric flags report written ‚Üí {special_flags_path}")
display(special_flags_df)

n_flags = len(special_numeric_map)

# Build unified diagnostics chunk for 2.1.3
sec2_chunk_213 = pd.DataFrame(
    {
        "section":        ["2.1.3"],
        "section_name":   ["Special-case numeric flag registration"],
        "check":          ["Special-case numeric flags"],
        "level":          ["info"],
        "status":         ["OK"],
        "n_flags":        [n_flags],
        "timestamp":      [pd.Timestamp.now()],
        "detail":         [
            f"Detected {n_flags} special numeric flag column(s); "
            f"written to {special_flags_path.name}."
        ],
    }
)

display(sec2_chunk_213)

append_sec2(sec2_chunk_213, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.3")

# 2.1.4 üîÅ Duplicate & Record-Level Consistency Audit
print("\n2.1.4 üîÅ Duplicate & Record-Level Consistency Audit")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0.0 first."
assert "id_cols" in globals(), "‚ùå id_cols not found. Run 2.1.2 first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."

dup_report = []

# 1Ô∏è‚É£ Complete-row duplicates (all columns)
n_full_dupes = int(df.duplicated(keep=False).sum())
dup_report.append({"type": "full_row", "n_duplicates": n_full_dupes})

# 2Ô∏è‚É£ ID-level duplicates (per id column)
for col in id_cols:
    if col in df.columns:
        n_dupe_ids = int(df[col].duplicated(keep=False).sum())
        dup_report.append({"type": f"id:{col}", "n_duplicates": n_dupe_ids})

dup_df = pd.DataFrame(dup_report)

# Write duplicate_audit_report.csv atomically
dup_report_path = SEC2_REPORTS_DIR / "duplicate_audit_report.csv"
tmp_dup_path = dup_report_path.with_suffix(".tmp.csv")

dup_df.to_csv(tmp_dup_path, index=False)
os.replace(tmp_dup_path, dup_report_path)

print(f"‚úÖ 2.1.4 duplicate audit report written ‚Üí {dup_report_path}")
display(dup_df)

# Build unified diagnostics chunk for 2.1.4
sec2_chunk_214 = pd.DataFrame(
    {
        "section":        ["2.1.4"],
        "section_name":   ["Duplicate & record-level consistency audit"],
        "check":          ["Duplicate audit"],
        "level":          ["info"],
        "status":         ["OK"],  # same behavior as original
        "full_row_dupes": [n_full_dupes],
        "timestamp":      [pd.Timestamp.now()],
        "detail":         [
            f"Duplicate audit written to {dup_report_path.name}; "
            f"{n_full_dupes} full-row duplicates detected."
        ],
    }
)

display(sec2_chunk_214)
append_sec2(sec2_chunk_214, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.4")
# üëÅÔ∏è 2.1.4.5 | Duplicate audit preview + atomic CSV | def(reporting) no C()
print("\n2.1.4.5 üëÅÔ∏è Duplicate audit preview & sample export")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0.0 first."
assert "id_cols" in globals(), "‚ùå id_cols not found. Run 2.1.2 first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."

_rows = 12  # rows to display

# --- Build a compact preview of duplicates ---
preview_parts = []

# A) full-row duplicate sample
full_dupe_mask = df.duplicated(keep=False)
has_full_dupes = bool(full_dupe_mask.any())
if has_full_dupes:
    full_dupes_sample = df.loc[full_dupe_mask].head(_rows).copy()
    full_dupes_sample.insert(0, "_preview_kind", "full_row")
    preview_parts.append(full_dupes_sample)

# B) per-ID duplicate samples
for col in id_cols:
    if col in df.columns:
        id_counts = df[col].value_counts(dropna=False)
        dupe_ids = set(id_counts[id_counts > 1].index.tolist())
        if dupe_ids:
            sample = df[df[col].isin(list(dupe_ids))].head(_rows).copy()
            sample.insert(0, "_preview_kind", f"id:{col}")
            preview_parts.append(sample)

# Concatenate previews (or create an empty frame if none)
if preview_parts:
    _preview_df = pd.concat(preview_parts, ignore_index=True)
else:
    _preview_df = pd.DataFrame(columns=["_preview_kind"] + df.columns.tolist())

n_preview_rows, n_preview_cols = _preview_df.shape

_name = "2.1.4_duplicate_audit_sample.csv"
print(f"üîé {_name}: {n_preview_rows}√ó{n_preview_cols} ‚Üí showing {_rows} rows")
display(_preview_df.head(_rows))

_out_path = SEC2_REPORTS_DIR / _name
_tmp = _out_path.with_suffix(".tmp.csv")

_preview_df.to_csv(_tmp, index=False)
os.replace(_tmp, _out_path)
print(f"üßæ wrote ‚Üí {_out_path}")

# --- Unified diagnostics row for 2.1.4.5.5 ------------------------------------
sec2_chunk_21455 = pd.DataFrame(
    {
        "section":        ["2.1.4.5.5"],
        "section_name":   ["Duplicate audit preview & sample export"],
        "check":          ["Duplicate audit preview"],
        "level":          ["info"],
        "status":         ["OK"],
        "n_preview_rows": [n_preview_rows],
        "n_preview_cols": [n_preview_cols],
        "has_full_dupes": [has_full_dupes],
        "detail":         [
            f"Duplicate preview sample written to {_out_path.name} "
            f"with {n_preview_rows} rows."
        ],
        "timestamp":      [pd.Timestamp.now()],
    }
)

display(sec2_chunk_21455)
append_sec2(sec2_chunk_21455, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.4.5.5")
# 2.1.5 üß¨ Feature Group Registration | Column-level Feature Catalog
print("\n2.1.5 üß¨ Feature Group Registration | Column-level Feature Catalog")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0.0 first."
assert "CONFIG" in globals(), "‚ùå CONFIG not found. Run 2.0.0 first."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."
assert "ARTIFACTS_DIR" in globals(), "‚ùå ARTIFACTS_DIR missing. Run 2.0.0 first."
assert "id_cols" in globals(), "‚ùå id_cols not found. Run 2.1.2 first."

import json  # used later for group_counts_json in diagnostics

# --- 2.1.5.1 Config + thresholds --------------------------------------------
fg_cfg = CONFIG.get("FEATURE_GROUPING", {}) or {}
low_card_threshold = int(fg_cfg.get("LOW_CARDINALITY_THRESHOLD", 20))
free_text_min_avg_len = int(fg_cfg.get("FREE_TEXT_MIN_AVG_LEN", 30))

ordinal_cfg = CONFIG.get("ORDINAL_COLUMNS", []) or []
if isinstance(ordinal_cfg, (str, bytes)):
    ordinal_cols = [ordinal_cfg]
else:
    ordinal_cols = list(ordinal_cfg)

protected_cfg = CONFIG.get("PROTECTED_COLUMNS", []) or []
if isinstance(protected_cfg, (str, bytes)):
    protected_from_config = {protected_cfg}
else:
    protected_from_config = set(protected_cfg)

# --- 2.1.5.2 Resolve target columns -----------------------------------------
# Try to locate target columns from earlier steps
raw_target_col = None
encoded_target_col = None

_target_block = CONFIG.get("TARGET", {}) or {}
_raw_from_cfg = _target_block.get("RAW_COLUMN")
_enc_from_cfg = _target_block.get("COLUMN")

if _raw_from_cfg and _raw_from_cfg in df.columns:
    raw_target_col = _raw_from_cfg
elif "raw_target_col" in globals() and isinstance(raw_target_col, str) and raw_target_col in df.columns:
    # keep previously-resolved raw_target_col if present
    pass

if _enc_from_cfg and _enc_from_cfg in df.columns:
    encoded_target_col = _enc_from_cfg
elif "encoded_target_col" in globals() and isinstance(encoded_target_col, str) and encoded_target_col in df.columns:
    # keep previously-resolved encoded_target_col if present
    pass

# --- 2.1.5.3 Load special numeric flags (from 2.1.3) ------------------------
special_flags_path = SEC2_REPORTS_DIR / "special_numeric_flags.csv"
special_flag_cols = set()

if special_flags_path.exists() and special_flags_path.stat().st_size > 0:
    try:
        _special_flags_df = pd.read_csv(special_flags_path)
    except Exception:
        _special_flags_df = pd.DataFrame()
    if "column" in _special_flags_df.columns:
        special_flag_cols = set(
            _special_flags_df["column"].dropna().astype("string")
        )
else:
    _special_flags_df = pd.DataFrame(columns=["column", "role"])

# --- 2.1.5.4 Build protected-columns set ------------------------------------
protected_cols = set()

# IDs
protected_cols.update(id_cols)

# Targets
if raw_target_col is not None:
    protected_cols.add(raw_target_col)
if encoded_target_col is not None:
    protected_cols.add(encoded_target_col)

# Special numeric flags
protected_cols.update(special_flag_cols)

# Config-driven protected list
protected_cols.update(protected_from_config)

# Ensure only columns that actually exist in df are considered protected
# Only keep those that actually exist in df
protected_cols = {c for c in protected_cols if c in df.columns}

# --- 2.1.5.5 Feature grouping logic (per-column catalog) --------------------
feature_group_rows = []

for col in df.columns:
    s = df[col]
    dtype_str = str(s.dtype)
    n_unique = int(s.nunique(dropna=True))
    is_protected = col in protected_cols

    # Base notes str we can enrich
    notes = []

    # Target / target_aux
    if encoded_target_col is not None and col == encoded_target_col:
        feature_group = "target"
        notes.append("binary target (encoded)")
    elif raw_target_col is not None and col == raw_target_col:
        feature_group = "target_aux"
        notes.append("raw target label")
    # ID / primary key
    elif col in id_cols:
        feature_group = "id"
        notes.append("ID / key candidate")
    # Explicit ordinal from config
    elif col in ordinal_cols:
        feature_group = "ordinal"
        notes.append("ordinal from CONFIG.ORDINAL_COLUMNS")
    # Special-case numeric flags from 2.1.3
    elif col in special_flag_cols:
        feature_group = "numeric_flag"
        notes.append("special numeric flag (2.1.3)")
    else:
        # Type-based rules
        if pd.api.types.is_datetime64_any_dtype(s):
            feature_group = "datetime"
            notes.append("datetime-like dtype")
        elif pd.api.types.is_bool_dtype(s):
            feature_group = "numeric_flag"
            notes.append("bool ‚Üí treated as flag")
        elif pd.api.types.is_numeric_dtype(s):
            # numeric: detect potential flag-like or discrete small-card
            if n_unique <= low_card_threshold and n_unique <= 10:
                feature_group = "numeric_flag"
                notes.append(
                    f"numeric small-card (n_unique={n_unique} ‚â§ {low_card_threshold})"
                )
            else:
                feature_group = "numeric_continuous"
                notes.append("numeric continuous / high-card")
        else:
            # object / string-like / category
            # quick heuristic for free text: high card + long strings
            try:
                avg_len = float(
                    s.dropna()
                    .astype("string")
                    .str.len()
                    .mean()
                )
            except Exception:
                avg_len = 0.0

            if n_unique <= low_card_threshold:
                feature_group = "categorical_low_card"
                notes.append(
                    f"low-card categorical (n_unique={n_unique} ‚â§ {low_card_threshold})"
                )
            else:
                if avg_len >= free_text_min_avg_len:
                    feature_group = "free_text"
                    notes.append(
                        f"free text (avg_len‚âà{avg_len:.1f} ‚â• {free_text_min_avg_len})"
                    )
                else:
                    feature_group = "categorical_high_card"
                    notes.append(
                        f"high-card categorical (n_unique={n_unique} > {low_card_threshold})"
                    )

    feature_group_rows.append(
        {
            "column": col,
            "dtype": dtype_str,
            "feature_group": feature_group,
            "n_unique": n_unique,
            "protected": bool(is_protected),
            "notes": "; ".join(notes),
        }
    )

#
feature_groups_df = pd.DataFrame(feature_group_rows)

# Just in case, ensure feature_group is not missing
feature_groups_df["feature_group"] = feature_groups_df["feature_group"].fillna("other")

# --- 2.1.5.6 Persist CSV artifact under SEC2_REPORTS_DIR --------------------
fg_csv_path = SEC2_REPORTS_DIR / "feature_groups_2_1_5.csv"
fg_tmp_csv = fg_csv_path.with_suffix(".tmp.csv")

feature_groups_df.to_csv(fg_tmp_csv, index=False)
os.replace(fg_tmp_csv, fg_csv_path)

print(f"‚úÖ 2.1.5 feature groups CSV written ‚Üí {fg_csv_path}")
display(feature_groups_df.head(30))

# FIXME: integrate into 2.1.6 --- 2.1.5.6 Persist YAML / JSON artifact under ARTIFACTS_DIR --------------
# Build group ‚Üí columns mapping (+ protected info) for YAML/JSON
group_map = {}
for grp, sub_df in feature_groups_df.groupby("feature_group"):
    group_map[str(grp)] = sorted(sub_df["column"].astype("string").tolist())

protected_list = sorted(feature_groups_df.loc[feature_groups_df["protected"], "column"].astype("string").tolist())
meta = {
    "section": "2.1.5",
    "description": "Feature group catalog at end of Section 2.1",
    "low_card_threshold": low_card_threshold,
    "free_text_min_avg_len": free_text_min_avg_len,
    "protected_columns": protected_list,
}

fg_struct = {
    "groups": group_map,
    "meta": meta,
}

# JSON
fg_json_path = ARTIFACTS_DIR / "feature_groups_2_1_5.json"
fg_tmp_json = fg_json_path.with_suffix(".tmp.json")
with open(fg_tmp_json, "w", encoding="utf-8") as f:
    json.dump(fg_struct, f, indent=2, ensure_ascii=False)
os.replace(fg_tmp_json, fg_json_path)

print(f"üíæ feature groups JSON written ‚Üí {fg_json_path}")

# YAML (optional)
fg_yaml_path = ARTIFACTS_DIR / "feature_groups_2_1_5.yaml"
if yaml is not None:
    fg_tmp_yaml = fg_yaml_path.with_suffix(".tmp.yaml")
    with open(fg_tmp_yaml, "w", encoding="utf-8") as f:
        yaml.safe_dump(fg_struct, f, sort_keys=False, allow_unicode=True)
    os.replace(fg_tmp_yaml, fg_yaml_path)
    print(f"üíæ feature groups YAML written ‚Üí {fg_yaml_path}")
else:
    print("‚ö†Ô∏è yaml not available; skipping YAML export for feature groups.")


# --- 2.1.5.7 Summary metrics + unified diagnostics row ----------------------
group_counts = (
    feature_groups_df["feature_group"]
    .value_counts()
    .sort_index()
    .to_dict()
)

n_features = int(len(feature_groups_df))
n_protected = int(feature_groups_df["protected"].sum())
n_unassigned = int((feature_groups_df["feature_group"] == "other").sum())

sec2_chunk_215 = pd.DataFrame(
    {
        "section":            ["2.1.5"],
        "section_name":       ["Feature group registration"],
        "check":              ["Feature group catalog (column-level)"],
        "level":              ["info"],
        "status":             ["OK"],
        "n_features":         [n_features],
        "n_protected":        [n_protected],
        "n_unassigned":       [n_unassigned],
        "group_counts_json":  [json.dumps(group_counts, sort_keys=True)],
        "feature_groups_csv": [fg_csv_path.name],
        "feature_groups_json": [fg_json_path.name],
        "feature_groups_yaml": [fg_yaml_path.name if yaml is not None else None],
        "timestamp":          [pd.Timestamp.now()],
        "detail":             [
            f"Feature groups registered for {n_features} column(s); "
            f"catalog written to {fg_csv_path.name}."
        ],
    }
)

display(sec2_chunk_215)
append_sec2(sec2_chunk_215, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.5")

# 2.1.6 üß± Feature Space Scaffolding | Groups ‚Üí Config for Downstream
print("\n2.1.6 üß± Feature Space Scaffolding | Groups ‚Üí Config for Downstream")

# Guards
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1 first."
assert "SEC2_REPORTS_DIR" in globals(), "‚ùå SEC2_REPORTS_DIR missing. Run 2.0.0/2.0.1 first."
assert "ARTIFACTS_DIR" in globals(), "‚ùå ARTIFACTS_DIR missing. Run 2.0.0 first."
assert "CONFIG" in globals(), "‚ùå CONFIG not found. Run 2.0.0 first."

import json
try:
    import yaml
except Exception:
    yaml = None

# --- 2.1.6.1 Reload thresholds so they are embedded in meta ------------------
fg_cfg = CONFIG.get("FEATURE_GROUPING", {}) or {}
low_card_threshold = int(fg_cfg.get("LOW_CARDINALITY_THRESHOLD", 20))
free_text_min_avg_len = int(fg_cfg.get("FREE_TEXT_MIN_AVG_LEN", 30))

# --- 2.1.6.2 Load the 2.1.5 catalog -----------------------------------------
fg_csv_path = SEC2_REPORTS_DIR / "feature_groups_2_1_5.csv"
assert fg_csv_path.exists(), f"‚ùå {fg_csv_path} not found. Run 2.1.5 first."

feature_groups_df_216 = pd.read_csv(fg_csv_path)

if "feature_group" not in feature_groups_df_216.columns:
    raise KeyError("‚ùå feature_groups_2_1_5.csv missing 'feature_group' column.")

# --- 2.1.6.3 Build group ‚Üí columns mapping + protected list ------------------
group_map = {}
for grp, sub_df in feature_groups_df_216.groupby("feature_group"):
    group_map[str(grp)] = sorted(sub_df["column"].astype("string").tolist())

protected_mask = feature_groups_df_216.get("protected", pd.Series([False] * len(feature_groups_df_216)))
protected_list = sorted(
    feature_groups_df_216.loc[protected_mask.astype(bool), "column"].astype("string").tolist()
)

meta = {
    "section": "2.1.6",
    "description": "Feature space scaffolding (groups ‚Üí columns) derived from 2.1.5 catalog.",
    "source_catalog": fg_csv_path.name,
    "low_card_threshold": low_card_threshold,
    "free_text_min_avg_len": free_text_min_avg_len,
    "protected_columns": protected_list,
}

feature_space_struct = {
    "groups": group_map,
    "meta": meta,
}

protected_list = sorted(feature_groups_df.loc[feature_groups_df["protected"], "column"].astype("string").tolist())
meta = {
    "section": "2.1.5",
    "description": "Feature group catalog at end of Section 2.1",
    "low_card_threshold": low_card_threshold,
    "free_text_min_avg_len": free_text_min_avg_len,
    "protected_columns": protected_list,
}

fg_struct = {
    "groups": group_map,
    "meta": meta,
}

# JSON
fg_json_path = ARTIFACTS_DIR / "feature_groups_2_1_5.json"
fg_tmp_json = fg_json_path.with_suffix(".tmp.json")
with open(fg_tmp_json, "w", encoding="utf-8") as f:
    json.dump(fg_struct, f, indent=2, ensure_ascii=False)
os.replace(fg_tmp_json, fg_json_path)

print(f"üíæ feature groups JSON written ‚Üí {fg_json_path}")

# YAML (optional)
fg_yaml_path = ARTIFACTS_DIR / "feature_groups_2_1_5.yaml"
if yaml is not None:
    fg_tmp_yaml = fg_yaml_path.with_suffix(".tmp.yaml")
    with open(fg_tmp_yaml, "w", encoding="utf-8") as f:
        yaml.safe_dump(fg_struct, f, sort_keys=False, allow_unicode=True)
    os.replace(fg_tmp_yaml, fg_yaml_path)
    print(f"üíæ feature groups YAML written ‚Üí {fg_yaml_path}")
else:
    print("‚ö†Ô∏è yaml not available; skipping YAML export for feature groups.")


# --- 2.1.6.4 Persist JSON / YAML artifacts under ARTIFACTS_DIR --------------
fs_json_path = ARTIFACTS_DIR / "feature_space_2_1_6.json"
fs_tmp_json = fs_json_path.with_suffix(".tmp.json")
with open(fs_tmp_json, "w", encoding="utf-8") as f:
    json.dump(feature_space_struct, f, indent=2, ensure_ascii=False)
os.replace(fs_tmp_json, fs_json_path)

print(f"üíæ 2.1.6 feature space JSON written ‚Üí {fs_json_path}")

fs_yaml_path = ARTIFACTS_DIR / "feature_space_2_1_6.yaml"
if yaml is not None:
    fs_tmp_yaml = fs_yaml_path.with_suffix(".tmp.yaml")
    with open(fs_tmp_yaml, "w", encoding="utf-8") as f:
        yaml.safe_dump(feature_space_struct, f, sort_keys=False, allow_unicode=True)
    os.replace(fs_tmp_yaml, fs_yaml_path)
    print(f"üíæ 2.1.6 feature space YAML written ‚Üí {fs_yaml_path}")
else:
    print("‚ö†Ô∏è yaml not available; skipping YAML export for feature space scaffolding.")

# --- 2.1.6.5 Diagnostics summary + SECTION2_REPORT_PATH append ---------------
group_counts_216 = {
    grp: len(cols) for grp, cols in group_map.items()
}

n_features_216 = int(len(feature_groups_df_216))
n_protected_216 = int(len(protected_list))
n_groups_216 = int(len(group_map))

sec2_chunk_216 = pd.DataFrame(
    {
        "section":             ["2.1.6"],
        "section_name":        ["Feature space scaffolding"],
        "check":               ["Feature space config (groups ‚Üí columns)"],
        "level":               ["info"],
        "status":              ["OK"],
        "n_features":          [n_features_216],
        "n_protected":         [n_protected_216],
        "n_groups":            [n_groups_216],
        "group_counts_json":   [json.dumps(group_counts_216, sort_keys=True)],
        "feature_space_json":  [fs_json_path.name],
        "feature_space_yaml":  [fs_yaml_path.name if yaml is not None else None],
        "source_catalog_csv":  [fg_csv_path.name],
        "timestamp":           [pd.Timestamp.now()],
        "detail":              [
            f"Feature space scaffolding built from {fg_csv_path.name}; "
            f"JSON: {fs_json_path.name}, "
            f"YAML: {fs_yaml_path.name if yaml is not None else 'skipped'}."
        ],
    }
)

display(sec2_chunk_216)
append_sec2(sec2_chunk_216, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.6")

# NEW 2.1.7 üß± Column-Type Alignment Audit + dtype baseline Snapshot (no coercion) | def(reporting) no C()
print("\n2.1.7 üß± Column-Type Alignment Audit (no coercion)")

# Guards
assert "df" in globals(), "‚ùå df not found. Run Section 2.0 first."
assert "CONFIG" in globals(), "‚ùå CONFIG not found. Run 2.0.1‚Äì2.0.2."
assert "REPORTS_DIR" in globals(), "‚ùå REPORTS_DIR missing. Run 2.0.1."
assert "SECTION2_REPORT_PATH" in globals(), "‚ùå SECTION2_REPORT_PATH missing. Run 2.0.1."

# Ensure Section 2 reports dir exists
SEC2_REPORTS_DIR   = REPORTS_DIR   / "section2"
SEC2_ARTIFACTS_DIR = ARTIFACTS_DIR / "section2"
SEC2_REPORTS_DIR.mkdir(parents=True, exist_ok=True)
SEC2_ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)

# Config: expected dtypes (may be empty)
expected_dtypes_cfg = CONFIG.get("SCHEMA_EXPECTED_DTYPES")
if expected_dtypes_cfg is None:
    expected_dtypes = {}
elif isinstance(expected_dtypes_cfg, dict):
    expected_dtypes = dict(expected_dtypes_cfg)
else:
    # Defensive: unexpected shape
    expected_dtypes = {}

baseline_rows = []
enforce_rows = []

for col, exp in expected_dtypes.items():
    present = col in df.columns
    actual_dtype = str(df[col].dtype) if present else None
    expected_str = str(exp)

    # Baseline row (no coercion, just capture current state)
    baseline_rows.append(
        {
            "column": col,
            "original_dtype": actual_dtype,
            "post_enforcement_dtype": actual_dtype,  # unchanged in audit-only mode
            "coercion_attempted": False,
            "coercion_ok": None,
            "n_coercion_fail": None,
            "sample_fail_values": None,
        }
    )

    # Enforcement row (expected vs actual)
    matches_expected = (actual_dtype == expected_str) if actual_dtype is not None else False

    note = ""
    if not present:
        note = "missing_in_df"

    enforce_rows.append(
        {
            "column": col,
            "expected_dtype": expected_str,
            "actual_dtype": actual_dtype,
            "matches_expected": bool(matches_expected),
            "present_in_df": bool(present),
            "note": note,
        }
    )

# ---- Write baseline + enforcement reports (atomic) --------------------------
dtype_baseline_df = pd.DataFrame(
    baseline_rows,
    columns=[
        "column",
        "original_dtype",
        "post_enforcement_dtype",
        "coercion_attempted",
        "coercion_ok",
        "n_coercion_fail",
        "sample_fail_values",
    ],
)

dtype_enforcement_df = pd.DataFrame(
    enforce_rows,
    columns=[
        "column",
        "expected_dtype",
        "actual_dtype",
        "matches_expected",
        "present_in_df",
        "note",
    ],
)

dtype_baseline_path = SEC2_REPORTS_DIR / "dtype_baseline_report.csv"
tmp = dtype_baseline_path.with_suffix(".tmp.csv")
dtype_baseline_df.to_csv(tmp, index=False)
os.replace(tmp, dtype_baseline_path)

dtype_enforcement_path = SEC2_REPORTS_DIR / "dtype_enforcement_report.csv"
tmp = dtype_enforcement_path.with_suffix(".tmp.csv")
dtype_enforcement_df.to_csv(tmp, index=False)
os.replace(tmp, dtype_enforcement_path)

print(f"üßæ Wrote baseline ‚Üí {dtype_baseline_path}")
print(f"üßæ Wrote enforcement ‚Üí {dtype_enforcement_path}")
display(dtype_enforcement_df.head(20))

# ---- Unified Section 2 diagnostics row (2.1.7A) -----------------------------
if len(expected_dtypes) == 0:
    status_217A = "SKIP"
    n_checked_217A = 0
    n_mismatched_217A = 0
else:
    n_checked_217A = len(expected_dtypes)
    if dtype_enforcement_df.empty:
        status_217A = "WARN"
        n_mismatched_217A = n_checked_217A
    else:
        ok_mask = dtype_enforcement_df["matches_expected"].fillna(False) & \
                  dtype_enforcement_df["present_in_df"].fillna(False)
        n_mismatched_217A = int(n_checked_217A - ok_mask.sum())
        status_217A = "OK" if n_mismatched_217A == 0 else "WARN"

sec2_chunk_217A = pd.DataFrame(
    {
        "section": ["2.1.7A"],
        "section_name": ["Column-type alignment audit (no coercion)"],
        "check": ["Schema-driven dtype alignment (read-only)"],
        "level": ["info"],
        "n_columns_checked": [n_checked_217A],
        "n_mismatched": [n_mismatched_217A],
        "status": [status_217A],
        "detail": [
            f"Baseline: {dtype_baseline_path.name}; "
            f"Enforcement: {dtype_enforcement_path.name}"
        ],
        "timestamp": [pd.Timestamp.now()],
    }
)

log_section_completion(
    "2.1.7A",
    status_217A,
    checked=n_checked_217A,
    mismatched=n_mismatched_217A,
)

display(sec2_chunk_217A)
append_sec2(sec2_chunk_217A, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.7A")

print(
    f"‚úÖ [2.1.7A] Dtype alignment audit | "
    f"status={status_217A} | "
    f"checked={n_checked_217A}, mismatched={n_mismatched_217A}"
)
```

># OUTPUT:
2.1.7 üß± Column-Type Alignment Audit (no coercion)
üßæ Wrote baseline ‚Üí
/Users/b/DATA/PROJECTS/Telco/Level_3/resources/reports/section2/dtype_baseline_report.csv
üßæ Wrote enforcement ‚Üí /Users/b/DATA/PROJECTS/Telco/Level_3/resources/reports/section2/dtype_enforcement_report.csv

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column</th>
      <th>expected_dtype</th>
      <th>actual_dtype</th>
      <th>matches_expected</th>
      <th>present_in_df</th>
      <th>note</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>
‚úÖ [2.1.7A] | status=SKIP | checked=0 | mismatched=0
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>section</th>
      <th>section_name</th>
      <th>check</th>
      <th>level</th>
      <th>n_columns_checked</th>
      <th>n_mismatched</th>
      <th>status</th>
      <th>detail</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.1.7A</td>
      <td>Column-type alignment audit (no coercion)</td>
      <td>Schema-driven dtype alignment (read-only)</td>
      <td>info</td>
      <td>0</td>
      <td>0</td>
      <td>SKIP</td>
      <td>Baseline: dtype_baseline_report.csv; Enforceme...</td>
      <td>2025-12-09 12:37:02.848693</td>
    </tr>
  </tbody>
</table>
</div>
üßæ Appended diagnostics ‚Üí /Users/b/DATA/PROJECTS/Telco/Level_3/resources/reports/section2/section2_data_quality_20251208_113544.csv
‚úÖ [2.1.7A] Dtype alignment audit | status=SKIP | checked=0, mismatched=0

Status is `SKIP` because, from the code‚Äôs own logic, there was **nothing to check.**

---

### 1Ô∏è‚É£ Why is `status=SKIP`?

This block is the key:

```python
expected_dtypes_cfg = CONFIG.get("SCHEMA_EXPECTED_DTYPES")
if expected_dtypes_cfg is None:
    expected_dtypes = {}
elif isinstance(expected_dtypes_cfg, dict):
    expected_dtypes = dict(expected_dtypes_cfg)
else:
    # Defensive: unexpected shape
    expected_dtypes = {}
```

Later:

```python
if len(expected_dtypes) == 0:
    status_217A = "SKIP"
    n_checked_217A = 0
    n_mismatched_217A = 0
else:
    ...
```

Your `dtype_enforcement_df` is empty and `n_columns_checked = 0`. That only happens if:

* `CONFIG["SCHEMA_EXPECTED_DTYPES"]` **doesn‚Äôt exist**, or
* It exists but is `None` or **not a dict**.

So 2.1.7A is saying:

> ‚ÄúI ran, but there were no expected dtypes configured, so I‚Äôm skipping enforcement.‚Äù

Nothing‚Äôs ‚Äúwrong‚Äù with the code ‚Äî you just haven‚Äôt populated the schema yet.

---

### 2Ô∏è‚É£ What do you need to do to ‚Äúfix‚Äù this?

‚ÄúFixing‚Äù here really means **turn this from SKIP ‚Üí OK/WARN by giving it a schema.**

You need a `CONFIG["SCHEMA_EXPECTED_DTYPES"]` mapping, e.g.:

```python
CONFIG["SCHEMA_EXPECTED_DTYPES"] = {
    "customerID": "string",
    "gender": "string",
    "SeniorCitizen": "Int64",
    "Partner": "string",
    "Dependents": "string",
    "tenure": "Int64",
    "MonthlyCharges": "float64",
    "TotalCharges": "float64",
    "Churn_flag": "Int64",
}
```

Things to consider when you build this:

1. **Match Pandas dtype strings, not Python types**

   The comparison is:

   ```python
   actual_dtype = str(df[col].dtype)
   matches_expected = (actual_dtype == expected_str)
   ```

   So `"Int64"` vs `"int64"` vs `"object"` matters.

2. **Nullable vs non-nullable**

   If earlier steps cast to nullable types (`"Int64"`, `"string[python]"`, `"boolean"`), you should use those here.
   Otherwise you‚Äôll always get `matches_expected = False` and a permanent WARN.

3. **Which columns are worth enforcing?**

   Start with ‚Äústructural‚Äù ones:

   * IDs (`customerID`, etc.)
   * Target / flags (`Churn_flag`, `SeniorCitizen`, other special flags)
   * Key numeric measures (`tenure`, `MonthlyCharges`, `TotalCharges`)

   You don‚Äôt have to list everything at first. A partial schema is fine; 2.1.7A will only check what you supply.

4. **Where to define it**

   Best places:

   * In your YAML config, e.g.:

     ```yaml
     SCHEMA_EXPECTED_DTYPES:
       customerID: string
       SeniorCitizen: Int64
       tenure: Int64
       MonthlyCharges: float64
       TotalCharges: float64
       Churn_flag: Int64
     ```

   * Or, as a temporary step, hard-coded in your notebook right after CONFIG load, until you move it into the main config.

Once `SCHEMA_EXPECTED_DTYPES` is a non-empty dict, you‚Äôll see:

* `n_columns_checked > 0`
* enforcement table populated
* status will become `OK` if all match, `WARN` if any mismatch.

---

### 3Ô∏è‚É£ Can the outputs of this cell be tighter?

Yes ‚Äî right now you effectively get:

1. Section header (`print("\n2.1.7 ...")`)
2. Two ‚ÄúWrote baseline/enforcement‚Äù prints
3. A `display(dtype_enforcement_df)` (even when empty)
4. A `display(sec2_chunk_217A)`
5. A print inside `log_section_completion(...)` (likely)
6. The final explicit `print(f"‚úÖ [2.1.7A] ...")`

That‚Äôs a lot for one cell.

Here‚Äôs a **tighter variant** that:

* Only shows the enforcement table if there is something to check
* Uses a **single summary print**
* Relies on your logger for detailed logging

```python
print("\n2.1.7 üß± Column-Type Alignment Audit (no coercion)")

# ... same code up through building dtype_baseline_df and dtype_enforcement_df ...

dtype_baseline_path = SEC2_REPORTS_DIR / "dtype_baseline_report.csv"
tmp = dtype_baseline_path.with_suffix(".tmp.csv")
dtype_baseline_df.to_csv(tmp, index=False)
os.replace(tmp, dtype_baseline_path)

dtype_enforcement_path = SEC2_REPORTS_DIR / "dtype_enforcement_report.csv"
tmp = dtype_enforcement_path.with_suffix(".tmp.csv")
dtype_enforcement_df.to_csv(tmp, index=False)
os.replace(tmp, dtype_enforcement_path)

# Only preview enforcement if we actually had expected dtypes
if not dtype_enforcement_df.empty:
    display(dtype_enforcement_df.head(20))

# ---- Unified diagnostics row (same logic as before) ------------------------
if len(expected_dtypes) == 0:
    status_217A = "SKIP"
    n_checked_217A = 0
    n_mismatched_217A = 0
else:
    n_checked_217A = len(expected_dtypes)
    if dtype_enforcement_df.empty:
        status_217A = "WARN"
        n_mismatched_217A = n_checked_217A
    else:
        ok_mask = (
            dtype_enforcement_df["matches_expected"].fillna(False)
            & dtype_enforcement_df["present_in_df"].fillna(False)
        )
        n_mismatched_217A = int(n_checked_217A - ok_mask.sum())
        status_217A = "OK" if n_mismatched_217A == 0 else "WARN"

sec2_chunk_217A = pd.DataFrame(
    {
        "section": ["2.1.7A"],
        "section_name": ["Column-type alignment audit (no coercion)"],
        "check": ["Schema-driven dtype alignment (read-only)"],
        "level": ["info"],
        "n_columns_checked": [n_checked_217A],
        "n_mismatched": [n_mismatched_217A],
        "status": [status_217A],
        "detail": [
            f"Baseline: {dtype_baseline_path.name}; Enforcement: {dtype_enforcement_path.name}"
        ],
        "timestamp": [pd.Timestamp.now()],
    }
)

display(sec2_chunk_217A)
append_sec2(sec2_chunk_217A, SECTION2_REPORT_PATH)
SECTION2_APPEND_SECTIONS.add("2.1.7A")

log_section_completion(
    "2.1.7A",
    status_217A,
    checked=n_checked_217A,
    mismatched=n_mismatched_217A,
)

print(
    f"‚úÖ [2.1.7A] Dtype alignment audit | "
    f"status={status_217A} | "
    f"checked={n_checked_217A}, mismatched={n_mismatched_217A}"
)
```

If you want it **even tighter**, you can:

* Remove the `display(sec2_chunk_217A)` (rely purely on the CSV + final print),
* Or remove the final `print(...)` and rely purely on `log_section_completion`.

---

If you want, next step we can sketch a **minimal SCHEMA_EXPECTED_DTYPES** for your Telco schema so 2.1.7A reports something meaningful on the very next run.

---
---

># Q: Why status=warn and 7 mismatched?

Short version:
`status=WARN` because **at least one column‚Äôs dtype doesn‚Äôt match the expectation**, and `mismatched=7` because **7 of the 9 columns in `SCHEMA_EXPECTED_DTYPES` didn‚Äôt match** (or were missing) according to your own 2.1.7A logic.

Let‚Äôs tie that directly to the code.

---

## 1Ô∏è‚É£ What the code considers a ‚Äúmismatch‚Äù

From 2.1.7A:

```python
matches_expected = (actual_dtype == expected_str) if actual_dtype is not None else False

enforce_rows.append(
    {
        "column": col,
        "expected_dtype": expected_str,
        "actual_dtype": actual_dtype,
        "matches_expected": bool(matches_expected),
        "present_in_df": bool(present),
        "note": note,
    }
)
```

Then:

```python
ok_mask = dtype_enforcement_df["matches_expected"].fillna(False) & \
          dtype_enforcement_df["present_in_df"].fillna(False)

n_mismatched_217A = int(n_checked_217A - ok_mask.sum())
status_217A = "OK" if n_mismatched_217A == 0 else "WARN"
```

So a column counts as **OK** only if:

* `present_in_df == True`, and
* `matches_expected == True` (i.e., `str(df[col].dtype) == expected_str`)

Anything else ‚Üí counted as **mismatched**.

You have:

* `n_columns_checked = 9`
* `n_mismatched = 7`

That means only **2** of the 9 columns had both:

* present in `df`
* `actual_dtype` string exactly equal to the config string.

---

## 2Ô∏è‚É£ Why *these* 7 are likely mismatched in your Telco setup

Given your config and typical Telco dtypes, the usual culprits are:

1. **customerID**

   * Your config (strict block) says: `object`
   * If earlier code did `df["customerID"] = df["customerID"].astype("string")`
     ‚Üí `actual_dtype` becomes `"string[python]"` (or `"string"`), so:

     ```python
     "string[python]" != "object"
     ```

     ‚Üí mismatch.

2. **Churn_flag**

   * You explicitly cast in 2.1.1:

     ```python
     df[encoded_target_col] = encoded.astype("Int64")
     ```
   * If strict config says `int64` or `Int8` ‚Üí mismatch vs `"Int64"`.

3. **SeniorCitizen**

   * Often read as `int64` from the CSV.
   * If you set config to `Int64` or `int` or vice versa, you can get:

     * `"Int64"` vs `"int64"`
     * or `"int64"` vs `"int"`
       ‚Üí mismatch.

4. **TotalCharges**

   * In raw IBM CSV, this is often `object` (spaces / weird strings).
   * If your strict config says `float64` but you **haven‚Äôt coerced yet**:

     ```python
     actual_dtype = "object"
     expected_str = "float64"
     ```

     ‚Üí mismatch.

5. **Churn**

   * If you‚Äôve cast to `string` / `category` but config says `object`
     or vice versa ‚Üí mismatch.

Basically: **config is asserting a schema that doesn‚Äôt exactly match the string representation of `df.dtypes`.**

---

## 3Ô∏è‚É£ How to see *exactly* which 7 are mismatched

Run this right after 2.1.7A:

```python
# See full enforcement table
display(dtype_enforcement_df)

# Just the mismatched / missing ones
bad = dtype_enforcement_df[
    (~dtype_enforcement_df["matches_expected"]) |
    (~dtype_enforcement_df["present_in_df"])
]
display(bad)
```

You‚Äôll see something like:

| column       | expected_dtype | actual_dtype   | matches_expected | present_in_df | note |
| ------------ | -------------- | -------------- | ---------------- | ------------- | ---- |
| customerID   | object         | string[python] | False            | True          |      |
| TotalCharges | float64        | object         | False            | True          |      |
| ‚Ä¶            | ‚Ä¶              | ‚Ä¶              | ‚Ä¶                | ‚Ä¶             | ‚Ä¶    |

Those 7 `matches_expected == False` (or `present_in_df == False`) rows are where the `7 mismatched` came from.

---

## 4Ô∏è‚É£ What you should do next

You‚Äôve got two ways to ‚Äúfix‚Äù it, depending on intent:

### Option A: Make **config match reality** (looser enforcement)

Use the **actual** dtypes as the strict truth:

```python
{k: str(v) for k, v in df.dtypes.items()}
```

Update `SCHEMA_EXPECTED_DTYPES_STRICT` so each key matches `str(df[col].dtype)`.
Then re-run 2.1.7A ‚Üí `status` should flip to `OK` if nothing drifts.

### Option B: Make **data match config** (stricter contracts)

Keep strict dtypes as the ‚Äúcontract‚Äù and **coerce df to match** in an earlier section (e.g., 2.0.x or 2.1.0):

* Cast `customerID` to `object` or `string` consistently
* Force `TotalCharges` to `float64` (after cleaning)
* Cast `Churn_flag` ‚Üí `Int64` and set config accordingly, etc.

Then 2.1.7A becomes a **true contract check**: it will keep warning you if you violate your intended schema.

---

If you paste the `bad` table above, I can give you a one-liner diff: ‚Äúchange these 3 lines in the YAML or these 3 casts in your prep section to get status=OK.‚Äù
